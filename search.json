[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spectral Finite Element Methods",
    "section": "",
    "text": "Preface\nThis course is related to the analysis, formulation, and implementation of spectral finite element methods. The course covers the following topics in detail.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Spectral Finite Element Methods",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nnone",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#table-of-contents",
    "href": "index.html#table-of-contents",
    "title": "Spectral Finite Element Methods",
    "section": "Table of contents",
    "text": "Table of contents\n\nChapter 1\n\nIntroduction to spectral methods\n\n\n\nChapter 2\n\nFourier series expansion\nDiscrete Fourier series: even expansion\nDiscrete Fourier series: odd expansion\nDiscrete derivatives\nDiscrete inner products\n\n\n\nChapter 3: Fourier spectral methods\n\nFourier-Galerkin methods\nFourier-collocation methods\n\n\n\nChapter 4: Orthogonal polynomials",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Why do we need higher order methods?\nFor slowly varying functions, it is better to use low order polynomial approximation, which is local in nature. However, using low order polynomial approximation for solutions with significant spatial-temporal variation requires a very fine grid in order to accurately resolve the function.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#applications-of-spectral-methods",
    "href": "intro.html#applications-of-spectral-methods",
    "title": "1  Introduction",
    "section": "1.2 Applications of spectral methods",
    "text": "1.2 Applications of spectral methods\n\nThe first spectral method computations were simulations of homogeneous turbulence on periodic domains",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html",
    "href": "fourier-expansion.html",
    "title": "Fourier series expansion",
    "section": "",
    "text": "Key featutes:\nLet \\(L^{2}\\left[0,2\\pi\\right]\\) be the functional space of square integrable functions defined on the interval \\(\\left[0,2\\pi\\right]\\), then Fourier series of a function \\(u(x)\\in L^{2}[0,2\\pi]\\) is given as:\n\\[\n\\mathcal{F}[u]:=a_{0}+\\sum_{n=1}^{\\infty}a_{n}\\cos(nx)+\\sum_{n=1}^{\\infty}b_{n}\\sin(nx)\n\\]\nwhere,\n\\[\na_{0}=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u(x)dx,\\quad a_{n}=\\frac{1}{\\pi}\\int_{0}^{2\\pi}u(x)\\cos(nx)dx,\\quad n&gt;0,\n\\]\n\\[\nb_{n}=\\frac{1}{\\pi}\\int_{0}^{2\\pi}u(x)\\sin(nx)dx,\\quad n&gt;0.\n\\]\nWe can also write Fourier series in complex variables by using Euler’s formula \\(e^{i\\theta}=\\cos\\theta+i\\sin\\theta\\)\n\\[\n\\cos\\theta=\\frac{e^{i\\theta}+e^{-i\\theta}}{2},\\quad\\sin\\theta=\\frac{e^{i\\theta}-e^{-i\\theta}}{2i}\n\\]\n\\[\n\\begin{aligned}\\mathcal{F}[u] & :=a_{0}+\\sum_{n=1}^{\\infty}a_{n}\\left(\\frac{e^{inx}+e^{-inx}}{2}\\right)+\\sum_{n=1}^{\\infty}b_{n}\\left(\\frac{e^{inx}-e^{-inx}}{2i}\\right)\\\\\n& =a_{0}+\\sum_{n=1}^{\\infty}\\left(\\frac{a_{n}-ib_{n}}{2}\\right)e^{inx}++\\sum_{n=1}^{\\infty}\\left(\\frac{a_{n}+ib_{n}}{2}\\right)e^{-inx}\\\\\n& =\\sum_{n=-\\infty}^{\\infty}c_{n}e^{inx}\n\\end{aligned}\n\\]\nwhere,\n\\[\nc_{n}=\\begin{cases}\na_{0} & n=0\\\\\n\\frac{a_{n}-ib_{n}}{2} & n&gt;0\\\\\n\\frac{a_{-n}+ib_{-n}}{2} & n&lt;0\n\\end{cases}\n\\]\nLet \\(L^{2}\\left[0,2\\pi\\right]\\) be a functional space of square integrable functions defined on the interval \\(\\left[0,2\\pi\\right]\\), then Fourier series of a function \\(u(x)\\in L^{2}[0,2\\pi]\\) is given as:\n\\[\n\\mathcal{F}[u]:=\\sum_{n=1}^{\\infty}\\hat{u}_{n}e^{inx}\n\\]\n\\[\n\\hat{u}_{n}=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u(x)e^{-inx}dx\n\\]\nLet \\(L^{2}\\left[0,L\\right]\\) be a functional space of square integrable functions defined on the interval \\(\\left[0,L\\right]\\), then Fourier series of a function \\(u(x)\\in L^{2}[0,L]\\) is given given as:\n\\[\n\\mathcal{F}[u]:=\\sum_{n=1}^{\\infty}\\hat{u}_{n}e^{\\frac{i2\\pi nx}{L}}\n\\]\n\\[\n\\hat{u}_{n}=\\frac{1}{L}\\int_{0}^{L}u(x)e^{-\\frac{2\\pi inx}{L}}dx\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#key-featutes",
    "href": "fourier-expansion.html#key-featutes",
    "title": "Fourier series expansion",
    "section": "",
    "text": "If \\(u(x)\\) is a real function, then coefficients \\(a_{n},b_{n}\\)will be real, and \\(c_{n}=c_{-n}^{*}\\) (complex conjugate). Thus, only half the coefficients are needed to describe in the Fourier series.\nIf \\(u(x)\\) is real and even, then \\(b_{n}=0\\Rightarrow\\) Cosine series\nIf \\(u(x)\\) is real and odd, then \\(a_{0}=0\\Rightarrow\\) Sine series",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#truncated-fourier-series",
    "href": "fourier-expansion.html#truncated-fourier-series",
    "title": "Fourier series expansion",
    "section": "Truncated Fourier Series",
    "text": "Truncated Fourier Series\nLet us define a finite dimensional space \\(\\mathfrak{\\hat{B}}_{N}\\) by\n\\[\n\\mathfrak{\\hat{B}}_{N}:=\\text{span}\\left\\{ e^{inx}\\vert\\quad\\vert n\\vert\\le N/2\\right\\}\n\\]\n\n\\(\\mathfrak{\\hat{B}}_{N}\\)has \\(N+1\\) dimension.\nIt contains \\(1,\\cos\\left(x\\right),\\cos\\left(2x\\right),\\cdots\\cos\\left(\\frac{N}{2}x\\right),\\sin\\left(x\\right),\\sin\\left(2x\\right),\\cdots\\sin\\left(\\frac{N}{2}x\\right)\\)\nTruncated Fourier series is obtained by taking projection of infinite Fourier series onto \\(\\mathfrak{\\hat{B}}_{N}\\):\n\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=-N/2}^{n=N/2}\\hat{u}_{n}e^{inx}\n\\]\nTheorem (Convergence of Fourier series): If \\(\\mathfrak{\\hat{B}}_{N}\\subset L^{2}\\), in other words, \\(\\sum_{n=-N/2}^{n=N/2}\\vert\\hat{u}_{n}\\vert^{2}&lt;\\infty\\), then the truncated series converges in the \\(L^{2}\\) norm, that is, \\(\\Vert u-\\mathcal{P}_{N}u\\Vert_{L^{2}\\left[0,2\\pi\\right]}\\rightarrow0\\text{{as}}N\\rightarrow\\infty\\). If, moreover, \\(\\sum_{n=-N/2}^{n=N/2}\\vert\\hat{u}_{n}\\vert&lt;\\infty\\) then the truncated series converges uniformly, that is\n\\[\n\\Vert u-\\mathcal{P}_{N}u\\Vert_{L^{\\infty}\\left[0,2\\pi\\right]}\\rightarrow0\\text{{as}}N\\rightarrow\\infty\n\\]\nCorollary: The fact that the truncated series converges implies that the error is dominated by the tail of the series:\n\\[\n\\Vert u-\\mathcal{P}_{N}u\\Vert_{L^{2}}^{2}=2\\pi\\sum_{\\vert n\\vert&gt;N/2}\\vert\\hat{u}_{n}\\vert^{2}\n\\]\nand\n\\[\n\\Vert u-\\mathcal{P}_{N}u\\Vert_{L^{\\infty}}^{2}\\le\\sum_{\\vert n\\vert&gt;N/2}\\vert\\hat{u}_{n}\\vert\n\\]\nTheorem: If a function \\(u(x)\\), its first \\((m-1)\\) derivatives, and their periodic extensions are all continuous and if the mth derivative of \\(u(x)\\) is in \\(L^{2}\\left[0,2\\pi\\right]\\) , then \\(\\forall n\\ne0\\), \\(\\hat{u}_{n}\\) decay as\n\\[\n\\vert\\hat{u}_{n}\\vert\\propto\\left(\\frac{1}{n}\\right)^{m}\n\\]\nProof: The error induced by truncating a Fourier series depends solely on how fast the \\(\\hat{u_{n}}\\)decays. This decay characteristics depends upon the regularity of \\(u(x)\\) in \\([0,2\\pi]\\) and periodicity of the functions and its derivatives.\n\\[\n\\begin{split}\\hat{u}_{n} & =\\sum_{k=0}^{m-1}\\frac{(-1)^{k}}{\\left(-2\\pi in\\right)^{k+1}}\\left(D^{k}u\\vert_{2\\pi}-D^{k}u\\vert_{0}\\right)\\\\\n& +\\frac{(-1)^{m}}{\\left(-2\\pi in\\right)^{m}}\\int_{0}^{2\\pi}D^{m}ue^{-inx}dx\n\\end{split}\n\\]\nwhere, \\(D^{k}u=\\frac{du(x)}{dx}\\)\n\nIf \\(u\\in C_{p}^{\\infty}[0,2\\pi]\\) then we obtain spectral convergence\nAs a thumb rule, the smoother the function, the faster the convergence of the truncated series.\n\nSpectral convergence: \\(u\\in C_{p}^{\\infty}[0,2\\pi]\\)\n\\[\nu(x)=\\frac{3}{5-4\\cos(x)}\n\\]\nNonuniform quadratic convergence:\n\\[\nu(x)=\\sin\\left(\\frac{x}{2}\\right)\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#derivative-of-truncated-fourier-series",
    "href": "fourier-expansion.html#derivative-of-truncated-fourier-series",
    "title": "Fourier series expansion",
    "section": "Derivative of truncated Fourier series",
    "text": "Derivative of truncated Fourier series\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{\\vert n\\vert\\le N/2}\\hat{u}_{n}e^{inx}\n\\]\n\\[\nD^{(k)}\\mathcal{P}_{N}u(x)=\\sum_{\\vert n\\vert\\le N/2}\\left(in\\right)^{k}\\hat{u}_{n}e^{inx}\n\\]\nIt is clear that\n\\[\nD^{(k)}\\mathcal{P}_{N}u=\\mathcal{P}_{N}D^{(k)}u\n\\]\nIt means that the projection of exact derivative of \\(u\\) is same as the derivative of projection of \\(u\\).",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#discrete-fourier-expansion",
    "href": "fourier-expansion.html#discrete-fourier-expansion",
    "title": "Fourier series expansion",
    "section": "Discrete Fourier expansion",
    "text": "Discrete Fourier expansion\nIn many practical applications, Fourier coefficients cannot be evaluated in closed form due to the complex nature of function \\(u(x)\\). Then to compute the Fourier coefficients:\n\\[\n\\hat{u}_{n}=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u(x)e^{-inx}dx\n\\]\nnumerical integration schemes are used. A typical numerical integration selects quadrature points and weights to approximate the above integral with finite summation:\n\\[\n\\hat{u}_{n}\\approx\\tilde{u}_{n}=\\sum_{j=0}^{M}u(x_{j})e^{-inx_{j}}w_{j}\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#trapezoidal-rule",
    "href": "fourier-expansion.html#trapezoidal-rule",
    "title": "Fourier series expansion",
    "section": "Trapezoidal rule",
    "text": "Trapezoidal rule\nIn this chapter, we will employ Trapezoidal rule due to its supreme performance and simple use.\n\nLet \\(f(x)\\) be a periodic function on \\([0,2\\pi]\\), that is \\(f(0)=f(2\\pi)\\). Let us divide the x axis by \\(N\\) uniform segments, then \\(x_{j}=\\frac{2\\pi}{N}j\\) for \\(j=0,1,\\cdots N\\), Note that \\(x_{0}=0\\) and \\(x_{N}=2\\pi\\). Let \\(f_{j}=f(x_{j})\\), then due to periodicity, \\(f_{0}=f_{N}.\\) Now, consider the area of trapezoidal:\n\\[\n\\Delta A_{j}=\\frac{1}{2}\\left(f_{j}+f_{j+1}\\right)\\Delta x_{j}=\\frac{1}{2}\\left(f_{j}+f_{j+1}\\right)\\frac{2\\pi}{N},\\forall j=0,1,\\cdots,N-1\n\\]\nThen,\n\\[\n\\begin{aligned}\\int_{0}^{2\\pi}f(x)dx & =\\sum_{j=0}^{N-1}\\Delta A_{j}\\\\\n& =\\frac{2\\pi}{N}\\sum_{j=0}^{N-1}\\frac{1}{2}\\left(f_{j}+f_{j+1}\\right)\\\\\n& =\\frac{2\\pi}{N}\\frac{1}{2}\\left(f_{0}+f_{1+1}\\right)+\\frac{2\\pi}{N}\\sum_{j=1}^{N-2}\\frac{1}{2}\\left(f_{j}+f_{j+1}\\right)+\\frac{2\\pi}{N}\\frac{1}{2}\\left(f_{N-1}+f_{N}\\right)\\\\\n& =\\frac{2\\pi}{N}\\frac{1}{2}\\left(f_{0}+f_{N}\\right)+\\frac{2\\pi}{N}\\sum_{j=1}^{N-1}f_{j}\\\\\n& =\\frac{2\\pi}{N}\\frac{1}{2}\\left(f_{0}+f_{0}\\right)+\\frac{2\\pi}{N}\\sum_{j=1}^{N-1}f_{j},\\quad\\left(\\text{due to periodicity}\\right)\\\\\n& =\\frac{2\\pi}{N}\\sum_{j=0}^{N-1}f_{j}\n\\end{aligned}\n\\]\nTherefore, for periodic function \\(f\\) over \\(\\left[0,2\\pi\\right]\\), trapezoidal rule is given by:\n\\[\n\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f(x)dx=\\frac{1}{M+1}\\sum_{j=0}^{M}f\\left(\\frac{2\\pi j}{M+1}\\right)\n\\]\nThe N point trapezoidal rule is exact for any trigonometric polynomial \\(f(x)=e^{inx},\\vert n\\vert\\le N-1\\).\n\nFor even expansion (\\(N\\) is even) we have \\(M=N-1\\), and there are \\(M+1=N\\) (even) points. This rule is exact for \\(f(x)=e^{inx},\\vert n\\vert\\le N-1\\).\nFor odd expansion (\\(N\\) is odd), we have \\(M=N\\), and there are \\(M+1=N+1\\)(even) points. This rule is exact for \\(f(x)=e^{inx},\\vert n\\vert\\le N\\).",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#even-expansion",
    "href": "fourier-expansion.html#even-expansion",
    "title": "Fourier series expansion",
    "section": "Even expansion",
    "text": "Even expansion\nWe consider following truncated series\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=-N/2}^{n=N/2}\\hat{u}_{n}e^{inx}\n\\]\nand its discrete counter part\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=-N/2}^{n=N/2}\\widetilde{u}_{n}e^{inx}\n\\]\nWhere, \\(N\\) is an even number. Consider \\(N\\) equally spaced grid points in \\([0,2\\pi)\\) denoted by \\(x_{j}\\) such that \\(x_{j}=\\frac{2\\pi}{N}j,\\quad j=0,1,2\\cdots N-1\\). Note that if we include \\(2\\pi\\), then there are \\(N+1\\) total points (odd), and \\(N\\) intervals (even). Fourier coefficients are given by\n\\[\n\\hat{u}_{n}=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u\\left(x\\right)e^{-inx}dx,\\forall\\vert n\\vert\\le\\frac{N}{2}\n\\]\nUsing trapezoidal rule to calculate the Fourier coefficients:\n\\[\n\\begin{aligned}\\tilde{u}_{n} & =\\frac{1}{2\\pi\\tilde{c}_{n}}\\sum_{j=0}^{N-1}u\\left(x_{j}\\right)e^{-inx_{j}}\\frac{2\\pi}{N}\\\\\n& =\\frac{1}{\\tilde{c}_{n}N}\\sum_{j=0}^{N-1}u\\left(x_{j}\\right)e^{-inx_{j}}\n\\end{aligned}\n\\]\nwhere,\n\\[\n\\tilde{c}_{n}=\\begin{cases}\n1 & \\vert n\\vert&lt;N/2\\\\\n2 & \\vert n\\vert=N/2\n\\end{cases}\n\\]\nThe quadrature formula\n\\[\n\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f(x)dx=\\frac{1}{N}\\sum_{j=0}^{N-1}f(x_{j}),\\quad x_{j}=\\frac{2\\pi}{N}j,j=0,1,\\cdots,N-1\n\\]\nis exact for any trigonometric polynomial \\(f(x)=e^{inx},\\vert n\\vert\\le N-1\\), that is ,\\(\\hat{\\mathfrak{B}}_{2N-2}\\).\n\nN points are enough for \\(1,\\cos(x),\\cdots\\cos(N-1)x,\\sin(x),\\cdots\\sin(N-1)x\\)\nN points are enough for \\(\\sin Nx\\)\nN points are not enough for \\(\\cos Nx\\)\n\nThere are only \\(N\\) independent discrete Fourier coefficients \\(\\tilde{u}_{n}\\) as \\(\\tilde{u}_{N/2}=\\tilde{u}_{-N/2}\\).\nNoting that\n\\[\n\\mathcal{I}_{N}\\sin\\left(\\frac{Nx}{2}\\right)=0\n\\]\nWe can say that \\(\\mathcal{I}_{N}\\) does not project in \\(\\mathfrak{\\hat{B}}_{N}\\). Actually, it projects in \\(\\mathfrak{\\tilde{B}}_{N}\\) which is given by\n\\[\n\\tilde{\\mathfrak{B}}_{N}=span\\left\\{ \\left(\\cos(nx),0\\le n\\le N/2\\right)\\cup\\left(\\sin\\left(nx\\right),1\\le n\\le N/2-1\\right)\\right\\}\n\\]\nNote that \\(dim\\left(\\mathfrak{\\tilde{B}}_{N}\\right)=N\\) .\nDue to the particular definition of \\(\\tilde{u}_{n}\\) used in this section, \\(\\mathcal{I}_{N}u\\) interpolates \\(u\\) at the quadrature nodes of the trapezoidal formula.\nFor the discrete Fourier transform considered in this section we have\n\\[\n\\mathcal{I}_{N}u(x_{j})=u(x_{j}),\\quad\\forall x_{j}=\\frac{2\\pi j}{N},j=0,1,\\cdots,N-1\n\\]\nor\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N-1}u(x_{j})g_{j}(x)\n\\]\n\\[\n\\begin{split}g_{j}(x) & =\\sum_{\\vert n\\vert\\le N/2}\\frac{1}{N\\tilde{c}_{n}}e^{in(x-x_{j})}\\\\\n& =\\frac{1}{N}\\sin\\left(N\\frac{x-x_{j}}{2}\\right)\\cot\\left(\\frac{x-x_{j}}{2}\\right)\n\\end{split}\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#odd-expansion",
    "href": "fourier-expansion.html#odd-expansion",
    "title": "Fourier series expansion",
    "section": "Odd expansion",
    "text": "Odd expansion\nLet \\(N\\) be odd, then we select \\(N+1\\) (even) points\n\\[\nx_{j}=\\frac{2\\pi}{N+1}j,j=0,1,2,\\cdots,N\n\\]\nNote that if we include \\(2\\pi\\), then there are \\(N+2\\) (odd) points, and \\(N+1\\) (even) intervals. By Using trapezoidal rule to calculate the Fourier coefficients:\n\\[\n\\begin{aligned}\\tilde{u}_{n} & =\\frac{1}{2\\pi}\\sum_{j=0}^{N}u\\left(x_{j}\\right)e^{-inx_{j}}\\frac{2\\pi}{N+1}\\\\\n& =\\frac{1}{N+1}\\sum_{j=0}^{N}u\\left(x_{j}\\right)e^{-inx_{j}}\n\\end{aligned}\n\\]\nDiscrete Fourier interpolation is given by\n\\[\n\\mathcal{I}_{N}u\\left(x\\right)=\\sum_{\\vert n\\vert\\le N/2}\\tilde{u}_{n}e^{inx}\n\\]\nThe quadrature formula is exact for \\(\\vert n\\vert\\le N\\). Which means it can compute the following inner product exactly:\n\\[\n\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f(x)g(x)dx=\\frac{1}{N+1}\\sum_{j=0}^{N}f(x_{j})g(x_{j})\n\\]\nwhere, \\(f,g\\in\\mathfrak{B}_{N}.\\)\nLagrange interpolation form (cardinal functions)\n\\[\n\\mathcal{I}_{N}u\\left(x\\right)=\\sum_{j=0}^{N}u\\left(x_{j}\\right)l_{j}\\left(x\\right)\n\\]\nwhere,\n\\[\nl_{j}\\left(x\\right)=\\frac{1}{N+1}\\frac{sin\\left[\\frac{N+1}{2}\\left(x-x_{j}\\right)\\right]}{sin\\left(\\frac{x-x_{j}}{2}\\right)}\n\\]\nNote that \\(l_{j}\\left(x\\right)\\) is a \\(N\\)th order polynomial in sine.",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#aliasing-error",
    "href": "fourier-expansion.html#aliasing-error",
    "title": "Fourier series expansion",
    "section": "Aliasing error",
    "text": "Aliasing error\nTODO",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#differentiation",
    "href": "fourier-expansion.html#differentiation",
    "title": "Fourier series expansion",
    "section": "Differentiation",
    "text": "Differentiation\n\\[\n\\frac{d}{dx}\\mathcal{I}_{N}u(x)=\\sum_{\\vert n\\vert\\le N/2}in\\tilde{u}_{n}e^{inx}\n\\]\nwhere\n\\[\n\\tilde{u}_{n}=\\frac{1}{N\\tilde{c}_{n}}\\sum_{j=0}^{N-1}u(x_{j})e^{-inx_{j}}\n\\]\nNote that\n\\[\n\\mathcal{I}_{N}\\frac{du}{dx}\\ne\\mathcal{I_{N}}\\frac{d}{dx}\\mathcal{I}_{N}u,\\quad\\text{{except}}if\\quad u\\in\\hat{\\mathfrak{B}}_{N}\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-expansion.html#discrete-inner-product",
    "href": "fourier-expansion.html#discrete-inner-product",
    "title": "Fourier series expansion",
    "section": "Discrete inner product",
    "text": "Discrete inner product\nLet us consider functions \\(f,g\\in L^{2}(\\left[0,2\\pi\\right])\\), and define following approximations:\n\\[\nf_{N}(x)=\\mathcal{P}_{N}f:=\\sum_{\\vert n\\vert\\le N/2}f(x)e^{inx}\n\\]\n\\[\ng_{N}(x)=\\mathcal{P}_{N}g:=\\sum_{\\vert n\\vert\\le N/2}g(x)e^{inx}\n\\]\nNote: \\(f_{N},g_{N}\\in\\mathfrak{\\hat{B}}_{N}\\).\nThen, the continuous inner product is defined by\n\\[\n\\left(f_{N},g_{N}\\right):=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f_{N}(x)\\bar{g}_{N}(x)dx\n\\]\nNote: \\(f_{N}g_{N}\\in\\mathfrak{\\hat{B}}_{2N}\\).\nThe discrete inner product (for odd expansion) is given by:\n\\[\n\\left(f_{N},g_{N}\\right)_{N}:=\\frac{1}{N+1}\\sum_{j=0}^{N}f_{N}(x_{j})\\bar{g}_{N}(x_{j})\n\\]\n\\[\n\\Vert f_{N}\\Vert_{N}^{2}=\\left(f_{N},f_{N}\\right)_{N}\n\\]\nIn the case of odd expansion \\(N+1\\) points are accurate for \\(f(x)=e^{inx},\\vert n\\vert\\le N\\). Therefore,\n\\[\n\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f_{N}(x)\\bar{g}_{N}(x)dx=\\left(f_{N},g_{N}\\right)_{N}:=\\frac{1}{N+1}\\sum_{j=0}^{N}f_{N}(x_{j})\\bar{g}_{N}(x_{j})\n\\]\nHowever, in the case of even expansion the situation is different:\nIn the case of even expansion \\(N\\) points are accurate for \\(f(x)=e^{inx},\\vert n\\vert\\le N-1\\), that is, \\(f\\in\\hat{\\mathfrak{\\mathfrak{B}}}_{2N-2}\\). Moreover, \\(N\\) points are sufficient for \\(\\sin Nx\\) but not for \\(\\cos Nx\\). Therefore, if \\(f_{N},g_{N}\\in\\mathfrak{\\hat{B}}_{N}\\), then\n\\[\n\\frac{1}{2\\pi}\\int_{0}^{2\\pi}f_{N}(x)\\bar{g}_{N}(x)dx\\ne\\left(f_{N},g_{N}\\right)_{N}:=\\frac{1}{N}\\sum_{j=0}^{N-1}f_{N}(x_{j})\\bar{g}_{N}(x_{j})\n\\]\nHowever, we can show that the continuous and discrete norms are uniformly equivalent.\n\\[\n\\frac{1}{K}\\Vert f_{N}\\Vert_{L^{2}[0,2\\pi]}^{2}\\le\\Vert f_{N}\\Vert_{N}^{2}\\le K\\Vert f_{N}\\Vert_{L^{2}[0,2\\pi]}^{2}\n\\]",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fourier series expansion</span>"
    ]
  },
  {
    "objectID": "fourier-galerkin-method.html",
    "href": "fourier-galerkin-method.html",
    "title": "Fourier-Galerkin method",
    "section": "",
    "text": "Examples\nLet \\(L\\) be a differential operator (linear or nonlinear). Consider following initial-boundary-value problem on \\([0,2\\pi]\\).\n\\[\n\\frac{\\partial u(x,t)}{\\partial t}=Lu,\\quad u(x,0)=u_{0}(x)\n\\]\nAlso, \\(u(0,t)=u(2\\pi,t),\\forall t\\)\nRecall that \\(\\hat{\\mathfrak{B}}_{N}:=span\\{e^{inx}\\vert\\quad\\vert n\\vert\\le N/2\\}\\). Then, we seek solutions in \\(\\hat{\\mathfrak{B}}_{N}\\) by approximating \\(u\\) as \\(u_{N}\\in\\hat{\\mathfrak{B}}_{N}\\) such that\n\\[\nu_{N}(x,t):=\\sum_{\\vert n\\vert\\le N/2}\\hat{a}_{n}(t)e^{inx}\n\\]\nNote that, in general:\n\\[\n\\hat{a}_{n}(t)\\ne\\hat{u}_{n}(t)=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u(x)e^{-inx}\n\\]\nResidual:\n\\[\nR(x,t)=\\frac{\\partial u_{N}}{\\partial t}-Lu_{N}\n\\]\nThe coefficients \\(\\hat{a}_{n}\\)are obtained by the requirement that the residual \\(R(x,t)\\) is orthogonal to \\(\\hat{\\mathfrak{B}}_{N}\\), that is:\n\\[\n\\int_{0}^{2\\pi}R(x,t)e^{-inx}dx=0,\\quad\\forall\\vert n\\vert\\le N/2\n\\]\nSo, if we express \\(R\\) as follows,\n\\[\nR(x,t)=\\sum_{\\vert n\\vert\\le\\infty}\\hat{R}_{n}(t)e^{inx}\n\\]\nthen,\n\\[\n\\hat{R}_{n}(t)=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}R(x,t)e^{-inx}dx=0,\\quad\\forall\\vert n\\vert\\le N/2\n\\]\nThese are \\(N+1\\) ODEs to determine \\(N+1\\) unknowns, \\(\\hat{a}_{n}(t)\\), with following initial conditions.\n\\[\n\\hat{a}_{n}(0)=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}u_{0}(x)e^{-inx}dx,\\quad\\forall\\vert n\\vert\\le N/2\n\\]\nNow we ask following questions:\nWhen does \\(R(x,t)\\) is orthogonal to \\(\\hat{\\mathfrak{B}}_{N}\\)?\nWhat if \\(R(x,t)\\) is NOT orthogonal to \\(\\hat{\\mathfrak{B}}_{N}\\)?\nWhat if \\(R(x,t)\\) is in \\(\\hat{\\mathfrak{B}}_{N}\\)\nConstant coefficient problem.\n\\[\nLu=c\\frac{\\partial u(x,t)}{\\partial x}+\\nu\\frac{\\partial^{2}u(x,t)}{\\partial t^{2}}\n\\]\nVariable coefficient problem\n\\[\nLu=\\sin(x)\\frac{\\partial u(x,t)}{\\partial x}\n\\]\nNonlinear problem\n\\[\nLu=u(x,t)\\frac{\\partial u(x,t)}{\\partial x}\n\\]\nStrongly nonlinear problem\n\\[\nLu=e^{u(x,t)}\\frac{\\partial u(x,t)}{\\partial x}\n\\]\nFourier-Galerkin method is very efficient for linear, constant coefficient problem\nIt becomes complicated for variable coefficient and nonlinear problem",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fourier-Galerkin method</span>"
    ]
  },
  {
    "objectID": "fourier-collocation-method.html",
    "href": "fourier-collocation-method.html",
    "title": "Fourier Collocation Method",
    "section": "",
    "text": "We will use interpolating operator \\(\\mathcal{I}_{N}\\) instead of projection operator \\(\\mathcal{P}_{N}\\).\nIt mean we seek solution in \\(\\tilde{\\mathfrak{B}}_{N}\\) and not in \\(\\hat{\\mathfrak{B}}_{N}\\) .\nThis method is called Fourier-collocation method or pseudospectral method\n\nQuadrature formulas and grid points are critical part of this method?\n\nCollocation grid: In collocation method, we require that the residual \\(R(x,t)\\) vanishes exactly on some set of gridpoints \\(y_{j}\\). These gridpoints are called Collocation points or Collocation grids.\nInterpolation grid: Collection of grid points, such as \\(x_{j}=\\frac{2\\pi}{N}j,\\quad j=0,1,\\cdots,N-1\\), which is used in \\(\\mathcal{I}_{N}\\).\n\nThere is no need for collocation grid and interpolation grid to be identical to each other.\nLet \\(L\\) be a differential operator (linear or nonlinear). Consider following initial-boundary-value problem on \\([0,2\\pi]\\).\n\\[\n\\frac{\\partial u(x,t)}{\\partial t}=Lu,\\quad u(x,0)=u_{0}(x)\n\\]\nRecall that \\(\\tilde{\\mathfrak{B}}_{N}:=span\\{e^{inx}\\vert\\quad\\vert n\\vert\\le N/2\\}/\\sin\\left(\\frac{Nx}{2}\\right)\\). Then, we seek solutions in \\(\\tilde{\\mathfrak{B}}_{N}\\) by approximating \\(u\\) as:\n\\[\nu_{N}(x,t):=\\sum_{j=0}^{N-1}u_{N}(x_{j},t)g_{j}(x)\n\\]\nThere are \\(N\\) unknown coefficients \\(u_{N}(x_{j},t)\\), and \\(g_{j}(x)\\) is the Lagrange interpolation polynomial for an even numbe of points, and \\(x_{j}=\\frac{2\\pi}{N}j,j=0,1,\\cdots N-1\\).\nResidual:\n\\[\nR_{N}(x,t)=\\frac{\\partial u_{N}}{\\partial t}-Lu_{N}\n\\]\nCollocation method:\n\\[\nR_{N}(y_{j},t)=0,\\forall j=0,1,\\cdots,N-1\n\\]\nThese are \\(N\\) equations which should be sufficient to find \\(N\\) unknows.\nIn the collocation method the only use we make of the Fourier approximation is in obtaining the derivatives of the numerical approximation in physical space.",
    "crumbs": [
      "Fourier Spectral Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Fourier Collocation Method</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html",
    "href": "orthogonal-polynomials.html",
    "title": "Orthogonal polynomials",
    "section": "",
    "text": "Introduction\nThe Fourier spectral method, which is presented in previous chapters, if applied to a non-periodic problem, induces the so-called Gibbs phenomenon, and reduces the global convergence rate. Therefore, it can be said that Fourier spectral method is appropriate for problems with periodic boundary conditions. So, how to handle the problem with non-periodic boundary conditions? To this end, we should use orthogonal polynomials. In this chapter, we will discuss the classical orthogonal polynomials, such as the Jacobi, Ultraspherical, Legendre, Chebyshev, Hermite and Laguerre polynomials. The aim of this chapter is to present essential properties and computation aspects of these orthogonal polynomials.\nLet \\(\\alpha\\left(x\\right)\\) be a distribution, which is non-decreasing function, and not contant in the interval \\(\\left[a,b\\right].\\) If \\(a=-\\infty\\) or \\(b=+\\infty\\) then we require \\(\\alpha\\left(\\pm\\infty\\right)\\) to be finite in the limiting sense. Then, two functions, \\(f\\) and \\(g\\) on \\(\\left[a,b\\right]\\)are said to be orthogonal with respect to the distribution \\(\\alpha(x)\\), if\n\\[\\left(f,g\\right):=\\int_{a}^{b}f(x)g(x)d\\alpha(x)=0\\]\nIn this chapter we will use following form of distribution:\n\\[d\\alpha\\left(x\\right)=w(x)dx\\]\nwhere, \\(w(x)\\in L^{1}\\left(a,b\\right)\\) is called the weight funciton, which is strictly positive in the interval.\nA polynomial of degree \\(n\\) is given by\n\\[p_{n}(x)=\\sum_{m=0}^{n}k_{m}x^{m}\\]\nThe leading coefficient of \\(p_{n}\\)is denoted by \\(k_{n}\\ne0\\).\nThe collection of polynomial of degree upto \\(n\\) will be denoted by \\(\\mathcal{P}^{n}:=\\left\\{ p_{m}\\left(x\\right)\\right\\} _{m=0}^{n}\\). Then, \\(\\left\\{ p_{m}\\left(x\\right)\\right\\} _{m=0}^{n}\\) forms a orthogonal set of polynomials on \\(\\left[a,b\\right]\\)with respect to the distribution \\(\\alpha(x)\\), if\n\\[\\int_{a}^{b}p_{m}(x)p_{n}(x)d\\alpha(x)=h_{n}\\delta_{mn}\\]\nwhere, \\(\\delta_{mn}\\)is diract-delta symbol. It can be seen that \\(p_{m}\\in L_{\\alpha}^{2}\\left(a,b\\right),m=0,1,\\cdots\\), and\n\\[h_{n}:=\\Vert p_{n}\\Vert^{2}=\\int_{a}^{b}p_{n}(x)p_{n}(x)d\\alpha(x)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#introduction",
    "href": "orthogonal-polynomials.html#introduction",
    "title": "Orthogonal polynomials",
    "section": "",
    "text": "Theorem: A polynomial \\(q_{n}\\in\\mathcal{P}^{n}\\) can be given by linear combination of orthogonal polynomials \\(p_{0},\\cdots,p_{n}\\) as\n\\[q_{n}(x)=\\sum_{m=0}^{n}a_{m}p_{m}(x)\\]\nCorollary: For \\(q_{n}\\in\\mathcal{P}^{n}\\), we have following results:\n\\[\\left(q_{n},p_{m}\\right)=0,\\forall m&gt;n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#from-independent-to-orthonormal",
    "href": "orthogonal-polynomials.html#from-independent-to-orthonormal",
    "title": "Orthogonal polynomials",
    "section": "From independent to orthonormal",
    "text": "From independent to orthonormal\nIf \\(\\left\\{ f_{m}(x)\\right\\} _{m=0,\\cdots,n}\\) are the independent functions defined on \\([a,b]\\), then we can obtain a unique set of orthonormal polynomials \\(\\left\\{ p_{m}\\left(x\\right)\\right\\} _{m=1}^{m=n}\\) from these independent functions.",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#formal-fourier-expansion",
    "href": "orthogonal-polynomials.html#formal-fourier-expansion",
    "title": "Orthogonal polynomials",
    "section": "Formal Fourier expansion",
    "text": "Formal Fourier expansion\nA function \\(f(x)\\) can be written as a linear combination of orthonormal polynomials.\n\\[f(x)=\\sum_{m=0}^{\\infty}f_{m}p_{m}(x)\\]\nwhere,\n\\[f_{m}:=\\frac{\\left(f,p_{m}\\right)}{h_{m}}=\\frac{\\int_{a}^{b}f(x)p_{m}(x)d\\alpha(x)}{h_{m}}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#notations",
    "href": "orthogonal-polynomials.html#notations",
    "title": "Orthogonal polynomials",
    "section": "Notations",
    "text": "Notations\nFrom here on, we will use the following conventions to define orthogonal polynomials.\n\n\\(P_{n}\\) denotes a orthogonal polynomial of order \\(n\\), with leading coefficient \\(k_{n}\\) and \\(\\Vert P_{n}\\Vert^{2}=h_{n}\\)\nThe orthonormal polynomial corresponding to \\(P_{n}\\) will be denoted by \\(\\tilde{P}_{n}\\), note that \\(\\Vert\\tilde{P}_{n}\\Vert=1\\)\nThe monic orthogonal polynomial corresponding to \\(P_{n}\\) will be denoted by \\(\\pi_{n}\\), the leading coefficient is 1.\nThe monic orthonormal polynomial will be denoted by \\(\\tilde{\\pi}_{n}\\), the leading coefficient is 1 and and \\(\\Vert\\tilde{\\pi}_{n}\\Vert=1\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#recurrence-for-pi_n",
    "href": "orthogonal-polynomials.html#recurrence-for-pi_n",
    "title": "Orthogonal polynomials",
    "section": "Recurrence for \\(\\pi_{n}\\)",
    "text": "Recurrence for \\(\\pi_{n}\\)\nLet \\(\\pi_{n}\\) be a monic orthogonal polynomial of order \\(n\\) with respect to the distribution \\(\\alpha(x)\\) on \\([a,b]\\). Then the leading coefficient \\(k_{n}\\) of \\(\\pi_{n}\\) is the coefficient of \\(x^{n}\\). For a monic orthogonal polynomial \\(k_{n}=1\\). Then, following three term recurrence relation is satisfied by the monic orthogonal polynomials.\n\\[\\pi_{n+1}=\\left(x-\\alpha_{n}\\right)\\pi_{n}-\\beta_{n}\\pi_{n-1},\\quad n=0,1,2\\]\n\\[\\pi_{-1}=0,\\pi_{0}=1\\]\n\\[\\beta_{0}=\\left(1,1\\right)_{d\\lambda}=\\int_{a}^{b}d\\alpha(x)=\\int_{a}^{b}w(x)dx\\]\n\\[\\alpha_{n}=\\frac{\\left(x\\pi_{n},\\pi_{n}\\right)}{\\left(\\pi_{n},\\pi_{n}\\right)}\\]\n\\[\\beta_{n}=\\frac{\\left(\\pi_{n},\\pi_{n}\\right)}{\\left(\\pi_{n-1},\\pi_{n-1}\\right)}=\\frac{\\Vert\\pi_{n}\\Vert^{2}}{\\Vert\\pi_{n-1}\\Vert^{2}}\\]\n\\[\\Vert\\pi_{n}\\Vert^{2}=\\Pi_{i=0}^{n}\\beta_{i}\\]\nFollowing points should be noted\n\n\\(x\\pi_{n}\\) is also a monic polynomial of order \\(n+1\\), therefore,\n\n\\[x\\pi_{n}=\\sum_{m=0}^{n+1}a_{m}\\pi_{m}\\]\nBy comparing the leading coefficient we get \\(a_{n+1}=1\\), therefore, the above relation can be written as\n\\[x\\pi_{n}=\\pi_{n+1}+\\sum_{m=0}^{n}a_{m}\\pi_{m}\\]\nTherefore,\n\\[\\left(x\\pi_{n},\\pi_{n+1}\\right)=\\left(\\pi_{n},x\\pi_{n+1}\\right)=\\left(\\pi_{n+1},\\pi_{n+1}\\right)=\\Vert\\pi_{n+1}\\Vert^{2}=h_{n+1}\\]\nWe obtain the above mentioned expression for \\(\\alpha_{n}\\) by following process:\n\\[\\left(\\pi_{n+1},\\pi_{n}\\right)=\\left(x\\pi_{n},\\pi_{n}\\right)-\\alpha_{n}\\left(\\pi_{n},\\pi_{n}\\right)-\\beta_{n}\\left(\\pi_{n-1},\\pi_{n}\\right)\\]\n\\[\\alpha_{n}=\\frac{\\left(x\\pi_{n},\\pi_{n}\\right)}{\\left(\\pi_{n},\\pi_{n}\\right)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#recurrence-for-tildepi_n",
    "href": "orthogonal-polynomials.html#recurrence-for-tildepi_n",
    "title": "Orthogonal polynomials",
    "section": "Recurrence for \\(\\tilde{\\pi}_{n}\\)",
    "text": "Recurrence for \\(\\tilde{\\pi}_{n}\\)\nMonic polynomials \\(\\pi_{n}\\) are not orthonormal, that is \\(\\Vert\\pi_{n}\\Vert\\ne1\\), however, one can obtain the monic orthonormal polynomials, denoted by \\(\\tilde{\\pi}_{n}\\), as shown below:\n\\[\\pi_{n}=\\Vert\\pi_{n}\\Vert\\tilde{\\pi}_{n}\\]\nConsequently, the three term recurrence relation for monic orthonormal polynomial can be obtained.\n\\[\\tilde{\\pi}_{n+1}=\\frac{\\left(x-\\alpha_{n}\\right)}{\\sqrt{\\beta_{n+1}}}\\tilde{\\pi}_{n}-\\frac{\\beta_{n}}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\\]\nwith\n\\[\\tilde{\\pi}_{-1}=0,\\tilde{\\pi}_{0}=1\\]\nor\n\\[\\tilde{\\pi}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{\\pi}_{n}-\\beta_{n}s_{n}^{b}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\\]\nwhere,\n\\[s_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\\]\n\\[s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#recurrence-for-p_n",
    "href": "orthogonal-polynomials.html#recurrence-for-p_n",
    "title": "Orthogonal polynomials",
    "section": "Recurrence for \\(p_{n}\\)",
    "text": "Recurrence for \\(p_{n}\\)\n\\(p_{n}\\) is neither monic nor orthonormal. The leading coefficient of \\(p_{n}\\) is \\(k_{n}.\\) The relationship between \\(p_{n}\\) and \\(\\pi_{n}\\)is given by:\n\\[p_{n}=k_{n}\\pi_{n}\\]\nConsequently, following recurrence relation is obtained for \\(p_{n}\\):\n\\[\\frac{p_{n+1}}{k_{n+1}}=\\left(x-\\alpha_{n}\\right)\\frac{p_{n}}{k_{n}}-\\beta_{n}\\frac{p_{n-1}}{k_{n-1}},\\quad n=0,1,2\\]\nwith\n\\[p_{-1}=0,p_{0}=1\\]\n\\[p_{n+1}=\\left(x-\\alpha_{n}\\right)\\frac{k_{n+1}}{k_{n}}p_{n}-\\beta_{n}\\frac{k_{n+1}}{k_{n-1}}p_{n-1},\\quad n=0,1,2\\]\n\\[p_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}p_{n}-\\beta_{n}s_{n}^{b}p_{n-1},\\quad n=0,1,2\\]\n\\[s_{n}^{a}=\\frac{k_{n+1}}{k_{n}}\\]\n\\[s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#recurrence-for-tildep_n",
    "href": "orthogonal-polynomials.html#recurrence-for-tildep_n",
    "title": "Orthogonal polynomials",
    "section": "Recurrence for \\(\\tilde{p}_{n}\\)",
    "text": "Recurrence for \\(\\tilde{p}_{n}\\)\nThe orthonormal polynomial \\(\\tilde{p}_{n}\\) is given by\n\\[p_{n}=\\Vert p_{n}\\Vert\\tilde{p}_{n}=\\sqrt{h_{n}}\\tilde{p}_{n}\\]\n\\[\\tilde{p}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}p_{n}-\\beta_{n}s_{n}^{b}\\tilde{p}_{n-1},\\quad n=0,1,2\\]\nwith\n\\[\\tilde{p}_{-1}=0,\\tilde{p}_{0}=1,\\]\n\\[s_{n}^{a}=\\frac{k_{n+1}}{k_{n}}\\sqrt{\\frac{h_{n}}{h_{n+1}}}\\]\n\\[s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#kernel-polynomial",
    "href": "orthogonal-polynomials.html#kernel-polynomial",
    "title": "Orthogonal polynomials",
    "section": "Kernel polynomial",
    "text": "Kernel polynomial\nLet \\(p_{0,}\\cdots p_{n}\\) be the orthogonal polynomials, then the kernel polynomial \\(K_{n}(x,y)\\) is given by\n\\[K_{n}(x,y):=\\sum_{m=0}^{n}\\frac{p_{m}(x)p_{m}(y)}{h_{m}}\\]\nwhere, \\(h_{m}=\\Vert p_{m}\\Vert^{2}.\\)\nKernel polynomial satisfies has following important properties.\n\\[K_{n}(x,x)&gt;0\\]\nIf\n\\[s_{n}(x)=\\sum_{m=0}^{n}f_{m}p_{m}(x)=\\int_{a}^{b}f(y)K_{n}(x,y)dy\\]\n\nTheorem: \\(\\forall q\\in\\mathcal{P}^{n}\\)following is true:\n\\[q(x)=\\int_{a}^{b}q(y)K_{n}(x,y)dy\\]\n\nMoreover, the polynomial sequence \\(\\left\\{ K_{n}\\left(x,a\\right)\\right\\}\\) is orthogonal with respect to the weight function \\(\\left(x-a\\right)w(x),\\) and the sequence \\(\\left\\{ K_{n}\\left(x,b\\right)\\right\\}\\) is orthogonal with respect to the \\(\\left(x-b\\right)w(x),\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#christoff-darboux-formula",
    "href": "orthogonal-polynomials.html#christoff-darboux-formula",
    "title": "Orthogonal polynomials",
    "section": "Christoff-Darboux formula",
    "text": "Christoff-Darboux formula\n\\[K_{n}(x,y):=\\sum_{m=0}^{n}\\frac{p_{m}(x)p_{m}(y)}{h_{m}}=\\frac{k_{n}}{k_{n+1}}\\frac{p_{n+1}(x)p_{n}(y)-p_{n}(x)p_{n+1}(y)}{\\left(x-y\\right)h_{n}}\\]\nor\n\\[\\frac{p_{n+1}(x)p_{n}(y)-p_{n}(x)p_{n+1}(y)}{\\left(x-y\\right)}=\\frac{k_{n+1}h_{n}}{k_{n}}\\sum_{m=0}^{n}\\frac{p_{m}(x)p_{m}(y)}{h_{m}}\\]\n\\[\\frac{p_{n+1}(x)p_{n}(y)-p_{n}(x)p_{n+1}(y)}{\\left(x-y\\right)}=\\frac{k_{n+1}h_{n}}{k_{n}}K_{n}(x,y)\\]\nor\n\\[K_{n}(x,y)=\\frac{k_{n}}{k_{n+1}h_{n}}\\frac{p_{n+1}(x)p_{n}(y)-p_{n}(x)p_{n+1}(y)}{\\left(x-y\\right)}\\]\n\\[K_{n}(x,x)=\\frac{k_{n}}{k_{n+1}h_{n}}\\left(\\frac{dp_{n+1}}{dx}p_{n}(x)-\\frac{dp_{n}(x)}{dx}p_{n+1}(x)\\right)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#zeros-of-orthogonal-polynomials",
    "href": "orthogonal-polynomials.html#zeros-of-orthogonal-polynomials",
    "title": "Orthogonal polynomials",
    "section": "Zeros of orthogonal polynomials",
    "text": "Zeros of orthogonal polynomials\nZeros of orthogonal polynomials are chosen as the nodes of Gauss-type quadratures. These zeros are also used to generate computational grids for spectral methods. Let \\(\\left\\{ p_{n}\\right\\}\\) be a sequence of polynomials orthogonal with respect to the weight function \\(w(x)\\) in \\([a,b]\\).\n\nTheorem: Zeros of \\(p_{n+1}\\)are all real, unique, and distributed between \\(\\left[a,b\\right].\\)\nTheorem: Let zeros of \\(p_{n}\\) be denoted by \\(x_{1}&lt;x_{2}&lt;\\cdots&lt;x_{n},\\)let \\(x_{0}=a\\) and \\(x_{n+1}=b\\), let \\(I_{m}=\\left(x_{m},x_{m+1}\\right)\\), for \\(m=0,1,\\cdots n\\) be n interval, then each \\(I_{m}\\) contains exactly one zero of \\(p_{n+1}\\).\nTheorem Let \\(\\left\\{ p_{n}\\right\\}\\)be a sequence of orthogonal polynomials, then the zeros of \\(\\frac{dp_{n}}{dx}\\) are real, and there exists exactly one zeros of \\(\\frac{dp_{n}}{dx}\\) between two consecutives zeros of \\(p_{n}.\\)\n\nThe zeros \\(\\left\\{ x_{j}\\right\\} _{j=0}^{n}\\) of orthogonal polynomial \\(p_{n+1}\\), which satisfies the following recurrence relation\n\\[p_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}p_{n}-\\beta_{n}s_{n}^{b}p_{n-1},\\quad n=0,1,2\\]\nwith \\(p_{-1}=0,p_{0}=1\\), and \\(s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\\)\nare eigenvalues of the following symmetric tridiagonal matrix (Jacobi matrix):\n\\[{\\bf J}_{n+1}=\\left[\\begin{array}{ccccc}\n\\alpha_{0} & \\sqrt{\\beta_{1}}\\\\\n\\sqrt{\\beta_{1}} & \\alpha_{1} & \\sqrt{\\beta_{2}}\\\\\n& \\sqrt{\\beta_{2}} & \\ddots & \\ddots\\\\\n&  & \\ddots & \\alpha_{n-1} & \\sqrt{\\beta_{n}}\\\\\n&  &  & \\sqrt{\\beta_{n}} & \\alpha_{n}\n\\end{array}\\right]\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomials.html#gauss-quadrature",
    "href": "orthogonal-polynomials.html#gauss-quadrature",
    "title": "Orthogonal polynomials",
    "section": "Gauss-Quadrature",
    "text": "Gauss-Quadrature\nLet \\(d\\alpha\\) be a measure with bounded or unbounded support \\([a,b]\\). An n-point quadrature rule for the measure \\(d\\alpha\\) is given by\n\\[\\int_{a}^{b}f(x)d\\alpha(x)=\\sum_{m=1}^{n}f(x_{j})w_{j}+R_{n}(f)\\]\nwhere the sum on the right provides an approximation to the integral on the left and \\(R_{n}\\)is the error of such numerical integration. The set \\(\\left\\{ x_{j}\\right\\} _{j=1}^{n}\\) contains n distinct points in \\([a,b]\\) and called the quadrature points, and \\(\\left\\{ w_{j}\\right\\} _{j=1}^{n}\\)contains n positive numbers, which are called weight of the quadrature points.\nThe above quadrature rule is said to have degree of exactness (DOE) \\(d\\) if \\(R_{n}(p)=0\\) for \\(p\\in\\mathcal{P}^{d}\\). It is said to have precise DOE d if it has DOE \\(d\\) but not \\(d+1\\). A quadrature rule with DOE \\(d=n-1\\) is called interpolatory. Usually, \\(n\\) points have DOE of \\(d=n-1\\). But we want to find \\(n\\) points such that we can achieve maximum valuea of DOE. Such points corresponds to the Gauss-Quadrature.\n\nTheorem (Gauss-Quadrature): Let \\(\\left\\{ x_{m}\\right\\} _{m=1}^{n}\\) be the set if zeros of the orthogonal polynomial \\(p_{n}\\). Then there exists a unique set of quadrature weights \\(\\left\\{ w_{m}\\right\\} _{m=1}^{n}\\) such that \\[\\int_{a}^{b}p(x)w(x)dx=\\sum_{m=1}^{n}p(x_{m})w_{m},\\forall p\\in P_{2n-1}\\] \\(N\\) point Gauss-Quadrature rule has DOE \\(d=2N-1\\)\n\n\nTheorem (Gauss-Left-Radau): Let \\(x_{1}=a\\), and \\(\\left\\{ x_{m}\\right\\} _{m=2}^{n}\\) be the \\(n-1\\) zeros of the orthogonal polynomial \\(q_{n-1}\\in\\mathcal{P}^{n-1}\\) given by \\[q_{n-1}=\\frac{p_{n}+\\alpha_{n-1}p_{n-1}}{x-a}\\] with \\(\\alpha_{n-1}=-\\frac{p_{n}(a)}{p_{n-1}(a)}\\), then there exists a unique set of quadrature weights \\(\\left\\{ w_{m}\\right\\} _{m=1}^{n}\\) such that \\[\\int_{a}^{b}p(x)w(x)dx=\\sum_{m=1}^{n}p(x_{m})w_{m},\\forall p\\in P_{2n-2}\\] \\(N\\) point Gauss-Radau rule has DOE \\(d=2N-2\\)\n\n\nTheorem (Gauss-Right-Radau): Let \\(x_{n}=b\\), and \\(\\left\\{ x_{m}\\right\\} _{m=1}^{n-1}\\) be the zeros of the orthogonal polynomial \\(q_{n-1}\\in\\mathcal{P}^{n-1}\\) given by \\[q_{n-1}=\\frac{p_{n}+\\alpha_{n-1}p_{n-1}}{x-b}\\] with \\(\\alpha_{n-1}=-\\frac{p_{n}(b)}{p_{n-1}(b)}\\), then there exists a unique set of quadrature weights \\(\\left\\{ w_{m}\\right\\} _{m=1}^{n}\\) such that \\[\\int_{a}^{b}p(x)w(x)dx=\\sum_{m=1}^{n}p(x_{m})w_{m},\\forall p\\in P_{2n-2}\\] \\(N\\) point Gauss-Radau rule has DOE \\(d=2N-2\\)\n\n\nTheorem (Gauss-Lobatto): Let \\(x_{1}=a,x_{n}=b\\), and \\(\\left\\{ x_{m}\\right\\} _{m=2}^{n-1}\\) be the \\(n-2\\) zeros of the orthogonal polynomial \\(z_{n-2}\\in\\mathcal{P}^{n-2}\\) given by \\[z_{n-2}=\\frac{p_{n}+\\alpha_{n-1}p_{n-1}+\\beta_{n-1}p_{n-2}}{\\left(x-a\\right)\\left(b-x\\right)}\\] with \\(\\alpha_{n-1},\\beta_{n-1}\\), such \\(p_{n}+\\alpha_{n-1}p_{n-1}+\\beta_{n-1}p_{n-2}=0\\) at \\(x=a,b\\), then there exists a unique set of quadrature weights \\(\\left\\{ w_{m}\\right\\} _{m=1}^{n}\\) such that \\[\\int_{a}^{b}p(x)w(x)dx=\\sum_{m=1}^{n}p(x_{m})w_{m},\\forall p\\in P_{2n-3}\\] \\(N\\) point Gauss-Lobatto rule has DOE \\(d=2N-3\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Orthogonal polynomials</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html",
    "href": "jacobi-polynomials.html",
    "title": "Jacobi polynomial",
    "section": "",
    "text": "Leading coefficient\nJacobi polynomial of order \\(n\\) is denoted by \\(P_{n}^{(\\alpha,\\beta)}\\left(x\\right)\\).\nHere \\(\\alpha\\) and \\(\\beta\\) are parameters of Jacobi polynomial. Note that\n\\[1+\\alpha&gt;0,\\quad1+\\beta&gt;0\\]\nThe Jacobi polynomials are orthogonal with respect to the following weight function.\n\\[w(x)=(1-x)^{\\alpha}(1+x)^{\\beta}\\]\nThe support of Jacobi polynomial is \\([-1,1].\\)\nThe leading coefficient of \\(P_{n}^{(\\alpha,\\beta)}\\) is denoted by \\(k_{n}\\) and it is given by\n\\[k_{n}=\\frac{1}{2^{n}}\\left(\\begin{array}{c}\n2n+\\alpha+\\beta\\\\\nn\n\\end{array}\\right)=\\frac{1}{2^{n}}\\frac{\\Gamma\\left(2n+\\alpha+\\beta+1\\right)}{n!\\Gamma\\left(n+\\alpha+\\beta+1\\right)}\\]\n\\[\\frac{k_{n+1}}{k_{n}}=\\frac{1}{2}\\left(\\frac{2n+\\alpha+\\beta+2}{n+1}\\right)\\left(\\frac{2n+\\alpha+\\beta+1}{n+\\alpha+\\beta+1}\\right)\\]\n\\[\\frac{k_{1}}{k_{0}}=\\frac{1}{2}\\left(\\alpha+\\beta+2\\right)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#norm",
    "href": "jacobi-polynomials.html#norm",
    "title": "Jacobi polynomial",
    "section": "Norm",
    "text": "Norm\nThe norm of \\(P_{n}^{(\\alpha,\\beta)}\\) is given below:\n\\[\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert^{2}=:h_{n}^{(\\alpha,\\beta)}=\\frac{2^{\\alpha+\\beta+1}}{2n+\\alpha+\\beta+1}\\frac{\\Gamma(n+\\alpha+1)\\Gamma(n+\\beta+1)}{n!\\Gamma(n+\\alpha+\\beta+1)}\\]\n\\[\\frac{h_{n-1}^{(\\alpha,\\beta)}}{h_{n}^{(\\alpha,\\beta)}}=\\begin{cases}\n\\frac{3+\\alpha+\\beta}{\\left(1+\\alpha\\right)\\left(1+\\beta\\right)} & n=1\\\\\n\\frac{n\\left(2n+\\alpha+\\beta+1\\right)\\left(n+\\alpha+\\beta\\right)}{\\left(2n+\\alpha+\\beta-1\\right)\\left(n+\\alpha\\right)\\left(n+\\beta\\right)} & n&gt;1\n\\end{cases}\\]\n\\[\\frac{h_{n+1}^{(\\alpha,\\beta)}}{h_{n}^{(\\alpha,\\beta)}}=\\begin{cases}\n\\frac{\\left(1+\\alpha\\right)\\left(1+\\beta\\right)}{\\left(3+\\alpha+\\beta\\right)} & n=0\\\\\n\\frac{\\left(2n+\\alpha+\\beta+1\\right)\\left(n+\\alpha+1\\right)\\left(n+\\beta+1\\right)}{\\left(n+1\\right)\\left(2n+\\alpha+\\beta+3\\right)\\left(n+\\alpha+\\beta+1\\right)} & n\\ge1\n\\end{cases}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#scaling",
    "href": "jacobi-polynomials.html#scaling",
    "title": "Jacobi polynomial",
    "section": "Scaling",
    "text": "Scaling\nJacobi polynomials are scaled such that the value of \\(P_{n}^{(\\alpha,\\beta)}\\) at \\(x=1\\) is given by\n\\[P_{n}^{(\\alpha,\\beta)}(1)=\\frac{\\Gamma(n+\\alpha+1)}{n!\\Gamma(1+\\alpha)}=\\left(\\begin{array}{c}\nn+\\alpha\\\\\nn\n\\end{array}\\right)\\]\n\\[P_{n}^{(\\alpha,\\beta)}\\left(-1\\right)=\\left(-1\\right)^{n}\\frac{\\Gamma(n+\\beta+1)}{n!\\Gamma(1+\\beta)}=\\left(-1\\right)^{n}\\left(\\begin{array}{c}\nn+\\beta\\\\\nn\n\\end{array}\\right)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#symmetry",
    "href": "jacobi-polynomials.html#symmetry",
    "title": "Jacobi polynomial",
    "section": "Symmetry",
    "text": "Symmetry\nSymmetry of Jacobi polynomial depends upon \\(n\\) and \\(\\alpha,\\beta\\) as shown below.\n\\[P_{n}^{(\\alpha,\\beta)}(x)=\\left(-1\\right)^{n}P_{n}^{(\\beta,\\alpha)}(-x)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#scaling-1",
    "href": "jacobi-polynomials.html#scaling-1",
    "title": "Jacobi polynomial",
    "section": "Scaling",
    "text": "Scaling",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#boundedness",
    "href": "jacobi-polynomials.html#boundedness",
    "title": "Jacobi polynomial",
    "section": "Boundedness",
    "text": "Boundedness",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#derivatives",
    "href": "jacobi-polynomials.html#derivatives",
    "title": "Jacobi polynomial",
    "section": "Derivatives",
    "text": "Derivatives\nDerivative of Jacobi polynomial \\(P_{n}^{(\\alpha,\\beta)}\\) is also a Jacobi Polynomial of order \\(n-1\\) and parameter \\(\\alpha+1\\) and \\(\\beta+1\\).\n\\[\\frac{dP_{n}^{(\\alpha,\\beta)}}{dx}=\\frac{1}{2}\\left(n+\\alpha+\\beta+1\\right)P_{n-1}^{\\left(\\alpha+1,\\beta+1\\right)}\\]\nDerivative of \\(P_{n}^{(\\alpha,\\beta)}\\) is also a Jacobi Polynomial of order \\(n-k\\) and parameters \\(\\alpha+k\\) and \\(\\beta+k\\).\n\\[\\frac{d^{k}P_{n}^{(\\alpha,\\beta)}}{dx^{k}}=\\frac{\\Gamma\\left(n+k+\\alpha+\\beta+1\\right)}{2^{k}\\Gamma\\left(n+\\alpha+\\beta+1\\right)}P_{n-k}^{\\left(\\alpha+k,\\beta+k\\right)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#orthogonality",
    "href": "jacobi-polynomials.html#orthogonality",
    "title": "Jacobi polynomial",
    "section": "Orthogonality",
    "text": "Orthogonality",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#polynomial-representation",
    "href": "jacobi-polynomials.html#polynomial-representation",
    "title": "Jacobi polynomial",
    "section": "Polynomial representation",
    "text": "Polynomial representation\n\\(P_{n}^{(\\alpha,\\beta)}\\) can be expressed as\n\\[\nP_{n}^{(\\alpha,\\beta)}(x)=\\sum_{k=0}^{n}a_{k}^{n}(x-1)^{k}\n\\]\nwhere,\n\\[\n\\frac{a_{k+1}^{n}}{a_{k}^{n}}=\\frac{h_{n}^{(\\alpha,\\beta)}-k\\left(k+\\alpha+\\beta+1\\right)}{2(k+1)(k+\\alpha+1)}\n\\]\nwith\n\\[\na_{0}^{n}=P_{n}^{(\\alpha,\\beta)}(1)=\\frac{\\Gamma(n+\\alpha+1)}{n!\\Gamma(1+\\alpha)}=\\left(\\begin{array}{c}\nn+\\alpha\\\\\nn\n\\end{array}\\right)\n\\]\nTherefore, we can expand Jacobi polynomial by\n\\[\nP_{n}^{(\\alpha,\\beta)}(x)=\\frac{\\Gamma(n+\\alpha+1)}{n!\\Gamma(n+\\alpha+\\beta+1)}\\sum_{k=0}^{n}\\left(\\begin{array}{c}\nn\\\\\nk\n\\end{array}\\right)\\frac{\\Gamma\\left(n+k+\\alpha+\\beta+1\\right)}{\\Gamma\\left(k+\\alpha+1\\right)}\\left(\\frac{x-1}{2}\\right)^{k}\n\\]\nThere is another representation:\n\\[\nP_{n}^{(\\alpha,\\beta)}(x)=\\frac{1}{2^{n}}\\sum_{k=0}^{n}\\left(\\begin{array}{c}\nn+\\alpha\\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nn+\\beta\\\\\nn-k\n\\end{array}\\right)\\left(x-1\\right)^{n-k}\\left(x+1\\right)^{k}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#strum-liovile-equation",
    "href": "jacobi-polynomials.html#strum-liovile-equation",
    "title": "Jacobi polynomial",
    "section": "Strum-Liovile equation",
    "text": "Strum-Liovile equation\n\\(P_{n}^{(\\alpha,\\beta)}\\) is solution of following Strum-Liovile differential equation:\n\\[\n\\frac{1}{\\left(1-x\\right)^{\\alpha}\\left(1+x\\right)^{\\beta}}\\frac{d}{dx}\\left(\\left(1-x\\right)^{\\alpha+1}\\left(1+x\\right)^{\\beta+1}\\frac{dy}{dx}\\right)+n\\left(n+\\alpha+\\beta+1\\right)y=0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#rodriguess-formula",
    "href": "jacobi-polynomials.html#rodriguess-formula",
    "title": "Jacobi polynomial",
    "section": "Rodrigues’s Formula",
    "text": "Rodrigues’s Formula\n\\[\n\\left(1-x\\right)^{\\alpha}\\left(1+x\\right)^{\\beta}P_{n}^{(\\alpha,\\beta)}(x)=\\frac{\\left(-1\\right)^{n}}{2^{n}n!}\\frac{d^{n}}{dx^{n}}\\left[\\left(1-x\\right)^{n+\\alpha}\\left(1+x\\right)^{n+\\beta}\\right]\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-monic-jacobi-polynomials",
    "href": "jacobi-polynomials.html#recurrence-relation-for-monic-jacobi-polynomials",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for monic Jacobi polynomials",
    "text": "Recurrence relation for monic Jacobi polynomials\nLet \\(\\pi_{n}^{(\\alpha,\\beta)}\\) be the monic Jacobi polynomials, the three-term reccurence relationship for monic polynomial:\n\\[\\pi_{n+1}^{(\\alpha,\\beta)}=\\left(x-\\alpha_{n}\\right)\\pi_{n}^{(\\alpha,\\beta)}-\\beta_{n}\\pi_{n-1}^{(\\alpha,\\beta)},\\quad n=0,1,2\\]\n\\[\\beta_{0}=2^{\\alpha+\\beta+1}\\frac{\\Gamma(\\alpha+1)\\Gamma(\\beta+1)}{\\Gamma(\\alpha+\\beta+2)}\\]\n\\[\\beta_{1}=\\frac{4(1+\\alpha)(1+\\beta)}{(2+\\alpha+\\beta)^{2}(3+\\alpha+\\beta)}\\]\n\\[\\beta_{n\\ge2}=\\frac{4n(n+\\alpha)(n+\\beta)(n+\\alpha+\\beta)}{(2n+\\alpha+\\beta)^{2}(2n+\\alpha+\\beta+1)(2n+\\alpha+\\beta-1)}\\]\n\\[\\alpha_{0}=\\frac{\\beta-\\alpha}{\\alpha+\\beta+2}\\]\n\\[\\alpha_{n\\ge1}=\\frac{\\beta^{2}-\\alpha^{2}}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+2)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-monic-orthonormal-jacobi-polynomials",
    "href": "jacobi-polynomials.html#recurrence-relation-for-monic-orthonormal-jacobi-polynomials",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for monic orthonormal Jacobi polynomials",
    "text": "Recurrence relation for monic orthonormal Jacobi polynomials\nLet \\(\\tilde{\\pi}_{n}^{(\\alpha,\\beta)}\\) be the monic orthonormal Jacobi polynomials, the three-term reccurence relationship:\n\\[\\tilde{\\pi}_{n+1}^{(\\alpha,\\beta)}=\\frac{\\left(x-\\alpha_{n}\\right)}{\\sqrt{\\beta_{n+1}}}\\tilde{\\pi}_{n}^{(\\alpha,\\beta)}-\\frac{\\beta_{n}}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\tilde{\\pi}_{n-1}^{(\\alpha,\\beta)},\\quad n=0,1,2\\]\nor\n\\[\\tilde{\\pi}_{n+1}^{(\\alpha,\\beta)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{\\pi}_{n}^{(\\alpha,\\beta)}-\\beta_{n}s_{n}^{b}\\tilde{\\pi}_{n-1}^{(\\alpha,\\beta)},\\quad n=0,1,2\\]\n\\[s_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\\]\n\\[s_{n}^{b}=\\frac{1}{\\sqrt{\\beta_{n}\\beta_{n+1}}}=s_{n}^{a}s_{n-1}^{a}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-jacobi-polynomial",
    "href": "jacobi-polynomials.html#recurrence-relation-for-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for Jacobi polynomial",
    "text": "Recurrence relation for Jacobi polynomial\nLet \\(P_{n}^{(\\alpha,\\beta)}\\) be the Jacobi polynomial with initial values:\n\\[P_{-1}^{(\\alpha,\\beta)}=0\\]\n\\[P_{0}^{(\\alpha,\\beta)}=1\\]\n\\[P_{1}^{(\\alpha,\\beta)}=\\frac{1}{2}\\left(\\alpha+\\beta+2\\right)x+\\frac{1}{2}\\left(\\alpha-\\beta\\right)\\]\nthen, the three term recurrence relationship is given by:\n\\[P_{n+1}^{(\\alpha,\\beta)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}P_{n}^{(\\alpha,\\beta)}-\\beta_{n}s_{n}^{b}P_{n-1}^{(\\alpha,\\beta)},\\quad n=0,1,2\\]\nwhere,\n\\[s_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{1}{2}\\left(\\frac{2n+\\alpha+\\beta+2}{n+1}\\right)\\left(\\frac{2n+\\alpha+\\beta+1}{n+\\alpha+\\beta+1}\\right)\\]\n\\[s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\\]\n\\[s_{0}^{a}=\\frac{k_{1}}{k_{0}}=\\frac{1}{2}\\left(\\alpha+\\beta+2\\right)\\]\n\\[s_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\\]\nAlternatively, we can write the three term relationship as:\n\\[P_{n+1}^{(\\alpha,\\beta)}=\\left(a_{n}x+b_{n}\\right)P_{n}^{(\\alpha,\\beta)}-c_{n}P_{n-1}^{(\\alpha,\\beta)},\\quad n=1,2,\\cdots\\]\n\\[a_{n}=s_{n}^{a}=\\frac{\\left(2n+\\alpha+\\beta+2\\right)\\left(2n+\\alpha+\\beta+1\\right)}{2\\left(n+1\\right)\\left(n+\\alpha+\\beta+1\\right)}\\]\n\\[b_{n}=-\\alpha_{n}s_{n}^{a}=\\frac{\\left(\\alpha^{2}-\\beta^{2}\\right)\\left(2n+\\alpha+\\beta+1\\right)}{2\\left(n+1\\right)\\left(n+\\alpha+\\beta+1\\right)\\left(2n+\\alpha+\\beta\\right)}\\]\n\\[c_{n}=\\beta_{n}s_{n}^{a}s_{n-1}^{a}=\\frac{\\left(n+\\alpha\\right)\\left(n+\\beta\\right)\\left(2n+\\alpha+\\beta+2\\right)}{\\left(n+1\\right)\\left(n+\\alpha+\\beta+1\\right)\\left(2n+\\alpha+\\beta\\right)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-orthonormal-jacobi-polynomials",
    "href": "jacobi-polynomials.html#recurrence-relation-for-orthonormal-jacobi-polynomials",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for orthonormal Jacobi polynomials",
    "text": "Recurrence relation for orthonormal Jacobi polynomials\nLet \\(\\tilde{P}_{n}^{(\\alpha,\\beta)}\\) be the orthonormal Jacobi polynomials, then the recurrence relationship is given by: \\[\\tilde{P}_{n+1}^{(\\alpha,\\beta)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{P}_{n}^{(\\alpha,\\beta)}-\\beta_{n}s_{n}^{b}\\tilde{P}_{n-1}^{(\\alpha,\\beta)},\\quad n=0,1,2\\]\n\\[s_{n}^{a}=\\frac{k_{n+1}}{k_{n}}\\frac{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n+1}^{(\\alpha,\\beta)}\\Vert}\\]\n\\[\\begin{aligned}s_{n}^{b} & =\\frac{k_{n+1}}{k_{n-1}}\\frac{\\Vert P_{n-1}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n+1}^{(\\alpha,\\beta)}\\Vert}\\\\\n& =\\frac{k_{n+1}}{k_{n-1}}\\frac{k_{n}}{k_{n}}\\frac{\\Vert P_{n-1}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n+1}^{(\\alpha,\\beta)}\\Vert}\\frac{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}\\\\\n& =\\frac{k_{n+1}}{k_{n}}\\frac{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n+1}^{(\\alpha,\\beta)}\\Vert}\\frac{k_{n}}{k_{n-1}}\\frac{\\Vert P_{n-1}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}\\\\\n& =s_{n}^{a}s_{n-1}^{a}\n\\end{aligned}\\]\n\\[\\frac{\\Vert\\pi_{n}\\Vert}{\\Vert\\pi_{n-1}\\Vert}=\\frac{k_{n-1}\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{k_{n}\\Vert P_{n-1}^{(\\alpha,\\beta)}\\Vert}=\\sqrt{\\beta_{n}}\\]\n\\[\\frac{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n-1}^{(\\alpha,\\beta)}\\Vert}=\\frac{k_{n}}{k_{n-1}}\\sqrt{\\beta_{n}}\\]\n\\[\\frac{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert}{\\Vert P_{n+1}^{(\\alpha,\\beta)}\\Vert}=\\frac{k_{n}}{k_{n+1}\\sqrt{\\beta_{n+1}}}\\]\n\\[\\begin{aligned}s_{n}^{a} & =\\frac{k_{n+1}}{k_{n}}\\frac{k_{n}}{k_{n+1}\\sqrt{\\beta_{n+1}}}\\\\\n& =\\frac{1}{\\sqrt{\\beta_{n+1}}}\n\\end{aligned}\\]\n\\[s_{n}^{b}=s_{n}^{a}s_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\]\n\\[s_{0}^{b}=\\frac{1}{\\sqrt{\\beta_{1}}}\\frac{1}{\\sqrt{\\beta_{0}}}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-jacobi-polynomial",
    "href": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for derivative of Jacobi polynomial",
    "text": "Recurrence relation for derivative of Jacobi polynomial\n\\[\nP_{n+1}^{\\alpha,\\beta}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}P_{n}^{\\alpha,\\beta}-\\beta_{n}s_{n}^{b}P_{n-1}^{\\alpha,\\beta}\n\\]\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{1}{2}\\left(\\frac{2n+\\alpha+\\beta+2}{n+1}\\right)\\left(\\frac{2n+\\alpha+\\beta+1}{n+\\alpha+\\beta+1}\\right)\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\nThen gradient can be computed by following recurrence relationship:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)s_{n-1}^{a}P_{n-1}^{\\alpha,\\beta}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)P_{n}^{\\alpha,\\beta}\n\\]\n\\[\n\\left(\\frac{dP_{n}}{dx}\\right)_{x=1}=\\frac{1}{2}\\left(n+\\alpha+\\beta+1\\right)\\frac{\\Gamma\\left(n+\\alpha+1\\right)}{\\left(n-1\\right)!\\Gamma\\left(\\alpha+2\\right)}\n\\]\n\\[\n\\left(\\frac{dP_{n}}{dx}\\right)_{x=-1}=\\left(-1\\right)^{n-1}\\frac{1}{2}\\left(n+\\alpha+\\beta+1\\right)\\frac{\\Gamma\\left(n+\\beta+1\\right)}{\\left(n-1\\right)!\\Gamma\\left(\\beta+2\\right)}\n\\]\nProof: It is know that\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=A_{n}P_{n-1}^{\\alpha,\\beta}+B_{n}P_{n}^{\\alpha,\\beta}-C_{n}P_{n+1}^{\\alpha,\\beta}\n\\]\nwith\n\\[\nA_{n}=\\frac{2(n+\\alpha)(n+\\beta)(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+1)}\n\\]\n\\[\nB_{n}=\\frac{(\\alpha-\\beta)2n(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+2)}\n\\]\n\\[\nC_{n}=\\frac{2n(n+1)(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta+1)(2n+\\alpha+\\beta+2)}\n\\]\nUsing recurrence relationship for \\(P_{n+1}^{\\alpha,\\beta}\\), we obtain:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=\\left(A_{n}+\\beta_{n}C_{n}s_{n}^{b}\\right)P_{n-1}^{\\alpha,\\beta}+\\left[B_{n}-C_{n}\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\right]P_{n}^{\\alpha,\\beta}\n\\]\nNoting that,\\(P_{n}^{\\alpha,\\beta}\\)\n\\[\nC_{n}s_{n}^{b}=ns_{n-1}^{a},\\text{ or }C_{n}=\\frac{n}{s_{n}^{a}}\n\\]\nBy using these relationship:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=\\left(A_{n}+n\\beta_{n}s_{n-1}^{a}\\right)P_{n-1}^{\\alpha,\\beta}+\\left(B_{n}-n\\left(x-\\alpha_{n}\\right)\\right)P_{n}^{\\alpha,\\beta}\n\\]\nNow note that\n\\[\nn\\beta_{n}s_{n-1}^{a}=\\frac{2n\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)\\left(2n+\\alpha+\\beta+1\\right)}\n\\]\n\\[\nA_{n}+n\\beta_{n}s_{n-1}^{a}=\\frac{2\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)}\n\\]\nand\n\\[\nB_{n}+n\\alpha_{n}=\\frac{n(\\alpha-\\beta)}{\\left(2n+\\alpha+\\beta\\right)}\n\\]\nThe above recurrence simplifies to:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=\\frac{2\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)}P_{n-1}^{\\alpha,\\beta}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)P_{n}^{\\alpha,\\beta}\n\\]\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)s_{n-1}^{a}P_{n-1}^{\\alpha,\\beta}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)P_{n}^{\\alpha,\\beta}\n\\]\nThis completes the proof.",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#more-recurrence-relationships-for-derivative-of-jacobi-polynomial",
    "href": "jacobi-polynomials.html#more-recurrence-relationships-for-derivative-of-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "More recurrence relationships for derivative of Jacobi polynomial",
    "text": "More recurrence relationships for derivative of Jacobi polynomial\nThree term recurrence\n\\[\\left(1-x^{2}\\right)\\frac{dP_{n}^{\\alpha,\\beta}}{dx}=A_{n}P_{n-1}^{\\alpha,\\beta}+B_{n}P_{n}^{\\alpha,\\beta}-C_{n}P_{n+1}^{\\alpha,\\beta}\\] with \\[A_{n}=\\frac{2(n+\\alpha)(n+\\beta)(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+1)}\\] \\[B_{n}=\\frac{(\\alpha-\\beta)2n(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+2)}\\] \\[C_{n}=\\frac{2n(n+1)(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta+1)(2n+\\alpha+\\beta+2)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-jacobi-polynomial",
    "href": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for derivative of orthonormal Jacobi polynomial",
    "text": "Recurrence relation for derivative of orthonormal Jacobi polynomial\n\\[\\left(1-x^{2}\\right)\\frac{d\\tilde{P}_{n}^{\\alpha,\\beta}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)s_{n-1}^{a}\\tilde{P}_{n-1}^{\\alpha,\\beta}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\tilde{P}_{n}^{\\alpha,\\beta}\\]\n\\[s_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-monic-jacobi-polynomial",
    "href": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-monic-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for derivative of monic Jacobi polynomial",
    "text": "Recurrence relation for derivative of monic Jacobi polynomial\n\\[\\left(1-x^{2}\\right)\\frac{d\\pi_{n}}{dx}=\\frac{2\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)}\\frac{k_{n-1}}{k_{n}}\\pi_{n-1}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\pi_{n}\\]\n\\[\\begin{aligned}\\frac{2\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)}\\frac{k_{n-1}}{k_{n}} & =\\frac{4n\\left(n+\\alpha\\right)\\left(n+\\beta\\right)\\left(n+\\alpha+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)^{2}\\left(2n+\\alpha+\\beta-1\\right)}\\\\\n& =\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)\n\\end{aligned}\\]\n\\[\\beta_{n\\ge2}=\\frac{4n\\left(n+\\alpha\\right)\\left(n+\\beta\\right)\\left(n+\\alpha+\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)^{2}\\left(2n+\\alpha+\\beta+1\\right)\\left(2n+\\alpha+\\beta-1\\right)}\\]\n\\[\\left(1-x^{2}\\right)\\frac{d\\pi_{n}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)\\pi_{n-1}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\pi_{n}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-jacobi-polynomial",
    "href": "jacobi-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-jacobi-polynomial",
    "title": "Jacobi polynomial",
    "section": "Recurrence relation for derivative of monic orthonormal Jacobi polynomial",
    "text": "Recurrence relation for derivative of monic orthonormal Jacobi polynomial\n\\[\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)\\tilde{\\pi}_{n-1}\\frac{\\Vert\\pi_{n-1}\\Vert}{\\Vert\\pi_{n}\\Vert}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\tilde{\\pi}_{n}\\]\n\\[\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)\\frac{1}{\\sqrt{\\beta_{n}}}\\tilde{\\pi}_{n-1}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\tilde{\\pi}_{n}\\]\n\\[\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}}{dx}=\\beta_{n}\\left(2n+\\alpha+\\beta+1\\right)s_{n-1}^{a}\\tilde{\\pi}_{n-1}+\\left(\\frac{n(\\alpha-\\beta)}{2n+\\alpha+\\beta}-nx\\right)\\tilde{\\pi}_{n}\\]\n\\[s_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#kernel-polynomial",
    "href": "jacobi-polynomials.html#kernel-polynomial",
    "title": "Jacobi polynomial",
    "section": "Kernel polynomial",
    "text": "Kernel polynomial\n\\[K_{n}(x,y):=\\sum_{m=0}^{n}\\frac{P_{m}^{\\alpha,\\beta}(x)P_{m}^{\\alpha,\\beta}(y)}{h_{m}^{\\alpha,\\beta}}\\]\n\\[K_{n}(x,1):=\\sum_{m=0}^{n}\\frac{P_{m}^{\\alpha,\\beta}(1)}{h_{m}^{\\alpha,\\beta}}P_{m}^{\\alpha,\\beta}(x)=d_{n}^{\\alpha,\\beta}P_{n}^{\\alpha+1,\\beta}(x)\\]\n\\[d_{n}^{\\alpha,\\beta}=\\frac{P_{m}^{\\alpha,\\beta}(1)k_{n}^{\\alpha,\\beta}}{k_{n}^{\\alpha+1,\\beta}h_{n}^{\\alpha,\\beta}}=\\frac{1}{2^{\\alpha+\\beta+1}}\\frac{\\Gamma\\left(n+\\alpha+\\beta+2\\right)}{\\Gamma\\left(\\alpha+1\\right)\\Gamma\\left(n+\\beta+1\\right)}\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#more-recurrence-relations",
    "href": "jacobi-polynomials.html#more-recurrence-relations",
    "title": "Jacobi polynomial",
    "section": "More recurrence relations",
    "text": "More recurrence relations\nJacobi polynomial \\(P_{n}^{\\alpha+1,\\beta}(x)\\) is a linear combination of \\(P_{m}^{\\alpha,\\beta}(x),m=0,1,\\cdots n\\), that is\n\\[P_{n}^{\\alpha+1,\\beta}(x)=\\frac{\\Gamma(n+\\beta+1)}{\\Gamma(n+\\alpha+\\beta+2)}\\sum_{m=0}^{n}\\frac{\\left(2m+\\alpha+\\beta+1\\right)\\Gamma\\left(m+\\alpha+\\beta+1\\right)}{\\Gamma(m+\\beta+1)}P_{m}^{\\alpha,\\beta}(x)\\]\nor\n\\[P_{n}^{\\alpha+1,\\beta}(x)=\\frac{2}{\\left(2n+\\alpha+\\beta+2\\right)}\\frac{\\left(n+\\alpha+1\\right)P_{n}^{\\alpha,\\beta}(x)-\\left(n+1\\right)P_{n+1}^{\\alpha,\\beta}(x)}{\\left(1-x\\right)}\\]\nSimilarly,\n\\[P_{n}^{\\alpha,\\beta+1}(x)=\\frac{\\Gamma(n+\\alpha+1)}{\\Gamma(n+\\alpha+\\beta+2)}\\sum_{m=0}^{n}\\left(-1\\right)^{n-m}\\frac{\\left(2m+\\alpha+\\beta+1\\right)\\Gamma\\left(m+\\alpha+\\beta+1\\right)}{\\Gamma(m+\\alpha+1)}P_{m}^{\\alpha,\\beta}(x)\\]\nor\n\\[P_{n}^{\\alpha,\\beta+1}(x)=\\frac{2}{\\left(2n+\\alpha+\\beta+2\\right)}\\frac{\\left(n+\\beta+1\\right)P_{n}^{\\alpha,\\beta}(x)+\\left(n+1\\right)P_{n+1}^{\\alpha,\\beta}(x)}{\\left(1+x\\right)}\\]\n\nRelation between \\(P_{n}^{(\\alpha+1,\\beta+1)}\\) and \\(P_{n}^{\\left(\\alpha,\\beta\\right)}\\) \\[\\begin{aligned}P_{n-1}^{\\alpha+1,\\beta+1}(x) & =P_{n}^{\\alpha+1,\\beta}(x)-P_{n}^{\\alpha,\\beta+1}(x)\\\\\n& =\\frac{2}{\\left(1-x^{2}\\right)}\\left[\\left(\\frac{\\alpha-\\beta}{\\left(2n+\\alpha+\\beta+2\\right)}+x\\right)P_{n}^{\\alpha,\\beta}(x)-\\frac{2n+2}{2n+\\alpha+\\beta+2}P_{n+1}^{\\alpha,\\beta}(x)\\right]\\\\\n& =\\frac{2}{\\left(1-x^{2}\\right)}\\left[\\left(a_{n}+x\\right)P_{n}^{\\alpha,\\beta}(x)-b_{n}P_{n+1}^{\\alpha,\\beta}(x)\\right]\n\\end{aligned}\\]\n\n\\[P_{n}^{\\alpha+1,\\beta+1}(x)=\\frac{1}{n+\\alpha+\\beta}\\left[\\left(n+\\beta\\right)P_{n}^{\\alpha+1,\\beta}(x)+\\left(n+\\alpha\\right)P_{n}^{\\alpha,\\beta+1}(x)\\right]\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#additional-properties",
    "href": "jacobi-polynomials.html#additional-properties",
    "title": "Jacobi polynomial",
    "section": "Additional properties",
    "text": "Additional properties\n\nProperty-1\nNote that \\(\\left\\{ \\frac{dP_{m}^{\\alpha,\\beta}}{dx}\\right\\} _{m=1}^{n+1}\\) forms an orthogonal basis of \\(\\mathcal{P}^{n}\\), hence we can write \\(P_{n}^{\\alpha,\\beta}\\) as\n\\[P_{n}^{\\alpha,\\beta}=a_{n}\\frac{dP_{n-1}^{\\alpha,\\beta}}{dx}+b_{n}\\frac{dP_{n}^{\\alpha,\\beta}}{dx}+c_{n}\\frac{dP_{n+1}^{\\alpha,\\beta}}{dx}\\]\nwhere,\n\\[a_{n}=\\frac{-2(n+\\alpha)(n+\\beta)}{(n+\\alpha+\\beta)(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+1)}\\]\n\\[b_{n}=\\frac{2(\\alpha-\\beta)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+2)}\\]\n\\[c_{n}=\\frac{2(n+\\alpha+\\beta+1)}{(2n+\\alpha+\\beta+1)(2n+\\alpha+\\beta+2)}\\]\n\n\nProperty-2\n\\[\\left(1-x^{2}\\right)\\frac{dP_{n+1}^{\\alpha,\\beta}}{dx}=-\\left(N+1\\right)\\left[x+\\frac{\\beta-\\alpha}{2n+\\alpha+\\beta+2}\\right]P_{n+1}^{\\alpha,\\beta}+2\\left[\\frac{\\left(n+\\alpha+1\\right)\\left(n+\\beta+1\\right)}{2n+\\alpha+\\beta+2}\\right]P_{n}^{\\alpha,\\beta}\\]\nSo, if \\(\\left\\{ x_{n+1}^{j}\\right\\} _{j=0}^{n}\\) are zeros of \\(P_{n+1}^{\\alpha,\\beta}\\), then \\[\\left(1-x_{j}^{2}\\right)\\frac{dP_{n+1}^{\\alpha,\\beta}\\left(x_{j}\\right)}{dx}=2\\left[\\frac{\\left(n+\\alpha+1\\right)\\left(n+\\beta+1\\right)}{2n+\\alpha+\\beta+2}\\right]P_{n}^{\\alpha,\\beta}\\left(x_{j}\\right)\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#jacobi-gauss-quadratures",
    "href": "jacobi-polynomials.html#jacobi-gauss-quadratures",
    "title": "Jacobi polynomial",
    "section": "Jacobi-Gauss Quadratures",
    "text": "Jacobi-Gauss Quadratures\nJacobi-matrix for Jacobi polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n}=\\left\\{ {\\bf D}_{n},{\\bf E}_{n}\\right\\}\\). The main diagonal \\({\\bf D}_{n}\\) and sub-diagonal \\({\\bf E}_{n}\\) are given by\n\\[{\\bf D}_{n}=\\left[\\alpha_{0},\\alpha_{1},\\cdots,\\alpha_{n-1}\\right]\\in R^{n}\\]\n\\[{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}}\\right]\\in R^{n-1}\\]\nThe N-point Jacobi-Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{G},w_{j}^{G}\\right\\} _{j=0}^{n-1}\\).\nThe points \\(x_{j}^{G}\\) are zeros of \\(P_{N}^{\\alpha,\\beta}\\), that is\n\\[P_{N}^{\\alpha,\\beta}(x_{j}^{G})=0,j=0,1,\\cdots n-1\\]\nand \\(\\left\\{ x_{j}^{G}\\right\\} _{n=0}^{n-1}\\) are the eigenvalues of Jacobi matrix \\({\\bf J}_{n}\\) .",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#jacobi-gauss-radau-quadratures",
    "href": "jacobi-polynomials.html#jacobi-gauss-radau-quadratures",
    "title": "Jacobi polynomial",
    "section": "Jacobi Gauss-Radau Quadratures",
    "text": "Jacobi Gauss-Radau Quadratures\nJacobi Gauss-Radau matrix for Jacobi polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+1}^{R,a}=\\left\\{ {\\bf D}_{n+1},{\\bf E}_{n+1}\\right\\}\\). The main diagonal \\({\\bf D}_{n+1}\\) and sub-diagonal \\({\\bf E}_{n+1}\\) are given by\n\\[{\\bf D}_{n+1}=\\left[\\alpha_{0},\\alpha_{1},\\cdots,\\alpha_{n-1},\\alpha_{n}^{R}\\right]\\in R^{n+1}\\]\n\\[{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}}\\right]\\in R^{n}\\]\nWhere,\n\\[\\alpha_{n}^{R}=a+\\frac{(1-a)n(n+\\alpha)-(1+a)n(n+\\beta)}{(2n+\\alpha+\\beta)(2n+\\alpha+\\beta+1)}\\]\nThe \\(n+1\\) point Jacobi Gauss-Radau Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{R},w_{j}^{R}\\right\\} _{j=0}^{n}\\), which are the eigenvalues of Jacobi Gauss-Radau matrix.\nThere is another point of view for understanding the Gauss-Radau quadrature points.\n\nFor \\(a=-1\\), \\(x_{0}^{R}=-1\\), and \\(n\\) points \\(x_{j}^{R},j=1,\\cdots n\\) are zeros of \\(P_{n}^{\\alpha,\\beta+1}(x)\\)\nFor \\(a=1\\), \\(x_{n}^{R}=1\\), and \\(n\\) points \\(x_{j}^{R},j=0,\\cdots n-1\\) are zeros \\(P_{n}^{\\alpha+1,\\beta}(x)\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#jacobi-gauss-lobatto-quadratures",
    "href": "jacobi-polynomials.html#jacobi-gauss-lobatto-quadratures",
    "title": "Jacobi polynomial",
    "section": "Jacobi Gauss-Lobatto Quadratures",
    "text": "Jacobi Gauss-Lobatto Quadratures\nJacobi Gauss-Lobatto matrix for Jacobi polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+2}^{L}=\\left\\{ {\\bf D}_{n+2},{\\bf E}_{n+2}\\right\\}\\). The main diagonal \\({\\bf D}_{n+2}\\) and sub-diagonal \\({\\bf E}_{n+2}\\) are given by\n\\[{\\bf D}_{n+2}=\\left[\\alpha_{0},\\alpha_{1},\\cdots,\\alpha_{n-1},\\alpha_{n},\\alpha_{n+1}^{L}\\right]\\in R^{n+2}\\]\n\\[{\\bf E}_{n+2}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}},\\sqrt{\\beta_{n+1}^{L}}\\right]\\in R^{n+1}\\]\nWhere,\n\\[\\alpha_{n+1}^{L}=\\frac{\\alpha-\\beta}{2n+\\alpha+\\beta+2}\\]\n\\[\\beta_{n+1}^{L}=4\\frac{\\left(n+\\alpha+1\\right)\\left(n+\\beta+1\\right)\\left(n+\\alpha+\\beta+1\\right)}{\\left(2n+\\alpha+\\beta+1\\right)\\left(2n+\\alpha+\\beta+2\\right)^{2}}\\]\nThe \\(n+2\\) point Jacobi Gauss-Lobatto quadrature rule is denoted by \\(\\left\\{ x_{j}^{R},w_{j}^{R}\\right\\} _{j=0}^{n+1}\\), which are the eigenvalues of Jacobi Gauss-Lobatto matrix.\nThere is another point of view for understanding the Gauss-Lobatto quadrature points.\n\n\\(x_{0}^{L}=-1\\) and \\(x_{n+1}^{L}=1\\), the \\(n-1\\) points \\(x_{j}^{L},j=1,\\cdots n-1\\) are zeros of \\(P_{n-1}^{\\alpha+1,\\beta+1}(x)\\) , that is zeros of \\(\\frac{dP_{n}^{\\alpha,\\beta}}{dx}\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-points",
    "href": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-points",
    "title": "Jacobi polynomial",
    "section": "Lagrange polynomials for Jacobi-Gauss points",
    "text": "Lagrange polynomials for Jacobi-Gauss points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-lobatto-points",
    "href": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-lobatto-points",
    "title": "Jacobi polynomial",
    "section": "Lagrange polynomials for Jacobi-Gauss-Lobatto points",
    "text": "Lagrange polynomials for Jacobi-Gauss-Lobatto points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-radau-points",
    "href": "jacobi-polynomials.html#lagrange-polynomials-for-jacobi-gauss-radau-points",
    "title": "Jacobi polynomial",
    "section": "Lagrange polynomials for Jacobi-Gauss-Radau points",
    "text": "Lagrange polynomials for Jacobi-Gauss-Radau points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Jacobi polynomial</span>"
    ]
  },
  {
    "objectID": "ultraspherical-polynomials.html",
    "href": "ultraspherical-polynomials.html",
    "title": "Ultraspherical polynomials",
    "section": "",
    "text": "Jacobi polynomial with \\(\\alpha=\\beta&gt;-1\\), are called the ultraspherical polynomials or Gegenbauer polynomial. We will denote ultraspherical polynomial by \\(P_{n}^{\\lambda}(x)\\) where, \\(\\alpha=\\lambda-\\frac{1}{2}\\). Note that \\(\\lambda&gt;-\\frac{1}{2}\\).\n\\[\nP_{n}^{(\\lambda)}(x)=\\frac{\\Gamma\\left(\\lambda+\\frac{1}{2}\\right)}{\\Gamma\\left(2\\lambda\\right)}\\frac{\\Gamma\\left(n+2\\lambda\\right)}{\\Gamma\\left(n+\\lambda+\\frac{1}{2}\\right)}P_{n}^{\\left(\\alpha,\\alpha\\right)}(x),\\quad\\alpha=\\lambda-\\frac{1}{2}\n\\]\nwe can also write\n\\[\nP_{n}^{(\\lambda)}(x)=\\frac{\\Gamma\\left(\\alpha+1\\right)}{\\Gamma\\left(2\\alpha+1\\right)}\\frac{\\Gamma\\left(n+2\\alpha+1\\right)}{\\Gamma\\left(n+\\alpha+1\\right)}P_{n}^{\\left(\\alpha,\\alpha\\right)}(x),\\quad\\alpha=\\lambda-\\frac{1}{2}\n\\]\n\nNote that for \\(\\alpha=-1/2\\), or \\(\\lambda=0\\), \\(\\Gamma\\left(2\\alpha+1\\right)\\)is not defined, and this case should be handled carefully.\nThe \\(P_{n}^{\\lambda}\\) are orthogonal with respect to the following weight function.\n\n\\[\nw(x)=(1-x^{2})^{\\alpha}=(1-x^{2})^{\\lambda-0.5}\n\\]\n\nThe support of ultraspherical polynomial is \\([-1,1].\\)\n\n\nFirst few Ultraspherical polynomials\n\\[\nP_{0}^{(\\lambda)}=1\n\\]\n\\[\nP_{1}^{(\\lambda)}=2\\lambda x\n\\]\n\nFor \\(\\lambda=1/2\\), \\(\\alpha=0\\), and we get Legendre polynomial.\n\n\\[\nP_{n}(x)=P_{n}^{(\\lambda)}(x)\n\\]\n\nFor \\(\\lambda=1\\), \\(\\alpha=1/2\\), we get Chebyshev polynomial of second kind.\n\n\\[\nU_{n}(x)=P_{n}^{(\\lambda)}(x)\n\\]\n\n\nLeading coefficient\nThe leading coefficient of \\(P_{n}^{(\\lambda)}\\) is denoted by \\(k_{n}\\) and it is given by\n\\[\n\\begin{aligned}k_{n} & =\\frac{1}{2^{n}}\\frac{\\Gamma\\left(2n+2\\alpha+1\\right)}{n!\\Gamma\\left(n+2\\alpha+1\\right)}\\frac{\\Gamma\\left(\\alpha+1\\right)}{\\Gamma\\left(2\\alpha+1\\right)}\\frac{\\Gamma\\left(n+2\\alpha+1\\right)}{\\Gamma\\left(n+\\alpha+1\\right)}\\\\\n& =\\frac{1}{2^{n}n!}\\frac{\\Gamma\\left(2n+2\\alpha+1\\right)}{\\Gamma\\left(n+\\alpha+1\\right)}\\frac{\\Gamma\\left(\\alpha+1\\right)}{\\Gamma\\left(2\\alpha+1\\right)}\\\\\n& =\\frac{2^{n}}{n!}\\frac{\\Gamma\\left(n+\\lambda\\right)}{\\Gamma\\left(\\lambda\\right)}\\quad\\lambda\\ne0\n\\end{aligned}\n\\]\nHere, we have used the following identity.\n\\[\n\\frac{\\Gamma\\left(2z\\right)}{\\Gamma(z)}=\\frac{\\Gamma(z+\\frac{1}{2})}{2^{0.5-2z}\\sqrt{2\\pi}}\n\\]\n\\[\n\\frac{k_{n+1}}{k_{n}}=2\\left(\\frac{n+\\lambda}{n+1}\\right)\n\\]\n\n\nNorm\nThe norm of \\(P_{n}^{(\\lambda)}\\) is given below:\n\\[\n\\Vert P_{n}^{(\\lambda)}\\Vert^{2}=:h_{n}^{\\lambda}=\\left(2^{1-2\\lambda}\\right)\\frac{\\pi}{\\left[\\Gamma(\\lambda)\\right]^{2}}\\frac{\\Gamma\\left(n+2\\lambda\\right)}{\\left(n+\\lambda\\right)\\Gamma\\left(n+1\\right)}\n\\]\n\\[\n\\frac{h_{n-1}^{\\lambda}}{h_{n}^{\\lambda}}=\\frac{n(n+\\lambda)}{(n+\\lambda-1)(n+2\\lambda-1)}\n\\]\n\\[\n\\frac{h_{n+1}^{\\lambda}}{h_{n}^{\\lambda}}=\\frac{(n+\\lambda)(n+2\\lambda)}{(n+1)(n+\\lambda+1)}\n\\]\n\n\nSymmetry\n\\[\nP_{n}^{(\\lambda)}(x)=\\left(-1\\right)^{n}P_{n}^{(\\lambda)}(-x)\n\\]\nTherefore, \\(P_{n}^{(\\lambda)}(x)\\) is even if \\(n\\) is even and odd if \\(n\\) is odd.\n\n\nScaling\n\\[\nP_{n}^{(\\lambda)}(\\pm1)=\\left(\\pm1\\right)^{n}\\left(\\begin{array}{c}\nn+2\\lambda-1\\\\\nn\n\\end{array}\\right)\n\\]\n\n\nBoundedness\n\n\nDerivatives\n\\[\n\\frac{dP_{n}^{(\\lambda)}}{dx}=2\\lambda P_{n-1}^{\\left(\\lambda+1\\right)}\n\\]\nor\n\\[\nP_{n-1}^{\\left(\\lambda+1\\right)}=\\frac{1}{2\\lambda}\\frac{dP_{n}^{(\\lambda)}}{dx}\n\\]\n\n\nOrthogonality\n\\[\n\\int_{-1}^{+1}P_{m}^{(\\lambda)}(x)P_{n}^{(\\lambda)}(x)(1-x^{2})^{\\lambda-0.5}dx=h_{m}^{(\\lambda)}\\delta_{mn}\n\\]\n\\[\n\\int_{-1}^{+1}\\frac{dP_{m}^{(\\lambda)}(x)}{dx}\\frac{dP_{n}^{(\\lambda)}(x)}{dx}\\left(1-x^{2}\\right)^{\\lambda+0.5}dx=4\\lambda^{2}h_{n-1}^{\\left(\\lambda+1\\right)}\\delta_{mn}\n\\]\n\n\nPolynomial representation\n\\[\nP_{n}^{(\\lambda)}(x)=\\frac{1}{\\Gamma\\left(\\lambda\\right)}\\sum_{m=0}^{\\left[n/2\\right]}\\left(-1\\right)^{m}2^{n-2m}\\frac{\\Gamma\\left(\\lambda+n-m\\right)}{m!\\left(n-2m\\right)!}x^{n-2m}\n\\]\nwhere \\(\\left[n/2\\right]\\) is the integer part of \\(n/2\\).\n\n\nStrum-Liovile equation\n\\[\n\\frac{1}{\\left(1-x^{2}\\right)^{\\alpha}}\\frac{d}{dx}\\left(\\left(1-x^{2}\\right)^{\\alpha+1}\\frac{dy}{dx}\\right)+n\\left(n+2\\alpha+1\\right)y=0\n\\]\n\n\nRodrigues’s Formula\n\\[\n\\left(1-x^{2}\\right)^{\\lambda-0.5}P_{n}^{(\\lambda)}(x)=\\frac{\\left(-2\\right)^{n}}{n!}\\frac{\\Gamma\\left(\\lambda+n\\right)}{\\Gamma\\left(\\lambda\\right)}\\frac{\\Gamma\\left(n+2\\lambda\\right)}{\\Gamma\\left(2n+2\\lambda\\right)}\\frac{d^{n}}{dx^{n}}\\left[\\left(1-x^{2}\\right)^{n+\\lambda-0.5}\\right]\n\\]\n\n\nRecurrence relation for monic Ultraspherical polynomial\nLet \\(\\pi_{n}^{(\\lambda)}\\) denotes the monic orthogonal Ultraspherical polynomial.\n\\[\n\\pi_{n+1}^{(\\lambda)}=\\left(x-\\alpha_{n}\\right)\\pi_{n}^{(\\lambda)}-\\beta_{n}\\pi_{n-1}^{(\\lambda)},\\quad n=0,1,2\n\\]\n\\[\n\\alpha_{n}=0,n\\ge0\n\\]\n\\[\n\\beta_{0}=2^{2\\alpha+1}\\frac{\\left[\\Gamma\\left(\\alpha+1\\right)\\right]^{2}}{\\Gamma\\left(2\\left(\\alpha+1\\right)\\right)}=\\frac{\\pi}{\\lambda2^{2\\lambda-1}}\\frac{\\Gamma(2\\lambda)}{\\left[\\Gamma(\\lambda)\\right]^{2}}\n\\]\n\\[\n\\beta_{1}=\\frac{1}{(3+2\\alpha)}=\\frac{1}{2+2\\lambda}\n\\]\n\\[\n\\begin{aligned}\\beta_{n\\ge2} & =\\frac{n(n+2\\alpha)}{(2n+2\\alpha+1)(2n+2\\alpha-1)}\\\\\n& =\\frac{n(2\\lambda+n-1)}{4(n+\\lambda)(n+\\lambda-1)}\n\\end{aligned}\n\\]\n\n\nRecurrence relation for monic orthonormal Ultraspherical polynomial\nLet \\(\\tilde{\\pi}_{n}^{(\\lambda)}\\) denotes the monic orthonormal Ultraspherical polynomial.\n\\[\n\\tilde{\\pi}_{n+1}^{(\\lambda)}=\\frac{\\left(x-\\alpha_{n}\\right)}{\\sqrt{\\beta_{n+1}}}\\tilde{\\pi}_{n}^{(\\lambda)}-\\frac{\\beta_{n}}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\tilde{\\pi}_{n-1}^{(\\lambda)},\\quad n=0,1,2\n\\]\nor\n\\[\n\\tilde{\\pi}_{n+1}^{(\\lambda)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{\\pi}_{n}^{(\\lambda)}-\\beta_{n}s_{n}^{b}\\tilde{\\pi}_{n-1}^{(\\lambda)},\\quad n=0,1,2\n\\]\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\n\\]\n\\[\ns_{n}^{b}=\\frac{1}{\\sqrt{\\beta_{n}\\beta_{n+1}}}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\n\nRecurrence relation for Ultraspherical polynomials\n\\[\nP_{-1}^{(\\lambda)}=0,\n\\]\n\\[\nP_{0}^{(\\lambda)}=1\n\\]\n\\[\nP_{1}^{(\\lambda)}=2\\lambda x\n\\]\n\\[\nP_{n+1}^{(\\lambda)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}P_{n}^{(\\lambda)}-\\beta_{n}s_{n}^{b}P_{n-1}^{(\\lambda)},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=2\\left(\\frac{n+\\lambda}{n+1}\\right)\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]\nAlternatively, we can write the above recurrence relationship as:\n\\[\nP_{n+1}^{(\\lambda)}=\\left(a_{n}x\\right)P_{n}^{(\\lambda)}-c_{n}P_{n-1}^{(\\lambda)},\\quad n=1,2,\\cdots\n\\]\n\\[\na_{n}=s_{n}^{a}=2\\left(\\frac{n+\\lambda}{n+1}\\right)\n\\]\n\\[\nc_{n}=\\beta_{n}s_{n}^{b}=\\frac{n+2\\lambda-1}{n+1}\n\\]\n\n\nRecurrence relation for orthonormal Ultraspherical polynomials\n\\[\n\\tilde{P}_{n+1}^{(\\lambda)}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{P}_{n}^{(\\lambda)}-\\beta_{n}s_{n}^{b}\\tilde{P}_{n-1}^{(\\lambda)},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]\n\n\nRecurrence relation for derivative of Ultraspherical polynomial\nThe gradient can be computed by following recurrence relationship:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}^{(\\lambda)}}{dx}=2\\beta_{n}\\left(n+\\lambda\\right)s_{n-1}^{a}P_{n-1}^{(\\lambda)}+\\left(-nx\\right)P_{n}^{(\\lambda)}\n\\]\n\\[\n\\left(\\frac{dP_{n}}{dx}\\right)_{x=1}=\\frac{1}{2}\\left(n+2\\lambda\\right)\\frac{\\Gamma\\left(n+\\lambda+1/2\\right)}{\\left(n-1\\right)!\\Gamma\\left(\\lambda+3/2\\right)}\n\\]\n\\[\n\\left(\\frac{dP_{n}}{dx}\\right)_{x=-1}=\\left(-1\\right)^{n-1}\\frac{1}{2}\\left(n+2\\lambda\\right)\\frac{\\Gamma\\left(n+\\lambda+1/2\\right)}{\\left(n-1\\right)!\\Gamma\\left(\\lambda+3/2\\right)}\n\\]\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=2\\left(\\frac{n+\\lambda}{n+1}\\right)\n\\]\n\n\nMore recurrence relation for derivative of Ultraspherical polynomial\n\\[\nnP_{n}^{(\\lambda)}=x\\frac{dP_{n}^{(\\lambda)}}{dx}-\\frac{dP_{n-1}^{(\\lambda)}}{dx}\n\\]\n\\[\nP_{n}^{(\\lambda)}=-\\frac{x}{n+2\\lambda}\\frac{dP_{n}^{(\\lambda)}}{dx}+\\frac{1}{n+2\\lambda}\\frac{dP_{n+1}^{(\\lambda)}}{dx}\n\\]\n\\[\nP_{n}^{(\\lambda)}=\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{d}{dx}\\left(P_{n+1}^{(\\lambda)}-P_{n-1}^{(\\lambda)}\\right)\n\\]\n\n\nRecurrence relation for derivative of orthonormal Ultraspherical polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{P}_{n}^{(\\lambda)}}{dx}=2\\beta_{n}\\left(n+\\lambda\\right)s_{n-1}^{a}\\tilde{P}_{n-1}^{(\\lambda)}+\\left(-nx\\right)\\tilde{P}_{n}^{(\\lambda)}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\n\\]\n\n\nRecurrence relation for derivative of monic Ultraspherical polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\pi_{n}^{(\\lambda)}}{dx}=2\\beta_{n}\\left(n+\\lambda\\right)\\pi_{n-1}^{(\\lambda)}+\\left(-nx\\right)\\pi_{n}^{(\\lambda)}\n\\]\n\n\nRecurrence relation for derivative of monic orthonormal Ultraspherical polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}^{(\\lambda)}}{dx}=2\\beta_{n}\\left(n+\\lambda\\right)s_{n-1}^{a}\\tilde{\\pi}_{n-1}^{(\\lambda)}+\\left(-nx\\right)\\tilde{\\pi}_{n}^{(\\lambda)}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\n\\]\n\n\nKernel polynomial\n\n\nMore recurrence relations\n\n\nAdditional properties\n\n\nUltraspherical-Gauss Quadratures\nJacobi-matrix for Ultraspherical polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n}=\\left\\{ {\\bf D}_{n},{\\bf E}_{n}\\right\\}\\). The main diagonal \\({\\bf D}_{n}\\) and sub-diagonal \\({\\bf E}_{n}\\) are given by\n\\[\n{\\bf D}_{n}=\\boldsymbol{0}\\in R^{n}\n\\]\n\\[\n{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}}\\right]\\in R^{n-1}\n\\]\n\nThe \\(N+1\\) point Ultraspherical-Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{G},w_{j}^{G}\\right\\} _{j=0}^{N}\\).\nThe points \\(x_{j}^{G}\\) are zeros of \\(P_{N+1}^{(\\lambda)}\\), that is,\n\n\\[\nP_{N+1}^{(\\lambda)}(x_{j}^{G})=0,j=0,1,\\cdots,N\n\\]\n\nand \\(\\left\\{ x_{j}^{G}\\right\\}_{j=0}^{N}\\) are the eigenvalues of Jacobi matrix \\({\\bf J}_{N+1}\\).\nWeights are given by\n\n\\[\nw_{j}=,j=0,\\cdots,N\n\\]\n\n\nUltraspherical Gauss-Radau Quadratures\nJacobi Gauss-Radau matrix for Ultraspherical polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+1}^{R,a}=\\left\\{ {\\bf D}_{n+1},{\\bf E}_{n+1}\\right\\}\\). The main diagonal \\({\\bf D}_{n+1}\\) and sub-diagonal \\({\\bf E}_{n+1}\\) are given by\n\\[\n{\\bf D}_{n+1}=\\left[\\boldsymbol{0},\\alpha_{n}^{R}\\right]\\in R^{n+1}\n\\]\n\\[\n{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}}\\right]\\in R^{n}\n\\]\nwhere,\n\\[\n\\alpha_{n}^{R}=\\frac{a}{2}\\left(\\frac{n+2\\lambda}{n+\\lambda}\\right)\n\\]\nThe \\(N+1\\) point Ultraspherical Gauss-Radau quadrature rule is denoted by \\(\\left\\{ x_{j}^{R},w_{j}^{R}\\right\\} _{j=0}^{n}\\), which are the eigenvalues of Jacobi Gauss-Radau matrix. The weights are given by\n\\[\nw_{j}=,j=0,\\cdots,n\n\\]\n\n\nUltraspherical Gauss-Lobatto Quadratures\nJacobi Gauss-Lobatto matrix for Ultraspherical polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+2}^{L}=\\left\\{ {\\bf D}_{n+2},{\\bf E}_{n+2}\\right\\}\\). The main diagonal \\({\\bf D}_{n+2}\\) and sub-diagonal \\({\\bf E}_{n+2}\\) are given by\n\\[\n{\\bf D}_{n+2}=\\boldsymbol{0}\\in R^{n+2}\n\\]\n\\[\n{\\bf E}_{n+2}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}},\\sqrt{\\beta_{n+1}^{L}}\\right]\\in R^{n+1}\n\\]\nThe \\(n+2\\) point Jacobi Gauss-Lobatto quadrature rule is denoted by \\(\\left\\{ x_{j}^{L},w_{j}^{L}\\right\\} _{j=0}^{n+1}\\), which are the eigenvalues of Jacobi Gauss-Lobatto matrix.The weights are given by\n\\[\nw_{j}=,j=0,\\cdots,n+1\n\\]\n\n\nLagrange polynomial for Ultraspherical-Gauss points\nThe Lagrange interpolation polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), based on the Gauss quadrature points, \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N},\\)are\n\\[\nl_{i}(x)=\\frac{P_{N+1}^{(\\lambda)}(x)}{(x-x_{i})\\frac{d}{dx}P_{N+1}^{(\\lambda)}(x_{i})},\\quad i=0,\\cdots,N\n\\]\n\n\nLagrange polynomial for Ultraspherical-Gauss-Lobatto points\nThe Lagrange interpolation polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), based on the Gauss-Lobatto quadrature points, \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N},\\)are\n\\[\nl_{i}(x)=\\begin{cases}\n(\\lambda+0.5)\\Pi_{N,i}^{(\\lambda)}(x) & i=0,N\\\\\n\\Pi_{N,i}^{(\\lambda)}(x) & \\text{otherwise}\n\\end{cases}\n\\]\nwhere,\n\\[\n\\Pi_{N,i}^{(\\lambda)}(x)=-\\frac{1}{N(N+2\\lambda)}\\frac{(1-x^{2})}{(x-x_{i})P_{N}^{(\\lambda)}(x_{i})}\\frac{dP_{N}^{(\\lambda)}(x)}{dx}\n\\]\n\n\nLagrange polynomial for Ultraspherical-Gauss-Radau points\nThe Lagrange interpolation polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), based on the Gauss-Radau quadrature points, \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N},\\)are\n\\[\nl_{i}(x)=\\begin{cases}\n(\\lambda+0.5)\\Pi_{N,i}^{(\\lambda)}(x) & i=0,orN\\\\\n\\Pi_{N,i}^{(\\lambda)}(x) & \\text{otherwise}\n\\end{cases}\n\\]\nwhere,\n\\[\n\\begin{aligned}\\Pi_{N,i}^{(\\lambda)}(x) & =\\frac{1}{2(N+\\lambda+0.5)(N+2\\lambda)}\\frac{(1-x_{i})}{P_{N}^{(\\lambda)}(x_{i})}\\\\\n& \\times\\frac{(N+1)P_{N+1}^{(\\lambda)}(x)+(N+2\\lambda)P_{N}^{(\\lambda)}(x)}{(x-x_{i})}\n\\end{aligned}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ultraspherical polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html",
    "href": "legendre-polynomials.html",
    "title": "Legendre polynomials",
    "section": "",
    "text": "First few Legendre polynomials\nJacobi polynomial with \\(\\alpha=\\beta=0\\), are called the Legendre polynomials. We will denote Legendre polynomial by \\(P_{n}(x)\\).\n\\[\nP_{n}(x)=P_{n}^{(1/2)}(x)=P_{n}^{(0,0)}(x)\n\\]\nThe \\(P_{n}\\) are orthogonal with respect to the following weight function.\n\\[\nw(x)=1\n\\]\nThe support of Legendre polynomial is \\(\\left[-1,1\\right].\\) Legendre polynomials are best from the point of view of minimizing the \\(L^{2}\\) error.\nThe first five legendre polynomials are given below.\n\\[\nP_{0}=x^{0}\n\\]\n\\[\nP_{1}=x\n\\]\n\\[\nP_{2}=\\frac{3}{2}x^{2}-\\frac{1}{2}\n\\]\n\\[\nP_{3}=\\frac{1}{2}x\\left(5x^{2}-3\\right)\n\\]\n\\[\nP_{4}=\\frac{1}{8}\\left(35x^{4}-30x^{2}+3\\right)\n\\]\n\\[\nP_{5}=\\frac{1}{8}x\\left(63x^{4}-70x^{2}+15\\right)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#leading-coefficient",
    "href": "legendre-polynomials.html#leading-coefficient",
    "title": "Legendre polynomials",
    "section": "Leading coefficient",
    "text": "Leading coefficient\nThe leading coefficient of \\(P_{n}\\) is denoted by \\(k_{n}\\), and it is given by\n\\[\nk_{n}=\\frac{\\left(2n\\right)!}{2^{n}\\left(n!\\right)^{2}}\n\\]\n\\[\n\\frac{k_{n+1}}{k_{n}}=\\frac{2n+1}{\\left(n+1\\right)}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#norm",
    "href": "legendre-polynomials.html#norm",
    "title": "Legendre polynomials",
    "section": "Norm",
    "text": "Norm\nThe norm of \\(P_{n}\\) is given below:\n\\[\n\\Vert P_{n}\\Vert^{2}=:h_{n}=\\frac{2}{2n+1}\n\\]\n\\[\n\\frac{h_{n-1}}{h_{n}}=\\frac{2n+1}{2n-1}\n\\]\n\\[\n\\frac{h_{n}}{h_{n-1}}=\\frac{2n-1}{2n+1}\n\\]\n\\[\n\\frac{h_{n+1}}{h_{n}}=\\frac{2n+1}{2n+3}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#symmetry",
    "href": "legendre-polynomials.html#symmetry",
    "title": "Legendre polynomials",
    "section": "Symmetry",
    "text": "Symmetry\n\\[\nP_{n}(x)=\\left(-1\\right)^{n}P_{n}(-x)\n\\]\nTherefore, \\(P_{n}(x)\\) is even if \\(n\\) is even and odd if \\(n\\) is odd.",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#scaling",
    "href": "legendre-polynomials.html#scaling",
    "title": "Legendre polynomials",
    "section": "Scaling",
    "text": "Scaling\n\\[\nP_{n}(\\pm1)=\\left(\\pm1\\right)^{n}\n\\]\n\\[\n\\frac{dP_{n}}{dx}\\left(\\pm1\\right)=\\frac{1}{2}\\left(\\pm1\\right)^{n-1}n(n+1)\n\\]\n\\[\n\\frac{d^{2}P_{n}}{dx^{2}}\\left(\\pm1\\right)=\\left(\\pm1\\right)^{n}n(n+1)\\left(n+2\\right)/8\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#boundedness",
    "href": "legendre-polynomials.html#boundedness",
    "title": "Legendre polynomials",
    "section": "Boundedness",
    "text": "Boundedness\n\\[\n\\vert P_{n}\\vert\\le1\n\\]\n\\[\n\\left|\\frac{dP_{n}}{dx}\\right|\\le\\frac{1}{2}n(n+1)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#derivatives",
    "href": "legendre-polynomials.html#derivatives",
    "title": "Legendre polynomials",
    "section": "Derivatives",
    "text": "Derivatives\n\\[\n\\frac{dP_{n}}{dx}=P_{n-1}^{(3/2)}=\\frac{n+1}{2}P_{n-1}^{\\left(1,1\\right)}\n\\]\n\\[\n\\frac{dP_{n}}{dx}=\\sum_{\\begin{aligned}k=0\\\\\nk+n & \\text{odd}\n\\end{aligned}\n}^{n-1}\\left(2k+1\\right)P_{k}(x)\n\\]\n\\[\n\\frac{d^{2}P_{n}}{dx^{2}}=\\sum_{\\begin{aligned}k=0\\\\\nk+n & \\text{even}\n\\end{aligned}\n}^{n-2}\\left(k+\\frac{1}{2}\\right)\\left[n\\left(n+1\\right)-k\\left(k+1\\right)\\right]P_{k}(x)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#orthogonality",
    "href": "legendre-polynomials.html#orthogonality",
    "title": "Legendre polynomials",
    "section": "Orthogonality",
    "text": "Orthogonality\n\\[\n\\int_{-1}^{+1}P_{m}(x)P_{n}(x)dx=h_{m}\\delta_{mn}\n\\]\n\\[\n\\int_{-1}^{+1}\\frac{dP_{m}(x)}{dx}\\frac{dP_{n}(x)}{dx}\\left(1-x^{2}\\right)dx=h_{n}n(n+1)\\delta_{mn}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#polynomial-representation",
    "href": "legendre-polynomials.html#polynomial-representation",
    "title": "Legendre polynomials",
    "section": "Polynomial representation",
    "text": "Polynomial representation\n\\[\nP_{n}(x)=\\frac{1}{2^{n}}\\sum_{m=0}^{\\left[n/2\\right]}\\left(-1\\right)^{m}\\left(\\begin{array}{c}\nn\\\\\nm\n\\end{array}\\right)\\left(\\begin{array}{c}\n2n-2m\\\\\nn\n\\end{array}\\right)x^{n-2m}\n\\]\nwhere \\(\\left[n/2\\right]\\) is the integer part of \\(n/2\\).",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#strum-liovile-equation",
    "href": "legendre-polynomials.html#strum-liovile-equation",
    "title": "Legendre polynomials",
    "section": "Strum-Liovile equation",
    "text": "Strum-Liovile equation\n\\[\n\\frac{d}{dx}\\left(\\left(1-x^{2}\\right)\\frac{dy}{dx}\\right)+n\\left(n+1\\right)y=0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#rodriguess-formula",
    "href": "legendre-polynomials.html#rodriguess-formula",
    "title": "Legendre polynomials",
    "section": "Rodrigues’s Formula",
    "text": "Rodrigues’s Formula\n\\[\nP_{n}(x)=\\frac{\\left(-1\\right)^{n}}{2^{n}n!}\\frac{d^{n}}{dx^{n}}\\left[\\left(1-x^{2}\\right)^{n}\\right]\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-monic-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-monic-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for monic Legendre polynomial",
    "text": "Recurrence relation for monic Legendre polynomial\nLet \\(\\pi_{n}\\) denotes the monic orthogonal Legendre polynomial.\n\\[\n\\pi_{n+1}=\\left(x-\\alpha_{n}\\right)\\pi_{n}-\\beta_{n}\\pi_{n-1},\\quad n=0,1,2\n\\]\n\\[\n\\alpha_{n}=0,n\\ge0\n\\]\n\\[\n\\beta_{0}=2\n\\]\n\\[\n\\beta_{n\\ge1}=\\frac{n^{2}}{4n^{2}-1}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-monic-orthonormal-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-monic-orthonormal-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for monic orthonormal Legendre polynomial",
    "text": "Recurrence relation for monic orthonormal Legendre polynomial\n\\[\n\\tilde{\\pi}_{n+1}=\\frac{\\left(x-\\alpha_{n}\\right)}{\\sqrt{\\beta_{n+1}}}\\tilde{\\pi}_{n}-\\frac{\\beta_{n}}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\n\\]\nor\n\\[\n\\tilde{\\pi}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{\\pi}_{n}-\\beta_{n}s_{n}^{b}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\n\\]\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\n\\]\n\\[\ns_{n}^{b}=\\frac{1}{\\sqrt{\\beta_{n}\\beta_{n+1}}}=s_{n}^{a}s_{n-1}^{a}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-legendre-polynomials",
    "href": "legendre-polynomials.html#recurrence-relation-for-legendre-polynomials",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for Legendre polynomials",
    "text": "Recurrence relation for Legendre polynomials\nLegendre polynomial \\(P_{n}\\) is neither monic nor orthonormal. First few Legendre polynomials are:\n\\[\nP_{-1}=0\n\\]\n\\[\nP_{0}=1\n\\]\n\\[\nP_{1}=x\n\\]\n\nThe following three term-term recurrence relationship can be used to compute the Legendre polynomial:\n\n\\[\n(n+1)P_{n+1}=\\left(2n+1\\right)xP_{n}-nP_{n-1},\\quad n=1,2,\\cdots\n\\]\nWe can also use the following three-term recurrence relationship:\n\\[\nP_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}P_{n}-\\beta_{n}s_{n}^{b}P_{n-1},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{2n+1}{n+1}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-orthonormal-legendre-polynomials",
    "href": "legendre-polynomials.html#recurrence-relation-for-orthonormal-legendre-polynomials",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for orthonormal Legendre polynomials",
    "text": "Recurrence relation for orthonormal Legendre polynomials\nLet \\(\\tilde{P}_{n}\\) denote the orthonormal Legendre polynomials.\n\\[\n\\tilde{P}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{P}_{n}-\\beta_{n}s_{n}^{b}\\tilde{P}_{n-1},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-derivative-of-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-derivative-of-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for derivative of Legendre polynomial",
    "text": "Recurrence relation for derivative of Legendre polynomial\nThe gradient can be computed by using the following three-term recurrence relationship:\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}P_{n-1}+\\left(-nx\\right)P_{n}\n\\]\n\\[\n\\frac{dP_{n}}{dx}\\left(\\pm1\\right)=\\frac{1}{2}\\left(\\pm1\\right)^{n-1}n(n+1)\n\\]\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{2n+1}{n+1}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#more-recurrence-relation-for-derivative-of-legendre-polynomial",
    "href": "legendre-polynomials.html#more-recurrence-relation-for-derivative-of-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "More recurrence relation for derivative of Legendre polynomial",
    "text": "More recurrence relation for derivative of Legendre polynomial\n\\[\nnP_{n}=x\\frac{dP_{n}}{dx}-\\frac{dP_{n-1}}{dx}\n\\]\n\\[\nP_{n}=-\\frac{x}{n+1}\\frac{dP_{n}}{dx}+\\frac{1}{n+1}\\frac{dP_{n+1}}{dx}\n\\]\n\\[\nP_{n}=\\frac{1}{\\left(2n+1\\right)}\\frac{d}{dx}\\left(P_{n+1}-P_{n-1}\\right)\n\\]\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n}}{dx}=\\frac{n\\left(n+1\\right)}{2n+1}\\left(P_{n-1}-P_{n+1}\\right)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for derivative of orthonormal Legendre polynomial",
    "text": "Recurrence relation for derivative of orthonormal Legendre polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{P}_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}\\tilde{P}_{n-1}+\\left(-nx\\right)\\tilde{P}_{n}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-derivative-of-monic-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-derivative-of-monic-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for derivative of monic Legendre polynomial",
    "text": "Recurrence relation for derivative of monic Legendre polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\pi_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)\\pi_{n-1}+\\left(-nx\\right)\\pi_{n}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-legendre-polynomial",
    "href": "legendre-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-legendre-polynomial",
    "title": "Legendre polynomials",
    "section": "Recurrence relation for derivative of monic orthonormal Legendre polynomial",
    "text": "Recurrence relation for derivative of monic orthonormal Legendre polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}\\tilde{\\pi}_{n-1}+\\left(-nx\\right)\\tilde{\\pi}_{n}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#kernel-polynomial",
    "href": "legendre-polynomials.html#kernel-polynomial",
    "title": "Legendre polynomials",
    "section": "Kernel polynomial",
    "text": "Kernel polynomial",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#more-recurrence-results",
    "href": "legendre-polynomials.html#more-recurrence-results",
    "title": "Legendre polynomials",
    "section": "More recurrence results",
    "text": "More recurrence results\n\\[\nP_{n}^{1,0}(x)=\\frac{P_{n}(x)-P_{n+1}(x)}{\\left(1-x\\right)}\n\\]\n\\[\nP_{n}^{0,1}(x)=\\frac{P_{n}(x)+P_{n+1}(x)}{\\left(1+x\\right)}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#additional-properties",
    "href": "legendre-polynomials.html#additional-properties",
    "title": "Legendre polynomials",
    "section": "Additional properties",
    "text": "Additional properties\n\\[\n\\left(1-x^{2}\\right)\\frac{dP_{n+1}}{dx}=-\\left(N+1\\right)xP_{n+1}+\\left(n+1\\right)P_{n}\n\\]\nSo, if \\(\\left\\{ x_{j}\\right\\}_{j=0}^{n}\\) are \\(n+1\\) zeros of \\(P_{n+1}\\), then \\[\n\\left(1-x_{j}^{2}\\right)\\frac{dP_{n+1}\\left(x_{j}\\right)}{dx}=\\left(n+1\\right)P_{n}\\left(x_{j}\\right)\n\\]\nTheorem: If \\(x_{j}\\) is zero of \\(P_{n}\\), then \\[\n\\frac{dP_{n}\\left(x_{j}\\right)}{dx}=\\frac{n}{1-x_{j}^{2}}P_{n-1}\\left(x_{j}\\right)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#legendre-gauss-quadratures",
    "href": "legendre-polynomials.html#legendre-gauss-quadratures",
    "title": "Legendre polynomials",
    "section": "Legendre-Gauss Quadratures",
    "text": "Legendre-Gauss Quadratures\nJacobi-matrix for Legendre polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n}=\\left\\{ {\\bf D}_{n},{\\bf E}_{n}\\right\\}\\). The main diagonal \\({\\bf D}_{n}\\) and sub-diagonal \\({\\bf E}_{n}\\) are given by\n\\[\n{\\bf D}_{n}=\\boldsymbol{0}\\in R^{n}\n\\]\n\\[\n{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}}\\right]\\in R^{n-1}\n\\]\n\nThe \\(N+1\\) point Legendre-Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{G},w_{j}^{G}\\right\\} _{j=0}^{N}\\).\nThe points \\(x_{j}^{G}\\) are zeros of \\(P_{N+1}\\), that is\n\n\\[\nP_{N+1}(x_{j}^{G})=0,j=0,1,\\cdots,N\n\\]\n\nand \\(\\left\\{ x_{j}^{G}\\right\\}_{j=0}^{N}\\) are the eigenvalues of Jacobi matrix \\({\\bf J}_{N+1}\\).\nWeights are given by\n\n\\[\nw_{j}=\\frac{2}{\\left[1-\\left(x_{j}^{G}\\right)^{2}\\right]\\left[\\frac{dP_{N+1}}{dx}\\left(x_{j}^{G}\\right)\\right]^{2}},j=0,\\cdots,N\n\\]\nBut, we know that\n\\[\n\\frac{d}{dx}P_{N+1}\\left(x_{j}^{G}\\right)=\\frac{N+1}{1-\\left(x_{j}^{G}\\right)^{2}}P_{N}\\left(x_{j}^{G}\\right)\n\\]\nthen weights become\n\\[\nw_{j}=\\frac{2\\left[1-\\left(x_{j}^{G}\\right)^{2}\\right]}{\\left(N+1\\right)^{2}\\left[P_{N}\\left(x_{j}^{G}\\right)\\right]^{2}},j=0,\\cdots,N\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#legendre-gauss-radau-quadratures",
    "href": "legendre-polynomials.html#legendre-gauss-radau-quadratures",
    "title": "Legendre polynomials",
    "section": "Legendre Gauss-Radau Quadratures",
    "text": "Legendre Gauss-Radau Quadratures\nJacobi Gauss-Radau matrix for Legendre polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+1}^{R,a}=\\left\\{ {\\bf D}_{n+1},{\\bf E}_{n+1}\\right\\}\\). The main diagonal \\({\\bf D}_{n+1}\\) and sub-diagonal \\({\\bf E}_{n+1}\\) are given by\n\\[\n{\\bf D}_{n+1}=\\left[\\boldsymbol{0},\\alpha_{n}^{R}\\right]\\in R^{n+1}\n\\]\n\\[\n{\\bf E}_{n}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}}\\right]\\in R^{n}\n\\]\nWhere,\n\\[\n\\alpha_{n}^{R}=a\\left(\\frac{n+1}{2n+1}\\right)\n\\]\nThe \\(n+1\\) point Legendre Gauss-Radau Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{R},w_{j}^{R}\\right\\} _{j=0}^{n}\\), which are the eigenvalues of Jacobi Gauss-Radau matrix. The weights are given by\n\\[\nw_{j}=\\frac{1}{\\left(n+1\\right)^{2}}\\frac{1+ax_{j}^{R}}{\\left[P_{n}(x_{j}^{R})\\right]^{2}},j=0,\\cdots,n\n\\]\nThere is another point of view for understanding the Gauss-Radau quadrature points.\n\nFor \\(a=-1\\), \\(x_{0}=-1\\), and \\(n\\) points \\(x_{j}^{R},1=0,\\cdots n\\) are zeros of \\(P_{n}^{0,1}(x)\\) that is, \\[\nP_{n}^{0,1}(x_{j}^{R})=0,j=1,\\cdots n\n\\]\nFor \\(a=1\\), \\(x_{n}^{R}=1\\), and \\(n\\) points \\(x_{j}^{R},j=0,\\cdots n-1\\) are zeros \\(P_{n}^{1,0}(x)\\) that is, \\[\nP_{n}^{1,0}(x_{j}^{R})=0,j=0,\\cdots n-1\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#legendre-gauss-lobatto-quadratures",
    "href": "legendre-polynomials.html#legendre-gauss-lobatto-quadratures",
    "title": "Legendre polynomials",
    "section": "Legendre Gauss-Lobatto Quadratures",
    "text": "Legendre Gauss-Lobatto Quadratures\nJacobi Gauss-Lobatto matrix for Legendre polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n+2}^{L}=\\left\\{ {\\bf D}_{n+2},{\\bf E}_{n+2}\\right\\}\\). The main diagonal \\({\\bf D}_{n+2}\\) and sub-diagonal \\({\\bf E}_{n+2}\\) are given by\n\\[\n{\\bf D}_{n+2}=\\boldsymbol{0}\\in R^{n+2}\n\\]\n\\[\n{\\bf E}_{n+2}=\\left[\\sqrt{\\beta_{1}},\\sqrt{\\beta_{2}},\\cdots,\\sqrt{\\beta_{n-1}},\\sqrt{\\beta_{n}},\\sqrt{\\beta_{n+1}^{L}}\\right]\\in R^{n+1}\n\\]\n\\[\n\\beta_{n+1}^{L}=\\frac{n+1}{2n+1}\n\\]\nThe \\(n+2\\) point Jacobi Gauss-Lobatto quadrature rule is denoted by \\(\\left\\{ x_{j}^{L},w_{j}^{L}\\right\\} _{j=0}^{n+1}\\), which are the eigenvalues of Jacobi Gauss-Lobatto matrix.The weights are given by\n\\[\nw_{j}=\\frac{2}{\\left(n+2\\right)\\left(n+1\\right)}\\frac{1}{\\left[P_{n+1}(x_{j}^{R})\\right]^{2}},j=0,\\cdots,n+1\n\\]\nThere is another point of view for understanding the Gauss-Lobatto quadrature points.\n\n\\(x_{0}^{L}=-1\\) and \\(x_{n+1}^{L}=1\\), the \\(n\\) points \\(x_{j}^{L},j=1,\\cdots n\\) are zeros of \\(P_{n}^{1,1}(x)\\) , that is zeros of \\(\\frac{dP_{n+1}}{dx}\\)",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-points",
    "href": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-points",
    "title": "Legendre polynomials",
    "section": "Lagrange polynomial for Legendre-Gauss points",
    "text": "Lagrange polynomial for Legendre-Gauss points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-lobatto-points",
    "href": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-lobatto-points",
    "title": "Legendre polynomials",
    "section": "Lagrange polynomial for Legendre-Gauss-Lobatto points",
    "text": "Lagrange polynomial for Legendre-Gauss-Lobatto points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-radau-points",
    "href": "legendre-polynomials.html#lagrange-polynomial-for-legendre-gauss-radau-points",
    "title": "Legendre polynomials",
    "section": "Lagrange polynomial for Legendre-Gauss-Radau points",
    "text": "Lagrange polynomial for Legendre-Gauss-Radau points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Legendre polynomials</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html",
    "href": "chebyshev-polynomials.html",
    "title": "Chebyshev Polynomial",
    "section": "",
    "text": "First few Chebyshev polynomials\nChebyshev polynomial family has a simple explicit formula and is straightforward to compute. Chebyshev polynomials are proportional to the Jacobi polynomial, \\(P_{n}^{(-0.5,-0.5)}(x)\\), and denoted by \\(T_{n}(x)\\).\n\\[\nT_{n}(x)=\\frac{\\left(n!2^{n}\\right)^{2}}{(2n)!}P_{N}^{(-0.5,-0.5)}(x)\n\\]\n\\(T_{n}(x)\\) are orthogonal with respect to the weight:\n\\[\nw(x)=\\frac{1}{\\sqrt{1-x^{2}}}\n\\]\nThe support of Chebyshev polynomial is \\(\\left[-1,1\\right]\\).\n\\[\nT_{0}(x)=1\n\\]\n\\[\nT_{1}(x)=x\n\\]\n\\[\nT_{2}(x)=2x^{2}-1\n\\]\n\\[\nT_{3}(x)=4x^{3}-3x\n\\]\n\\[\nT_{4}(x)=8x^{4}-8x^{2}+1\n\\]\n\\[\nT_{5}(x)=16x^{5}-20x^{3}+5x\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#leading-coefficient",
    "href": "chebyshev-polynomials.html#leading-coefficient",
    "title": "Chebyshev Polynomial",
    "section": "Leading coefficient",
    "text": "Leading coefficient\nThe leading coefficient of \\(T_{n}\\) is denoted by \\(k_{n}\\), and it is given by\n\\[\nk_{n}=2^{n-1}c_{n}\n\\]\n\\[\nc_{n}=\\begin{cases}\n2 & n=0\\\\\n1 & n\\ge1\n\\end{cases}\n\\]\n\\[\n\\frac{k_{n+1}}{k_{n}}=\\frac{2}{c_{n}},\\quad n\\ge0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#norm",
    "href": "chebyshev-polynomials.html#norm",
    "title": "Chebyshev Polynomial",
    "section": "Norm",
    "text": "Norm\nThe norm of \\(T_{n}\\) is given below:\n\\[\n\\Vert T_{n}\\Vert^{2}=:h_{n}=\\frac{c_{n}\\pi}{2}=\\begin{cases}\n\\pi & n=0\\\\\n\\frac{\\pi}{2} & n\\ge1\n\\end{cases}\n\\]\n\\[\n\\frac{h_{n-1}}{h_{n}}=c_{n}\n\\]\n\\[\n\\frac{h_{n+1}}{h_{n}}=\\frac{1}{c_{n+1}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#symmetry",
    "href": "chebyshev-polynomials.html#symmetry",
    "title": "Chebyshev Polynomial",
    "section": "Symmetry",
    "text": "Symmetry\n\\[\nT_{n}(-x)=\\left(-1\\right)^{n}T_{n}(x)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#scaling",
    "href": "chebyshev-polynomials.html#scaling",
    "title": "Chebyshev Polynomial",
    "section": "Scaling",
    "text": "Scaling\n\\[\nT_{n}\\left(\\pm1\\right)=\\left(\\pm1\\right)^{n}\n\\]\n\\[\n\\frac{d}{dx}T_{n}\\left(\\pm1\\right)=\\left(\\pm1\\right)^{n+1}n^{2}\n\\]\n\\[\n\\frac{d^{2}}{dx^{2}}T_{n}\\left(\\pm1\\right)=\\frac{1}{3}\\left(\\pm1\\right)^{n}n^{2}\\left(n^{2}-1\\right)\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#boundedness",
    "href": "chebyshev-polynomials.html#boundedness",
    "title": "Chebyshev Polynomial",
    "section": "Boundedness",
    "text": "Boundedness\n\\[\n\\vert T_{n}(x)\\vert\\le1,\\quad\\left|\\frac{dT_{n}}{dt}\\right|\\le n^{2}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#derivatives",
    "href": "chebyshev-polynomials.html#derivatives",
    "title": "Chebyshev Polynomial",
    "section": "Derivatives",
    "text": "Derivatives",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#orthogonality",
    "href": "chebyshev-polynomials.html#orthogonality",
    "title": "Chebyshev Polynomial",
    "section": "Orthogonality",
    "text": "Orthogonality\n\\[\n\\int_{-1}^{+1}T_{m}(x)T_{n}(x)\\frac{1}{\\sqrt{1-x^{2}}}dx=\\frac{c_{n}\\pi}{2}\\delta_{mn}\n\\]\n\\[\n\\int_{-1}^{+1}\\frac{dT_{m}(x)}{dx}\\frac{dT_{n}(x)}{dx}\\sqrt{1-x^{2}}dx=\\frac{n^{2}c_{n}\\pi}{2}\\delta_{mn}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#polynomial-representation",
    "href": "chebyshev-polynomials.html#polynomial-representation",
    "title": "Chebyshev Polynomial",
    "section": "Polynomial representation",
    "text": "Polynomial representation",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#strum-liovile-equation",
    "href": "chebyshev-polynomials.html#strum-liovile-equation",
    "title": "Chebyshev Polynomial",
    "section": "Strum-Liovile equation",
    "text": "Strum-Liovile equation\n\\[\n\\frac{d}{dx}\\left(\\sqrt{1-x^{2}}\\frac{dT_{n}}{dx}\\right)+\\frac{\\lambda_{n}}{\\sqrt{1-x^{2}}}T_{n}=0\n\\]\nwhere, the eigenvalue \\(\\lambda_{n}=n^{2}\\).\nIf we set \\(x=\\cos\\theta\\), then\n\\[\n\\frac{d^{2}T_{n}(\\theta)}{d\\theta^{2}}+\\lambda_{n}T_{n}(\\theta)=0\n\\]\ntherefore, \\(T_{n}(\\theta)=\\cos\\left(n\\theta\\right)\\).",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#rodriguess-formula",
    "href": "chebyshev-polynomials.html#rodriguess-formula",
    "title": "Chebyshev Polynomial",
    "section": "Rodrigues’s Formula",
    "text": "Rodrigues’s Formula\n\\[\nT_{n}(x)=\\frac{\\left(-1\\right)^{n}n!2^{n}}{(2n)!}\\sqrt{1-x^{2}}\\frac{d^{n}}{dx^{n}}\\left[\\left(1-x^{2}\\right)^{n-\\frac{1}{2}}\\right]\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-monic-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-monic-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for monic polynomial",
    "text": "Recurrence relation for monic polynomial\nLet \\(\\pi_{n}\\) denotes the monic orthogonal Chebyshev polynomial of first kind.\n\\[\n\\pi_{n+1}=\\left(x-\\alpha_{n}\\right)\\pi_{n}-\\beta_{n}\\pi_{n-1},\\quad n=0,1,2\n\\]\n\\[\n\\alpha_{n}=0,n\\ge0\n\\]\n\\[\n\\beta_{0}=\\pi\n\\]\n\\[\n\\beta_{n\\ge1}=\\frac{c_{n-1}}{4}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-monic-orthonormal-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-monic-orthonormal-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for monic orthonormal polynomial",
    "text": "Recurrence relation for monic orthonormal polynomial\nLet \\(\\tilde{\\pi}_{n}\\) denotes the monic orthonormal Chebyshev polynomial of first kind.\n\\[\n\\tilde{\\pi}_{n+1}=\\frac{\\left(x-\\alpha_{n}\\right)}{\\sqrt{\\beta_{n+1}}}\\tilde{\\pi}_{n}-\\frac{\\beta_{n}}{\\sqrt{\\beta_{n+1}\\beta_{n}}}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\n\\]\nor\n\\[\n\\tilde{\\pi}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{\\pi}_{n}-\\beta_{n}s_{n}^{b}\\tilde{\\pi}_{n-1},\\quad n=0,1,2\n\\]\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}=\\frac{2}{\\sqrt{c_{n}}}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-chebyshev-polynomials",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-chebyshev-polynomials",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for Chebyshev polynomials",
    "text": "Recurrence relation for Chebyshev polynomials\nChebyshev polynomial \\(T_{n}\\) is neither monic nor orthonormal.\n\\[\nT_{-1}=0,\\quad T_{0}=1\n\\]\n\\[\nT_{1}=x\n\\]\n\\[\nT_{n+1}=2xT_{n}-T_{n-1},\\quad n\\ge1\n\\]\nor,\n\\[\nT_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}T_{n}-\\beta_{n}s_{n}^{b}T_{n-1},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{2}{c_{n}}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-orthonormal-chebyshev-polynomials",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-orthonormal-chebyshev-polynomials",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for orthonormal Chebyshev polynomials",
    "text": "Recurrence relation for orthonormal Chebyshev polynomials\nLet \\(\\tilde{T}_{n}\\) denote the orthonormal Chebyshev polynomials.\n\\[\n\\tilde{T}_{n+1}=\\left(x-\\alpha_{n}\\right)s_{n}^{a}\\tilde{P}_{n}-\\beta_{n}s_{n}^{b}\\tilde{P}_{n-1},\\quad n=0,1,2\n\\]\nwhere,\n\\[\ns_{n}^{a}=\\frac{1}{\\sqrt{\\beta_{n+1}}}=\\frac{2}{\\sqrt{c_{n}}}\n\\]\n\\[\ns_{n}^{b}=s_{n}^{a}s_{n-1}^{a}\n\\]\n\\[\ns_{0}^{b}=\\frac{s_{0}^{a}}{\\sqrt{\\beta_{0}}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-chebyshev-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-chebyshev-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for derivative of Chebyshev polynomial",
    "text": "Recurrence relation for derivative of Chebyshev polynomial\nThe gradient can be computed by following recurrence relationship:\n\\[\n\\left(1-x^{2}\\right)\\frac{dT_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}T_{n-1}+\\left(-nx\\right)T_{n}\n\\]\n\\[\n\\frac{d}{dx}T_{n}\\left(\\pm1\\right)=\\left(\\pm1\\right)^{n+1}n^{2}\n\\]\n\\[\ns_{n}^{a}=\\frac{k_{n+1}}{k_{n}}=\\frac{2}{c_{n}}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#more-recurrence-relation-for-derivative-of-chebyshev-polynomial",
    "href": "chebyshev-polynomials.html#more-recurrence-relation-for-derivative-of-chebyshev-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "More recurrence relation for derivative of Chebyshev polynomial",
    "text": "More recurrence relation for derivative of Chebyshev polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{dT_{n}}{dx}=\\frac{n}{2}T_{n-1}-\\frac{n}{2}T_{n+1}\n\\]\n\\[\nT_{n}=-\\frac{1}{2(n-1)}\\frac{dT_{n-1}}{dx}+\\frac{1}{2(n+1)}\\frac{dT_{n+1}}{dx}\n\\]\n\\[\n\\frac{dT_{n+1}}{dx}=2(n+1)T_{n}+\\frac{(n+1)}{(n-1)}\\frac{dT_{n-1}}{dx}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-chebyshev-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-orthonormal-chebyshev-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for derivative of orthonormal Chebyshev polynomial",
    "text": "Recurrence relation for derivative of orthonormal Chebyshev polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{T}_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}\\tilde{T}_{n-1}+\\left(-nx\\right)\\tilde{T}_{n}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}=\\begin{cases}\n\\frac{1}{\\sqrt{\\beta_{0}}} & n=0\\\\\n\\frac{2}{\\sqrt{c_{n-1}}} & n\\ge1\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-monic-chebyshev-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-monic-chebyshev-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for derivative of monic Chebyshev polynomial",
    "text": "Recurrence relation for derivative of monic Chebyshev polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\pi_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)\\pi_{n-1}+\\left(-nx\\right)\\pi_{n}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-chebyshev-polynomial",
    "href": "chebyshev-polynomials.html#recurrence-relation-for-derivative-of-monic-orthonormal-chebyshev-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Recurrence relation for derivative of monic orthonormal Chebyshev polynomial",
    "text": "Recurrence relation for derivative of monic orthonormal Chebyshev polynomial\n\\[\n\\left(1-x^{2}\\right)\\frac{d\\tilde{\\pi}_{n}}{dx}=\\beta_{n}\\left(2n+1\\right)s_{n-1}^{a}\\tilde{\\pi}_{n-1}+\\left(-nx\\right)\\tilde{\\pi}_{n}\n\\]\n\\[\ns_{n-1}^{a}=\\frac{1}{\\sqrt{\\beta_{n}}}=\\begin{cases}\n\\frac{1}{\\sqrt{\\beta_{0}}} & n=0\\\\\n\\frac{2}{\\sqrt{c_{n-1}}} & n\\ge1\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#kernel-polynomial",
    "href": "chebyshev-polynomials.html#kernel-polynomial",
    "title": "Chebyshev Polynomial",
    "section": "Kernel polynomial",
    "text": "Kernel polynomial",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#more-recurrence-results",
    "href": "chebyshev-polynomials.html#more-recurrence-results",
    "title": "Chebyshev Polynomial",
    "section": "More recurrence results",
    "text": "More recurrence results",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#additional-properties",
    "href": "chebyshev-polynomials.html#additional-properties",
    "title": "Chebyshev Polynomial",
    "section": "Additional properties",
    "text": "Additional properties",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#chebyshev-gauss-quadratures",
    "href": "chebyshev-polynomials.html#chebyshev-gauss-quadratures",
    "title": "Chebyshev Polynomial",
    "section": "Chebyshev-Gauss Quadratures",
    "text": "Chebyshev-Gauss Quadratures\nJacobi-matrix for Chebyshev polynomials is a symmetric tridiagonal matrix \\({\\bf J}_{n}=\\left\\{ {\\bf D}_{n},{\\bf E}_{n}\\right\\}\\). The main diagonal \\({\\bf D}_{n}\\) and sub-diagonal \\({\\bf E}_{n}\\) are given by\n\\[\n{\\bf D}_{n}=\\boldsymbol{0}\\in R^{n}\n\\]\n\\[\n{\\bf E}_{n}=\\left[\\sqrt{2},2\\cdots,2\\right]\\in R^{n-1}\n\\]\n\nThe \\(N+1\\) point Chebyshev-Gauss quadrature rule is denoted by \\(\\left\\{ x_{j}^{G},w_{j}^{G}\\right\\} _{j=0}^{N}\\).\nThe points \\(x_{j}^{G}\\) are zeros of \\(T_{N+1}\\), that is\n\n\\[\nT_{N+1}(x_{j}^{G})=\\cos\\left(N+1\\right)\\theta=0,j=0,1,\\cdots,N\n\\]\n\nand \\(\\left\\{ x_{j}^{G}\\right\\}_{j=0}^{N}\\) are the eigenvalues of Jacobi matrix \\({\\bf J}_{N+1}\\) :\n\n\\[\nx_{j}^{G}=-\\cos\\frac{(2j+1)\\pi}{2N+2},j=0,\\cdots,N\n\\]\n\nWeights are given by\n\n\\[\nw_{j}=\\frac{\\pi}{N+1},j=0,\\cdots,N\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#chebyshev-gauss-radau-quadratures",
    "href": "chebyshev-polynomials.html#chebyshev-gauss-radau-quadratures",
    "title": "Chebyshev Polynomial",
    "section": "Chebyshev Gauss-Radau Quadratures",
    "text": "Chebyshev Gauss-Radau Quadratures\n\nLeft Chebyshev Gauss-Radau quadratures:\n\n\\[\nx_{j}^{R}=-\\cos\\frac{2\\pi j}{2N+1},j=0,\\cdots,N\n\\]\n\\[\nw_{0}^{R}=\\frac{\\pi}{2N+1}\n\\]\n\\[\nw_{j}^{R}=\\frac{2\\pi}{2N+1},j=1,\\cdots,N\n\\]\n\nRight Chebyshev Gauss-Radau quadratures:\n\n\\[\nx_{j}^{R}=-\\cos\\frac{(2j+1)\\pi}{2N+1},j=0,\\cdots,N\n\\]\n\\[\nw_{0}^{R}=\\frac{\\pi}{2N+1}\n\\]\n\\[\nw_{j}^{R}=\\frac{2\\pi}{2N+1},j=1,\\cdots,N\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#chebyshev-gauss-lobatto-quadratures",
    "href": "chebyshev-polynomials.html#chebyshev-gauss-lobatto-quadratures",
    "title": "Chebyshev Polynomial",
    "section": "Chebyshev Gauss-Lobatto Quadratures",
    "text": "Chebyshev Gauss-Lobatto Quadratures\n\\[\nx_{j}^{L}=-\\cos\\frac{\\pi j}{N},j=0,\\cdots,N\n\\]\n\\[\nw_{0}^{R}=w_{N}^{R}=\\frac{\\pi}{2N}\n\\]\n\\[\nw_{j}^{R}=\\frac{\\pi}{N},j=1,\\cdots,N-1\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-points",
    "href": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-points",
    "title": "Chebyshev Polynomial",
    "section": "Lagrange polynomial for Chebyshev-Gauss points",
    "text": "Lagrange polynomial for Chebyshev-Gauss points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-lobatto-points",
    "href": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-lobatto-points",
    "title": "Chebyshev Polynomial",
    "section": "Lagrange polynomial for Chebyshev-Gauss-Lobatto points",
    "text": "Lagrange polynomial for Chebyshev-Gauss-Lobatto points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-radau-points",
    "href": "chebyshev-polynomials.html#lagrange-polynomial-for-chebyshev-gauss-radau-points",
    "title": "Chebyshev Polynomial",
    "section": "Lagrange polynomial for Chebyshev-Gauss-Radau points",
    "text": "Lagrange polynomial for Chebyshev-Gauss-Radau points",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chebyshev Polynomial</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html",
    "href": "lobatto-polynomials.html",
    "title": "Lobatto Polynomials",
    "section": "",
    "text": "Lobatto polynomials as Jacobi polynomials\n\\[\nl_{0}\\left(x\\right)=\\frac{1-x}{2}=\\frac{1}{2}P_{0}-\\frac{1}{2}P_{1}\n\\]\n\\[\nl_{1}\\left(x\\right)=\\frac{1+x}{2}=\\frac{1}{2}P_{0}+\\frac{1}{2}P_{1}\n\\]\n\\[\nl_{m+2}\\left(x\\right)=\\frac{1}{\\Vert P_{m+1}\\Vert}\\int_{-1}^{x}P_{m+1}(x)dx,\\quad m\\ge0\n\\]\nwhere,\n\\[\n\\Vert P_{m+1}\\Vert=\\sqrt{\\frac{2}{2m+3}}\n\\]\nor,\n\\[\nl_{m}\\left(x\\right)=\\frac{1}{\\Vert P_{m-1}\\Vert}\\int_{-1}^{x}P_{m-1}(x)dx,\\quad m\\ge2\n\\]\nwhere,\n\\[\n\\Vert P_{m-1}\\Vert=\\sqrt{\\frac{2}{2m-1}}\n\\]\nso,\n\\[\nl_{m+2}\\left(x\\right)=\\sqrt{\\frac{2m+3}{2}}\\int_{-1}^{x}P_{m+1}(x)dx,\\quad m\\ge0\n\\]\nNoting that\n\\[\nP_{m}\\left(x\\right)=\\frac{1}{2m+1}\\frac{d}{dx}\\left(P_{m+1}-P_{m-1}\\right)\n\\]\nIt can be shown that\n\\[\nl_{m+2}\\left(x\\right)=\\frac{1}{\\sqrt{2\\left(2m+3\\right)}}\\left[P_{m+2}\\left(x\\right)-P_{m}\\left(x\\right)\\right],\\quad m\\ge0\n\\]\nThe above expression can also be written as:\n\\[\nl_{m}\\left(x\\right)=\\frac{1}{\\sqrt{2\\left(2m-1\\right)}}\\left[P_{m}\\left(x\\right)-P_{m-2}\\left(x\\right)\\right],\\quad m\\ge2\n\\]\nLobatto polynomials can also be given by\n\\[\nl_{0}=\\frac{1-x}{2}=\\frac{1}{2}P_{0}-\\frac{1}{2}P_{1}\n\\]\n\\[\nl_{1}=\\frac{1+x}{2}=\\frac{1}{2}P_{0}+\\frac{1}{2}P_{1}\n\\]\n\\[\nl_{m+2}(x)=-l_{0}(x)l_{1}(x)\\frac{\\sqrt{2\\left(2m+3\\right)}}{m+1}P_{m}^{\\left(1,1\\right)}(x),\\quad m\\ge0\n\\]\nor\n\\[\nl_{m}(x)=-l_{0}(x)l_{1}(x)\\frac{\\sqrt{2\\left(2m-1\\right)}}{m-1}P_{m-2}^{\\left(1,1\\right)}(x),\\quad m\\ge2\n\\]\nwhere \\(P_{m}^{\\left(1,1\\right)}(x)\\) for \\(m=0,1,\\cdots\\) are the Jacobi polynomials. We can also write Lobatto polynomials in terms of Ultraspherical polynomials as shown below:\n\\[\nl_{m+2}(x)=-l_{0}(x)l_{1}(x)\\frac{\\sqrt{8\\left(2m+3\\right)}}{\\left(m+1\\right)\\left(m+2\\right)}P_{m}^{(1.5)}\\left(x\\right),\\quad m\\ge0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#first-few-lobatto-polynomials",
    "href": "lobatto-polynomials.html#first-few-lobatto-polynomials",
    "title": "Lobatto Polynomials",
    "section": "First few lobatto polynomials",
    "text": "First few lobatto polynomials\n\\[\nl_{0}=\\frac{1-x}{2}\n\\]\n\\[\nl_{1}=\\frac{1+x}{2}\n\\]\n\\[\nl_{2}=\\frac{1}{2}\\sqrt{\\frac{3}{2}}\\left(x^{2}-1\\right)\n\\]\n\\[\nl_{3}=\\frac{1}{2}\\sqrt{\\frac{5}{2}}\\left(x^{2}-1\\right)x\n\\]\n\\[\nl_{4}=\\frac{1}{8}\\sqrt{\\frac{7}{2}}\\left(x^{2}-1\\right)\\left(5x^{2}-1\\right)\n\\]\n\\[\nl_{5}=\\frac{1}{8}\\sqrt{\\frac{9}{2}}\\left(x^{2}-1\\right)\\left(7x^{2}-3\\right)x\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#derivative-of-lobatto-polynomials",
    "href": "lobatto-polynomials.html#derivative-of-lobatto-polynomials",
    "title": "Lobatto Polynomials",
    "section": "Derivative of lobatto polynomials",
    "text": "Derivative of lobatto polynomials\n\\[\n\\frac{dl_{m+2}}{dx}=\\sqrt{\\frac{2m+3}{2}}P_{m+1}(x),m\\ge0\n\\]\nor\n\\[\n\\frac{dl_{m}}{dx}=\\sqrt{\\frac{2m-1}{2}}P_{m-1}(x),m\\ge2\n\\]\nwe know that\n\\[\nP_{n-1}^{(\\lambda+1)}\\left(x\\right)=\\frac{1}{2\\lambda}\\frac{dP_{n}^{(\\lambda)}}{dx}\\left(x\\right),\\lambda&gt;-1/2\n\\]\n\\[\n\\frac{dl_{m}}{dx}\\left(x\\right)=\\sqrt{\\frac{2m-1}{2}}P_{m-1}^{(-1+1/2+1)}(x),m\\ge2\n\\]\n\\[\n\\frac{dl_{m}}{dx}\\left(x\\right)=\\sqrt{\\frac{2m-1}{2}}P_{m-1}^{(1/2)}(x),m\\ge2\n\\]\n\\[\n\\frac{dl_{0}}{dx}=-\\frac{1}{2}\n\\]\n\\[\n\\frac{dl_{1}}{dx}=\\frac{1}{2}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#leading-coefficients",
    "href": "lobatto-polynomials.html#leading-coefficients",
    "title": "Lobatto Polynomials",
    "section": "Leading coefficients",
    "text": "Leading coefficients\n\\[\nk_{0}=-\\frac{1}{2}\n\\]\n\\[\nk_{1}=\\frac{1}{2}\n\\]\n\\[\nk_{m+2}=\\frac{1}{\\sqrt{2\\left(2m+3\\right)}}\\frac{\\left(2m+4\\right)!}{2^{m+2}\\left[\\left(m+2\\right)!\\right]^{2}},\\quad m\\ge0\n\\]\n\\[\nk_{2}=\\sqrt{\\frac{3}{8}}\n\\]\n\\[\n\\frac{k_{1}}{k_{0}}=-1\n\\]\n\\[\n\\frac{k_{2}}{k_{1}}=\\sqrt{\\frac{3}{32}}\n\\]\n\\[\n\\frac{k_{m+3}}{k_{m+2}}=\\frac{\\sqrt{\\left(2m+3\\right)\\left(2m+5\\right)}}{\\left(m+3\\right)},\\quad m\\ge0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#norm",
    "href": "lobatto-polynomials.html#norm",
    "title": "Lobatto Polynomials",
    "section": "Norm",
    "text": "Norm\nWe define norm of lobatto polynomial as\n\\[\n\\int_{-1}^{1}\\left(l_{m}\\right)^{2}dx=:\\Vert l_{m}\\Vert^{2}=h_{m}\n\\]\n\\[\nh_{0}=\\Vert l_{0}\\Vert^{2}=\\frac{2}{3}\n\\]\n\\[\nh_{1}=\\Vert l_{1}\\Vert^{2}=\\frac{2}{3}\n\\]\n\\[\nh_{m+2}=\\Vert l_{m+2}\\Vert^{2}=\\frac{2}{\\left(2m+1\\right)\\left(2m+5\\right)}\n\\]\n\\[\n\\frac{h_{0}}{h_{1}}=1\n\\]\n\\[\n\\frac{h_{1}}{h_{2}}=\n\\]\n\\[\n\\frac{h_{m+2}}{h_{m+3}}=,\\quad m\\ge0\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#moments",
    "href": "lobatto-polynomials.html#moments",
    "title": "Lobatto Polynomials",
    "section": "Moments",
    "text": "Moments\n\\[\nl_{m+2}=\\frac{1}{\\sqrt{2\\left(2m+3\\right)}}\\left[P_{m+2}\\left(x\\right)-P_{m}\\left(x\\right)\\right],\\quad m\\ge0\n\\]\nZero moment\n\\[\n\\left\\langle l_{m}\\right\\rangle_{0}:=\\int_{-1}^{+1}l_{m}dx\n\\]\n\\[\n\\left\\langle l_{0}\\right\\rangle_{0}=\\left\\langle l_{1}\\right\\rangle_{0}=1\n\\]\n\\[\n\\left\\langle l_{m+2}\\right\\rangle_{0}=\\begin{cases}\n-\\sqrt{\\frac{2}{3}} & m=0\\\\\n0 & m\\ge1\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#mass-matrix",
    "href": "lobatto-polynomials.html#mass-matrix",
    "title": "Lobatto Polynomials",
    "section": "Mass matrix",
    "text": "Mass matrix\n\\[\n\\left(l_{0},l_{0}\\right)=\\frac{2}{3}\n\\]\n\\[\n\\left(l_{0},l_{1}\\right)=\\frac{1}{3}\n\\]\n\\[\n\\left(l_{0},l_{m+2}\\right)=\\begin{cases}\n-\\frac{1}{\\sqrt{6}} & m=0\\\\\n\\frac{1}{3\\sqrt{10}} & m=1\\\\\n0 & m\\ge2\n\\end{cases}\n\\]\n\\[\n\\left(l_{1},l_{1}\\right)=\\frac{2}{3}\n\\]\n\\[\n\\left(l_{1},l_{m+2}\\right)=\\begin{cases}\n-\\frac{1}{\\sqrt{6}} & m=0\\\\\n-\\frac{1}{3\\sqrt{10}} & m=1\\\\\n0 & m\\ge2\n\\end{cases}\n\\]\n\\[\n\\left(l_{m+2},l_{m+2}\\right)=\\frac{2}{\\left(2m+1\\right)\\left(2m+5\\right)}\n\\]\n\\[\n\\left(l_{m+2},l_{m+4}\\right)=\\frac{-1}{\\left(2m+5\\right)\\sqrt{\\left(2m+7\\right)\\left(2m+3\\right)}}\n\\]\n\\[\nM=\\left[\\begin{array}{cccccccc}\nl_{00} & l_{01} & l_{02} & l_{03} & 0 & 0 & 0 & \\cdots\\\\\nl_{10} & l_{11} & l_{12} & l_{13} & 0 & 0 & 0 & \\cdots\\\\\nl_{20} & l_{21} & l_{22} & 0 & l_{24} & 0 & 0 & \\cdots\\\\\nl_{30} & l_{31} & 0 & l_{33} & 0 & l_{35} & 0 & \\cdots\\\\\n0 & 0 & l_{42} & 0 & l_{44} & 0 & l_{46} & \\cdots\\\\\n0 & 0 & 0 & l_{53} & 0 & l_{55} & 0 & \\cdots\\\\\n0 & 0 & 0 & 0 & l_{64} & 0 & l_{66} & \\cdots\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n\\end{array}\\right]\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#stiffness-matrix",
    "href": "lobatto-polynomials.html#stiffness-matrix",
    "title": "Lobatto Polynomials",
    "section": "Stiffness matrix",
    "text": "Stiffness matrix\n\\[\na(l_{m},l_{n})=\\int_{-1}^{+1}\\frac{dl_{m}}{dx}\\frac{dl_{n}}{dx}dx\n\\]\n\\[\na(l_{0},l_{0})=\\frac{1}{2},\\quad a(l_{0},l_{1})=-\\frac{1}{2}\n\\]\n\\[\na(l_{1},l_{0})=-\\frac{1}{2},\\quad a(l_{1},l_{1})=\\frac{1}{2}\n\\]\n\\[\na(l_{0},l_{m+2})=0,\\quad m\\ge0\n\\]\n\\[\na(l_{1},l_{m+2})=0,\\quad m\\ge0\n\\]\n\\[\na\\left(l_{m+2},l_{n+2}\\right)=\\begin{cases}\n1 & m=n\\ge0\\\\\n0 & m\\ne n\n\\end{cases}\n\\]\n\\[\nK=\\left[\\begin{array}{ccccc}\n0.5 & -0.5 & 0 & 0 & 0\\\\\n-0.5 & 0.5 & 0 & 0 & 0\\\\\n0 & 0 & 1.0 & 0 & 0\\\\\n0 & 0 & 0 & 1.0 & 0\\\\\n0 & 0 & 0 & 0 & 1.0\n\\end{array}\\right]\n\\]",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#zeros",
    "href": "lobatto-polynomials.html#zeros",
    "title": "Lobatto Polynomials",
    "section": "Zeros",
    "text": "Zeros\nZero of \\(l_{0}=1\\), zero of \\(l_{1}=-1\\), and by noting that\n\\[\nl_{m+2}=\\sqrt{\\frac{\\left(2m+3\\right)}{2\\left(m+1\\right)^{2}(m+2)^{2}}}\\left(x^{2}-1\\right)\\frac{dP_{m+1}}{dx}\n\\]\nzeros of \\(l_{m+2}\\) are \\(\\bar{\\pm1}\\), and zeros of \\(\\frac{dP_{m+1}}{dx}\\) or \\(P_{m}^{1,1}\\).",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "lobatto-polynomials.html#derivation-of-kernel-polynomials",
    "href": "lobatto-polynomials.html#derivation-of-kernel-polynomials",
    "title": "Lobatto Polynomials",
    "section": "Derivation of kernel polynomials",
    "text": "Derivation of kernel polynomials\nBy noting that:\n\\[\n\\begin{aligned}\\left(1-x^{2}\\right)\\frac{dP_{m}}{dx} & =\\frac{m(m+1)}{2m+1}\\left[P_{m-1}(x)-P_{m+1}(x)\\right]\\\\\n& =-\\frac{m(m+1)}{2m+1}\\sqrt{2\\left(2m+1\\right)}l_{m+1}\\\\\n& =-m(m+1)\\sqrt{\\frac{2}{\\left(2m+1\\right)}}l_{m+1}\n\\end{aligned}\n\\]\nwe get:\n\\[\n\\begin{aligned}l_{m+1}(x) & =\\sqrt{\\frac{\\left(2m+1\\right)}{2m^{2}(m+1)^{2}}}\\left(x^{2}-1\\right)\\frac{dP_{m}}{dx}\\\\\n& =\\sqrt{\\frac{\\left(2m+1\\right)}{2m^{2}(m+1)^{2}}}\\left(x^{2}-1\\right)\\frac{m+1}{2}P_{m-1}^{1,1}(x)\\\\\n& =\\sqrt{\\frac{\\left(2m+1\\right)}{8m^{2}}}\\left(x^{2}-1\\right)P_{m-1}^{1,1}(x)\\\\\n& =-\\frac{\\left(1-x^{2}\\right)}{4}\\sqrt{\\frac{16\\left(2m+1\\right)}{8m^{2}}}P_{m-1}^{1,1}(x)\\\\\n& =-l_{0}(x)l_{1}(x)\\sqrt{\\frac{16\\left(2m+1\\right)}{8m^{2}}}P_{m-1}^{1,1}(x)\n\\end{aligned}\n\\]\ntherefore,\n\\[\n\\phi_{m-1}(x)=-\\frac{\\sqrt{2\\left(2m+1\\right)}}{m}P_{m-1}^{1,1}(x)\n\\]\nNow we use following definition of ultraspherical polynomials:\n\\[\nP_{m}^{\\alpha+\\frac{1}{2}}(x)=\\frac{\\Gamma\\left(\\alpha+1\\right)}{\\Gamma\\left(2\\alpha+1\\right)}\\frac{\\Gamma\\left(m+2\\alpha+1\\right)}{\\Gamma\\left(m+\\alpha+1\\right)}P_{m}^{\\alpha,\\alpha}(x),\\quad\\alpha=\\lambda-\\frac{1}{2}\n\\]\nthen by setting \\(\\alpha=1\\), we get:\n\\[\nP_{m}^{1+\\frac{1}{2}}(x)=\\frac{\\Gamma\\left(2\\right)}{\\Gamma\\left(3\\right)}\\frac{\\Gamma\\left(m+3\\right)}{\\Gamma\\left(m+2\\right)}P_{m}^{1,1}(x)=\\frac{m+2}{2}P_{m}^{1,1}(x)\n\\]\nor\n\\[\nP_{m}^{1,1}(x)=\\frac{2}{m+2}P_{m}^{1.5}(x)\n\\]\nsubtituting the above expression in kernel polynomial:\n\\[\n\\phi_{m-1}=-\\frac{\\sqrt{8\\left(2m+1\\right)}}{m\\left(m+1\\right)}P_{m-1}^{1.5}(x)\n\\]\nThis completes the proof.",
    "crumbs": [
      "Orthogonal polynomial",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Lobatto Polynomials</span>"
    ]
  },
  {
    "objectID": "orthogonal-polynomial-expansion.html",
    "href": "orthogonal-polynomial-expansion.html",
    "title": "Orthogonal Polynomial expansions",
    "section": "",
    "text": "Continuous expansion\nLet \\(u(x)\\) be any continuous function defined over \\(\\left[-1,1\\right]\\) and \\(p_{n}(x)\\) be an orthogonal polynomial of degree \\(n\\) and \\(\\lambda&gt;-\\frac{1}{2}\\) . Then the continuous polynomial expansion of \\(u\\) in terms of \\(p_{n}(x)\\) is given by:\n\\[\nu(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}p_{n}(x)\n\\]\nwhere,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert p_{n}\\Vert^{2}}\\int_{-1}^{+1}u(x)p_{n}(x)w(x)dx\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) has a similar expansion with coefficients \\(\\hat{u}_{n}^{(m)}\\):\n\\[\n\\partial_{x}^{m}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(m)}p_{n}(x)\n\\]\n\n\nTruncated expansion\nIn practice, we employ truncated polynomial expansion by using orthognonal polynomials \\(\\left\\{ p_{n}\\right\\}_{n=0}^{N}\\):\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}p_{n}(x)\n\\]\nwhere,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert p_{n}\\Vert^{2}}\\int_{-1}^{+1}u(x)p_{n}(x)w(x)dx\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) in the frequency space is given by:\n\\[\n\\mathcal{P}_{N}\\partial_{x}^{m}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}^{(m)}p_{n}(x)\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) in the physical space is given by:\n\\[\n\\mathcal{P}_{N}\\partial_{x}^{m}u(x)=\\sum_{j=0}^{N}\\hat{u}_{n}\\partial_{x}^{m}l_{j}(x)\n\\]\nwhere, \\(l_{j}(x)\\) is the Lagrange polynomial of order \\(N\\) (the details are given in forthcoming sections).\n\n\nDiscrete expansion\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) be a set of Gauss, Gauss-Radau or Gauss-Lobatto quadrature nodes and weights. Let \\(f,g\\in L_{w}^{2}\\left[-1,1\\right]\\), then we can use the quadrature points to evaluate the discrete inner product and norm as:\n\\[\n\\left(f,g\\right)_{w}=\\int_{-1}^{+1}f(x)g(x)w(x)dx\\Rightarrow\\left(f,g\\right)_{w,N}=\\sum f(x_{i})g(x_{i})w_{i}\n\\]\n\\[\n\\Vert f\\Vert_{w}^{2}=\\left(f,f\\right)_{w}\\Rightarrow\\Vert f\\Vert_{w,N}^{2}=\\sum_{i=0}^{N}f(x_{i})g(x_{i})w_{i}\n\\]\nwhere, \\(\\left(f,g\\right)_{w,N}\\) and \\(\\Vert f\\Vert_{w,N}^{2}\\) are the discrete inner product and discrete norm.\n\nNote that discrete inner products and norms are approximation to their continuous counterparts, and the exactness of Gauss-type quadrature rules implies:\n\n\\[\n\\left(f,g\\right)_{w,N}=\\left(f,g\\right)_{w},\\forall f,g\\in P_{2N+q}\n\\]\nwhere, \\(q=1,0,-1\\) for Gauss, Gauss-Radau, and Gauss-Lobatto quadrature rules.\n\n\\(N+1\\) Gauss-Quadrature rule is accurate upto \\(2N+1\\) order polynomial\n\\(N+1\\) Gauss-Radau Quadrature rule is accurate upto \\(2N\\) order polynomial\n\\(N+1\\) Gauss-Lobatto Quadrature rule is accurate upto \\(2N-1\\) order polynomial\n\nIf \\(f\\in\\mathcal{P}_{N}\\) then, the \\(f^{2}\\in\\mathcal{P}_{2N}\\), therefore, \\(N+1\\) Gauss points and Gauss-Radau points are enough for computing the norm. However, Gauss-Lobatto points are not enough to compute the norm. In practice, Gauss-Lobatto rules are very useful as they include boundary nodes. Thanks to following lemma we can compute the equivalent norm by using the Gauss-Lobatto points.\nNow, we can describe the discrete polynomial expansion as:\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\n\\]\nwhere \\(\\tilde{u}_{n}\\) are the coefficients of discrete expansion:\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert p_{n}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})p_{n}(x_{j})w_{j}\n\\]\n\nIt is noteworthy that \\(\\Vert p_{N}\\Vert_{N}^{2}\\) would be exact for Gauss and Gauss-Radau quadratures, but it would be approximate for Gauss-Lobatto points.\n\\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) denotes value of \\(u\\) at quadrature points, we will refer it to nodal-values in physical space, or simply nodal values of \\(u\\).\n\\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) denotes the coefficient of polynomial expansion, we will refer it to modal-values in frequency space, or simply modal values \\(u\\).\nComputing \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) from \\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) will be refered to as forward discrete polynomial transform.\nComputing \\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) will be refered to as inverse discrete polynomial transform.\n\n\n\nCardinal function\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) defines a quadrature rule of N+1 points. Now consider the following discrete polynomial expansion:\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\n\\]\nwhere,\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert p_{n}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})p_{n}(x_{j})w_{j}\n\\]\nThen,\n\\[\n\\begin{aligned}\\mathcal{I}_{N}u(x) & =\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\\\\\n& =\\sum_{n=0}^{N}\\frac{1}{\\Vert p_{n}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})p_{n}(x_{j})w_{j}p_{n}(x)\\\\\n& =\\sum_{j=0}^{N}\\left(w_{j}\\sum_{n=0}^{N}\\frac{p_{n}(x)p_{n}(x_{j})}{\\Vert p_{n}\\Vert_{N}^{2}}\\right)u(x_{j})\\\\\n& \\sum_{j=0}^{N}l_{j}\\left(x\\right)u(x_{j})\n\\end{aligned}\n\\]\nwhere, \\(l_{j}(x)\\) is the generalized Lagrange polynomial (or cardinal function) satisfying \\(l_{j}\\left(x_{i}\\right)=\\delta_{ij}\\).\n\\[\nl_{j}\\left(x\\right)=w_{j}\\sum_{n=0}^{N}\\frac{p_{n}(x)p_{n}(x_{j})}{\\Vert p_{n}\\Vert_{N}^{2}}\n\\]\nThe right hand side can be evaluated by using Christoff-Darboux formula.\n\\[\n\\sum_{n=0}^{N}\\frac{p_{n}(x)p_{n}(x_{j})}{\\Vert p_{n}\\Vert_{N}^{2}}=\\begin{cases}\n\\frac{1}{\\Vert p_{N}\\Vert_{N}^{2}}\\frac{k_{N}}{k_{N+1}}\\left(\\frac{p_{N+1}\\left(x\\right)p_{N}\\left(x_{j}\\right)-p_{N}\\left(x\\right)p_{N+1}\\left(x_{j}\\right)}{x-x_{j}}\\right) & x\\ne x_{j}\\\\\n\\frac{1}{\\Vert p_{N}\\Vert_{N}^{2}}\\frac{k_{N}}{k_{N+1}}\\left[\\partial_{x}p_{N+1}\\left(x_{j}\\right)p_{N}\\left(x_{j}\\right)-\\partial_{x}p_{N}\\left(x_{j}\\right)p_{N+1}\\left(x_{j}\\right)\\right] & x=x_{j}\n\\end{cases}\n\\]\nwhere, \\(k_{N}\\) is the leading coefficient of \\(p_{N}(x)\\).\n\n\nOrthogonal projection and Aliasing error\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) defines a quadrature rule of N+1 points. Now consider the following discrete polynomial expansion:\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\n\\]\nwe have\n\\[\n\\mathcal{I}_{N}u(x_{i})=u\\left(x_{i}\\right)\n\\]\nTherefore, for any continuous function \\(v\\)\n\\[\n\\left(\\mathcal{I}_{N}u,v\\right)_{N}=\\left(u,v\\right)_{N}\n\\]\nTherefore, the interpolant \\(\\mathcal{I}_{N}u\\) is the orthognonal projection of \\(u\\) onto \\(\\mathbb{P}_{N}\\) with respect to the discrete inner product.\nIn general \\(\\tilde{u}_{n}\\) are approximation of \\(\\hat{u}_{n}\\), the error in this coefficient is called the aliasing error. This is because, in discrete case\n\\[\n\\left(p_{l},p_{k}\\right)_{N}\\ne0,\\forall l&gt;N,k=0,1,\\cdots,N\n\\]\nTherefore, from\n\\[\n\\tilde{u}_{k}=\\frac{1}{\\Vert p_{n}\\Vert_{N}^{2}}\\left(u,p_{k}\\right)_{N}\\forall k=0,1,\\cdots,N\n\\]\n\\[\n\\tilde{u}_{k}=\\hat{u}_{k}+\\frac{1}{\\Vert p_{k}\\Vert_{N}^{2}}\\sum_{l&gt;N}\\left(p_{l},p_{k}\\right)_{N}\\hat{u}_{l},\\forall k=0,1,\\cdots,N\n\\]\nThis means that the \\(k\\)th coefficient of interpolant depends on the kth mode (coefficient) of \\(u\\) and all the modes whose wavenumber is larger than \\(N\\).\nTherefore,\n\\[\n\\mathcal{I}_{N}u=\\mathcal{P}_{N}u+\\mathcal{R}_{N}u\n\\]\nwhere,\n\\[\n\\mathcal{R}_{N}u=\\sum_{k=0}^{N}\\left(\\frac{1}{\\Vert p_{k}\\Vert_{N}^{2}}\\sum_{l&gt;N}\\left(p_{l},p_{k}\\right)_{N}\\hat{u}_{l}\\right)p_{k}\n\\]\ncan be viewed as the aliasing error due to interpolation. The aliasing error is orthogonal to the truncation error \\(u-\\mathcal{P}_{N}u\\) so that\n\\[\n\\Vert u-\\mathcal{I}_{N}u\\Vert_{w}^{2}=\\Vert u-\\mathcal{P}_{N}u\\Vert_{w}^{2}+\\Vert\\mathcal{R}_{N}u\\Vert_{w}^{2}\n\\]\nNote that aliasing error will be zero if \\(u\\in\\mathbb{P}_{N}\\).\n\n\nDifferentiation in physical space\nIn the frequency space the discrete polynomial expansion is given by finite sum of orthogonal polynomials:\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\n\\]\nSimilary, in the physical space, we can write the discrete expansion by using the Lagrange polynomials with interpolation points as the Gauss quadrature points \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N}\\).\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})l_{j}(x)\n\\]\n\nAll Lagrange polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), are \\(N\\) order polynomials, and \\(l_{j}(x_{i})=\\delta_{ij}\\).\nLagrange polynomial depends upon the orthogonal polynomials and the quadrature rules. For example, for a given orthogonal polynomial family, the expression of Lagrange polynomials will be different for Gauss, Gauss-Radau, and Gauss-Lobatto polynomials.\n\nThe differentiation in physical space is given by:\n\\[\n\\partial_{x}^{m}\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x)\n\\]\nIf we evaluate the derivatives at quadrature points, then\n\\[\n\\begin{aligned}\\partial_{x}^{m}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\end{aligned}\n\\]\nConsider \\(m=1\\):\n\\[\n\\begin{aligned}\\partial_{x}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\\\\n& =\\sum_{j=0}^{N}u(x_{j})D_{ij}\n\\end{aligned}\n\\]\nwhere, \\(D_{ij}\\) is called the Differentiation matrix, which is a square matrix of size \\(N+1\\). In the matrix-vector form:\n\\[\n\\partial_{x}{\\bf u}={\\bf D}{\\bf u}\n\\]\n\nThe entries of matrix \\({\\bf D}\\) depend upon the orthogonal polynomial family, and quadrature type.\nIf the \\(N+1\\) quadrature points are zeros of polynomial \\(Q\\in P_{N+1}\\), (\\(Q\\) is also called the quadrature polynomial) then Lagrange polynomial and \\(D_{ij}\\) are given by:\n\n\\[\nl_{j}(x)=\\frac{Q(x)}{\\partial_{x}Q(x_{j})}\\frac{1}{\\left(x-x_{j}\\right)},j=0,\\cdots,N\n\\]\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}Q(x_{i})}{\\partial_{x}Q(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\\\\\n\\frac{\\partial_{x}^{2}Q(x_{i})}{2\\partial_{x}Q(x_{j})} & i=j\n\\end{cases}\n\\]\nQuadrature polynomial \\(Q\\) for Gauss, Gauss-Radau, and Gauss-Lobatto quadrature are given by\n\\[\nQ=\\begin{cases}\np_{N+1}(x) & \\text{Gauss}\\\\\np_{N+1}(x)-\\frac{p_{N+1}(a)}{p_{N}(a)}p_{N}(x) & \\text{Gauss-Radau}\\\\\np_{N+1}(x)+\\alpha_{N}p_{N}(x)+\\beta_{N}p_{N-1}(x) & \\text{Gauss-Lobatto}\n\\end{cases}\n\\]\nIn the case of Gauss-Radau \\(a\\in\\left\\{ -1,1\\right\\} ,\\)and in the case of Gauss-Lobatto, \\(\\alpha_{N}\\) and \\(\\beta_{N}\\) are obtained by solving following 2×2 system of equations:\n\\[\n\\left[\\begin{array}{cc}\np_{N}(-1) & p_{N-1}(-1)\\\\\np_{N}(1) & p_{N-1}(1)\n\\end{array}\\right]\\left\\{ \\begin{array}{c}\n\\alpha_{N}\\\\\n\\beta_{N}\n\\end{array}\\right\\} =-\\left\\{ \\begin{array}{c}\np_{N+1}(-1)\\\\\np_{N+1}(+1)\n\\end{array}\\right\\}\n\\]\n\nThe \\(m\\)th order derivative of \\(u\\) at quadrature point is given by:\n\n\\[\n\\partial_{x}^{m}{\\bf u}={\\bf D}^{m}{\\bf u}\n\\]\n\n\nDifferentiation in frequency space\nThe process of Differentiation in the frequency space is relatively simpler than that in the physical space. In the frequency space, \\(\\mathcal{I}_{N}u(x)\\in P_{N}\\),\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}p_{n}(x)\n\\]\nand \\(\\mathcal{I}_{N}\\partial_{x}u(x)\\in P_{N-1}\\)\n\\[\n\\mathcal{I}_{N}\\partial_{x}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}\\partial_{x}p_{n}(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}^{(1)}p_{n}(x)\n\\]\nwhere, \\(\\tilde{u}_{n}^{(1)}\\) are the modal coefficients for first derivative, and \\(\\tilde{u}_{N}^{(1)}=0\\).\nNow we want to express \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\) in terms of \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\). In the case of classical orthognonal polynomials \\(\\left\\{ \\partial_{x}p_{n}(x)\\right\\} _{n=0}^{N}\\)are also orthogonal. So, we have following three-term recurrence relationship:\n\\[\n\\partial_{x}p_{n+1}(x)=\\left(a_{n}^{(1)}x+b_{n}^{(1)}\\right)\\partial_{x}p_{n}(x)-c_{n}^{(1)}\\partial_{x}p_{n-1}(x)\n\\]\nIn addition, \\(\\left\\{ p_{n}(x)\\right\\}_{n=0}^{N}\\) satisfy:\n\\[\np_{n+1}(x)=\\left(a_{n}x+b_{n}\\right)p_{n}(x)-c_{n}p_{n-1}(x)\n\\]\nThen,\n\\[\n\\partial_{x}p_{n+1}=a_{n}p_{n}+a_{n}x\\partial_{x}p_{n}+b_{n}\\partial_{x}p_{n}-c_{n}\\partial_{x}p_{n-1}\n\\]\nor\n\\[\n\\begin{aligned}p_{n} & =\\frac{c_{n}}{a_{n}}\\partial_{x}p_{n-1}-\\left(x+\\frac{b_{n}}{a_{n}}\\right)\\partial_{x}p_{n}+\\frac{1}{a_{n}}\\partial_{x}p_{n+1}\\\\\n& =\\tilde{a}_{n}\\partial_{x}p_{n-1}+\\tilde{b}_{n}\\partial_{x}p_{n}+\\tilde{c}_{n}\\partial_{x}p_{n+1}\n\\end{aligned}\n\\]\nNow, we can use following backward subtitution algorithm to get \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\)from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\):\n\nInitialization: \\(\\tilde{u}_{N}^{(1)}=0\\), \\(\\tilde{u}_{N-1}^{(1)}=\\frac{1}{\\tilde{c}_{N-1}}\\tilde{u}_{N}\\)\nFor \\(n=N-1,\\cdots,1\\): \\(\\tilde{u}_{n-1}^{(1)}=\\frac{1}{\\tilde{c}_{n-1}}\\left[\\tilde{u}_{n}-\\tilde{b}_{n}\\tilde{u}_{n}^{(1)}-\\tilde{a}_{n+1}\\tilde{u}_{n+1}^{(1)}\\right]\\)\n\nSummary: Consider the nodal values in physical space, \\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\), then use Forward discrete polynomial transform to compute \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\), then we use backward subtitution scheme to compute, \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\), and finally perform inverse discrete polynomial transform to compute \\(\\frac{d}{dx}u(x_{j})\\).\n\n\nClenshaw’s algorithm\nClenshaw’s algorithm is an efficient way to evaluate the finite sum of orthogonal polynomials at given points. Let \\(p_{n}(x)\\) be the orthogonal polynomials with following three-term recurrence relationship:\n\\[\np_{n+1}=(x-\\alpha_{n})p_{n}-\\beta_{n}p_{n-1},n=0,1,\\cdots\n\\]\nwith given initial values \\(p_{0}\\)and \\(p_{-1}\\). Then we can evaluate the finite sum\n\\[\ns(x)=\\sum_{n=0}^{N}c_{n}p_{n}(x)\n\\]\nby using Clenshaw’s algorithm:\n\nInitialization: \\(u_{n}=c_{n},u_{n+1}=0\\)\nFor \\(k=n-1,\\cdots,0\\), do\n\n\\(u_{k}=(x-\\alpha_{k})u_{k+1}-\\beta_{k+1}u_{k+2}+c_{k}\\)\n\nResult: \\(s(x)=u_{0}p_{0}-\\beta_{0}u_{1}p_{-1}\\)\n\nNote that if \\(p_{-1}=0\\), then \\(s(x)=u_{0}p_{0}\\)\n\n\nConversion algorithm\nLet \\(\\left\\{ p_{n}\\right\\}\\) be the monic orthogonal polynomials satisfying the following three-term recurrence relation:\n\\[\np_{n+1}=(x-a_{n})p_{n}-b_{n}p_{n-1},n=0,1,\\cdots\n\\]\nwith, \\(p_{0}=1\\) and \\(p_{-1}=0\\). Let \\(\\left\\{ \\pi_{n}\\right\\}\\) be another monic orthogonal polynomials satisfying the following three-term recurrence relation:\n\\[\n\\pi_{n+1}=(x-\\alpha_{n})\\pi_{n}-\\beta_{n}\\pi_{n-1},n=0,1,\\cdots\n\\]\nwith, \\(\\pi_{0}=1\\) and \\(\\pi_{-1}=0\\). Now consider the finite sum:\n\\[\ns(x)=\\sum_{n=0}^{N}c_{n}p_{n}(x)\n\\]\nwe want to express this finite sum in terms of \\(\\pi_{n}(x)\\).\n\\[\ns(x)=\\sum_{n=0}^{N}d_{n}\\pi_{n}(x)\n\\]\nThen, \\(d_{n}\\) can be obtained by following algorithm:\n\nInitialization: \\(\\sigma_{00}=\\beta_{0}\\),\n\\(\\sigma_{-1,l}=0\\), \\(\\sigma_{k,k-1}=\\sigma_{k+1,k-1}=0\\), for \\(k=0,\\cdots,n\\)\nFor \\(l=0,1,\\cdots,n-1\\)\n\nFor \\(k=0,1,\\cdots,l+1\\)\n\n\\(\\sigma_{k,l+1}=\\sigma_{k+1,l}+(\\alpha_{k}-a_{l})\\sigma_{kl}+\\beta_{k}\\sigma_{k-1,l}-b_{l}\\sigma_{k,l-1}\\)\n\n\n\\(d_{k}=\\frac{1}{\\sigma_{kk}}\\sum_{l=k}^{n}\\sigma_{kl}c_{l}\\)\n\n\n\nBarrio-Clenshaw-Smith algorithm\n\n\nCompensated Clenshaw algorithm",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Orthogonal Polynomial expansions</span>"
    ]
  },
  {
    "objectID": "jacobi-polynomial-expansion.html",
    "href": "jacobi-polynomial-expansion.html",
    "title": "Jacobi Polynomial Expansion",
    "section": "",
    "text": "Continuous expansion\nLet \\(u(x)\\) be any continuous function defined over \\(\\left[-1,1\\right]\\) and \\(P_{n}^{(\\alpha,\\beta)}(x)\\) be the Jacobi polynomial of degree \\(n\\) and \\(\\alpha,\\beta&gt;-1\\) . Then the continuous polynomial expansion of \\(u\\) in terms of \\(P_{n}^{(\\alpha,\\beta)}(x)\\) is given by:\n\\[\nu(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nwhere,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert p_{n}\\Vert^{2}}\\int_{-1}^{+1}u(x)P_{n}^{(\\alpha,\\beta)}(x)\\left(1-x\\right)^{\\alpha}\\left(1+x\\right)^{\\beta}dx\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) has a similar expansion with coefficients \\(\\hat{u}_{n}^{(m)}\\):\n\\[\n\\partial_{x}^{m}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(m)}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\n\n\nTruncated expansion\nIn practice, we employ truncated polynomial expansion by using the finite number of Jacobi polynomials \\(\\left\\{ P_{n}^{(\\alpha,\\beta)}\\right\\}_{n=0}^{N}\\):\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nwhere,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert^{2}}\\int_{-1}^{+1}u(x)P_{n}^{(\\alpha,\\beta)}(x)w(x)dx\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) in the frequency space is given by:\n\\[\n\\mathcal{P}_{N}\\partial_{x}^{m}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}^{(m)}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) in the physical space is given by:\n\\[\n\\mathcal{P}_{N}\\partial_{x}^{m}u(x)=\\sum_{j=0}^{N}\\hat{u}_{n}\\partial_{x}^{m}l_{j}(x)\n\\]\nwhere, \\(l_{j}(x)\\) is the Lagrange polynomial of order \\(N\\) (the details are given in forthcoming sections).\n\n\nDiscrete expansion\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) be a set of Jacobi Gauss, Gauss-Radau or Gauss-Lobatto quadrature nodes and weights. The discrete Jacobi polynomial expansion is given by Inverse Discrete Jacobi Transform (or_Inverse Jacobi Transform_):\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nwhere \\(\\tilde{u}_{n}\\) are the coefficients of discrete polynomial expansion compute by Forward Discrete Jacobi Transform (or_Jacobi Transform_):\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\alpha,\\beta)}(x_{j})w_{j}\n\\]\n\nIt is noteworthy that \\(\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert_{N}^{2}\\) would be exact for Gauss and Gauss-Radau quadratures, but it would be approximate for Gauss-Lobatto points.\n\\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) denotes value of \\(u\\) at quadrature points, we will refer it to nodal-values in physical space, or simply nodal values of \\(u\\).\n\\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) denotes the coefficient of polynomial expansion, we will refer it to modal-values in frequency space, or simply modal values \\(u\\).\n\n\n\nDifferentiation in physical space\nIn the physical space, we can write the discrete Jacobi expansion by using the Lagrange polynomials with interpolation points as the Gauss quadrature points \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N}\\).\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})l_{j}(x)\n\\]\n\nAll Lagrange polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), are \\(N\\) order polynomials, and \\(l_{j}(x_{i})=\\delta_{ij}\\).\nLagrange polynomial depend upon the quadrature rules used in the discrete transformation.\n\nThe differentiation in physical space is given by:\n\\[\n\\partial_{x}^{m}\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x)\n\\]\nIf we evaluate the derivatives at quadrature points, then\n\\[\n\\begin{aligned}\\partial_{x}^{m}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\end{aligned}\n\\]\nConsider \\(m=1\\):\n\\[\n\\begin{aligned}\\partial_{x}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\\\\n& =\\sum_{j=0}^{N}u(x_{j})D_{ij}\n\\end{aligned}\n\\]\nwhere, \\(D_{ij}\\) is called the Differentiation matrix, which is a square matrix of size \\(N+1\\). In the matrix-vector form:\n\\[\n\\frac{d{\\bf u}}{dx}={\\bf D}{\\bf u}\n\\]\n\nThe entries of matrix \\({\\bf D}\\) depend upon the orthogonal polynomial family, and quadrature type.\nIf the \\(N+1\\) quadrature points are zeros of polynomial \\(Q\\in P_{N+1}\\), (\\(Q\\) is also called the quadrature polynomial) then Lagrange polynomial and \\(D_{ij}\\) are given by:\n\n\\[\nl_{j}(x)=\\frac{Q(x)}{\\partial_{x}Q(x_{j})}\\frac{1}{\\left(x-x_{j}\\right)},j=0,\\cdots,N\n\\]\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}Q(x_{i})}{\\partial_{x}Q(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\\\\\n\\frac{\\partial_{x}^{2}Q(x_{i})}{2\\partial_{x}Q(x_{j})} & i=j\n\\end{cases}\n\\]\nQuadrature polynomial \\(Q\\) for Gauss, Gauss-Radau, and Gauss-Lobatto quadrature are given by\n\\[\nQ=\\begin{cases}\nP_{N+1}^{(\\alpha,\\beta)}(x) & \\text{Gauss}\\\\\nP_{N+1}^{(\\alpha,\\beta)}(x)-\\frac{P_{N+1}^{(\\alpha,\\beta)}(a)}{P_{N}^{(\\alpha,\\beta)}(a)}P_{N}^{(\\alpha,\\beta)}(x) & \\text{Gauss-Radau}\\\\\nP_{N+1}^{(\\alpha,\\beta)}(x)+\\alpha_{N}P_{N}^{(\\alpha,\\beta)}(x)+\\beta_{N}P_{N-1}^{(\\alpha,\\beta)}(x) & \\text{Gauss-Lobatto}\n\\end{cases}\n\\]\nIn the case of Gauss-Radau \\(a\\in\\left\\{ -1,1\\right\\} ,\\)and in the case of Gauss-Lobatto, \\(\\alpha_{N}\\) and \\(\\beta_{N}\\) are obtained by solving following 2×2 system of equations:\n\\[\n\\left[\\begin{array}{cc}\nP_{N}^{(\\alpha,\\beta)}(-1) & P_{N-1}^{(\\alpha,\\beta)}(-1)\\\\\nP_{N}^{(\\alpha,\\beta)}(1) & P_{N-1}^{(\\alpha,\\beta)}(1)\n\\end{array}\\right]\\left\\{ \\begin{array}{c}\n\\alpha_{N}\\\\\n\\beta_{N}\n\\end{array}\\right\\} =-\\left\\{ \\begin{array}{c}\nP_{N+1}^{(\\alpha,\\beta)}(-1)\\\\\nP_{N+1}^{(\\alpha,\\beta)}(+1)\n\\end{array}\\right\\}\n\\]\n\nThe \\(m\\)th order derivative of \\(u\\) at quadrature point is given by:\n\n\\[\n\\frac{d^{m}{\\bf u}}{dx^{m}}={\\bf D}^{m}{\\bf u}\n\\]\n\n\nDerivative in frequency space\nThe process of Differentiation in the frequency space is relatively simpler than that in the physical space. In the frequency space, \\(\\mathcal{I}_{N}u(x)\\in P_{N}\\),\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nand \\(\\mathcal{I}_{N}\\frac{d}{dx}u(x)\\in P_{N-1}\\)\n\\[\n\\mathcal{I}_{N}\\frac{d}{dx}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}\\frac{d}{dx}P_{n}^{(\\alpha,\\beta)}(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}^{(1)}P_{n}^{(\\alpha,\\beta)}(x)\n\\]\nwhere, \\(\\tilde{u}_{n}^{(1)}\\) are the modal coefficients for first derivative, and \\(\\tilde{u}_{N}^{(1)}=0\\).\nWe can use following backward subtitution algorithm to get \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\)from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\):\n\nInitialization: \\(\\tilde{u}_{N}^{(1)}=0\\), \\(\\tilde{u}_{N-1}^{(1)}=\\frac{1}{\\tilde{c}_{N-1}}\\tilde{u}_{N}\\)\nFor \\(n=N-1,\\cdots,1\\): \\(\\tilde{u}_{n-1}^{(1)}=\\frac{1}{\\tilde{c}_{n-1}}\\left[\\tilde{u}_{n}-\\tilde{b}_{n}\\tilde{u}_{n}^{(1)}-\\tilde{a}_{n+1}\\tilde{u}_{n+1}^{(1)}\\right]\\)\n\nwhere,\n\\[\n\\tilde{a}_{n}=\\frac{-2\\left(n+\\alpha\\right)\\left(n+\\beta\\right)}{\\left(n+\\alpha+\\beta\\right)\\left(2n+\\alpha+\\beta\\right)\\left(2n+\\alpha+\\beta+1\\right)}\n\\]\n\\[\n\\tilde{b}_{n}=\\frac{2\\left(\\alpha-\\beta\\right)}{\\left(2n+\\alpha+\\beta\\right)\\left(2n+\\alpha+\\beta+2\\right)}\n\\]\n\\[\n\\tilde{c}_{n}=\\frac{2\\left(n+\\alpha+\\beta+1\\right)}{\\left(2n+\\alpha+\\beta+1\\right)\\left(2n+\\alpha+\\beta+2\\right)}\n\\]\n\\[\n\\tilde{c}_{0}=\\frac{2}{\\left(\\alpha+\\beta+2\\right)}\n\\]\n\n\nJacobi Gauss-Lobatto expansion\n\nJacobi Transformation:\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\alpha,\\beta)}(x_{j})w_{j}\n\\]\n\\[\n\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert_{N}^{2}=\\begin{cases}\n\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert^{2} & n&lt;N\\\\\n\\left(2+\\frac{\\alpha+\\beta+1}{N}\\right)\\Vert P_{N}^{(\\alpha,\\beta)}\\Vert^{2} & n=N\n\\end{cases}\n\\]\nwhere,\n\\[\n\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert^{2}=\\frac{2^{\\alpha+\\beta+1}}{2N+\\alpha+\\beta+1}\\frac{\\Gamma(N+\\alpha+1)\\Gamma(N+\\beta+1)}{N!\\Gamma(N+\\alpha+\\beta+1)}\n\\]\n\nInverse Jacobi Transformation:\n\n\\[\nu(x_{j})=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\alpha,\\beta)}(x_{j})\n\\]\nor\n\\[\n{\\bf u}={\\bf P}\\tilde{{\\bf u}}\n\\]\nwhere,\n\\[\nP_{ij}=P_{j}^{(\\alpha,\\beta)}(x_{i})\n\\]\n\\[\n\\tilde{{\\bf u}}=\\left[\\tilde{u}_{0},\\tilde{u}_{1},\\cdots,\\tilde{u}_{N}\\right]^{T}\n\\]\n\\[\n{\\bf u}=\\left[u(x_{0}),u(x_{1}),\\cdots,u(x_{N})\\right]^{T}\n\\]\nNote that inverse Jacobi transform is computed by using Clenshaw algorithm.\nDifferentiation in physical space is performed by using \\(D\\) matrix. The quadrature polynomial for Jacobi-Gauss-Lobatto expansion is given by:\n\\[\n\\begin{aligned}Q(x) & =\\left(1-x^{2}\\right)P_{N-1}^{(\\alpha+1,\\beta+1)}\\\\\n& =2\\left(a_{n}+x\\right)P_{n}^{(\\alpha,\\beta)}(x)-2b_{n}P_{n+1}^{(\\alpha,\\beta)}(x)\n\\end{aligned}\n\\]\nwhere,\n\\[\na_{n}=\\frac{\\alpha-\\beta}{\\left(2n+\\alpha+\\beta+2\\right)}\n\\]\n\\[\nb_{n}=\\frac{2n+2}{2n+\\alpha+\\beta+2}\n\\]\nLet\n\\[\nJ(x)=\\partial_{x}P_{N-1}^{(\\alpha+1,\\beta+1)}=\\partial_{x}P_{N}^{\\alpha+1,\\beta}(x)-\\partial_{x}P_{N}^{\\alpha,\\beta+1}(x)\n\\]\nThen,\n\\[\n\\partial_{x}Q(x_{j})=\\begin{cases}\n\\frac{2\\Gamma(N+\\beta+1)}{(-1)^{N-1}\\Gamma(N)\\Gamma(\\beta+2)} & j=0\\\\\n(1-x_{j}^{2})J(x_{j}) & j=1,\\cdots,N-1\\\\\n\\frac{-2\\Gamma(N+\\alpha+1)}{\\Gamma(N)\\Gamma(\\alpha+2)} & j=N\n\\end{cases}\n\\]\n\\[\n\\partial_{x}^{2}Q(x_{j})=\\begin{cases}\n\\frac{2\\left[\\alpha-N(N+\\alpha+\\beta+1)\\right]\\Gamma(N+\\beta+1)}{(-1)^{N+1}\\Gamma(N)\\Gamma(\\beta+3)} & j=0\\\\\n\\left[\\alpha-\\beta+\\left(\\alpha+\\beta\\right)x_{j}\\right]J(x_{j}) & j=1,\\cdots,N-1\\\\\n\\frac{2\\left[\\beta-N(N+\\alpha+\\beta+1)\\right]\\Gamma(N+\\alpha+1)}{\\Gamma(N)\\Gamma(\\alpha+3)} & j=N\n\\end{cases}\n\\]\nZeroth column of \\(D\\) matrix is given by:\n\\[\nD_{i0}=\\begin{cases}\n\\frac{\\alpha-N(N+\\alpha+\\beta+1)}{2(\\beta+2)} & i=0\\\\\n\\frac{\\left(-1\\right)^{N-1}\\Gamma(N)\\Gamma(\\beta+2)}{2\\Gamma(N+\\beta+1)}\\left(1-x_{i}\\right)J(x_{i}) & i=1,\\cdots,N-1\\\\\n\\frac{\\left(-1\\right)^{N}}{2}\\frac{\\Gamma(\\beta+2)\\Gamma(N+\\alpha+1)}{\\Gamma(N+\\beta+1)\\Gamma(\\alpha+2)} & i=N\n\\end{cases}\n\\]\nThe last column of \\(D\\) matrix is given by:\n\\[\nD_{iN}=\\begin{cases}\n\\frac{\\left(-1\\right)^{N+1}}{2}\\frac{\\Gamma(\\alpha+2)\\Gamma(N+\\beta+1)}{\\Gamma(N+\\alpha+1)\\Gamma(\\beta+2)} & i=0\\\\\n\\frac{\\Gamma(N)\\Gamma(\\alpha+2)}{2\\Gamma(N+\\alpha+1)}\\left(1+x_{i}\\right)J(x_{i}) & i=1,\\cdots,N-1\\\\\n\\frac{-\\beta+N(N+\\alpha+\\beta+1)}{2(\\alpha+2)} & i=N\n\\end{cases}\n\\]\nColumns 1 to \\(N-1\\) of \\(D\\) matrix are given by:\n\\[\nD_{ij}=\\begin{cases}\n\\frac{2\\left(-1\\right)^{N}\\Gamma(N+\\beta+1)}{\\Gamma(N)\\Gamma(\\beta+2)(1-x_{j})(1+x_{j})^{2}J(x_{j})} & i=0\\\\\n\\frac{(1-x_{i}^{2})J(x_{i})}{(1-x_{j}^{2})J(x_{j})}\\frac{1}{\\left(x_{i}-x_{j}\\right)} & i\\ne j,i=1,\\cdots,N-1\\\\\n\\frac{\\alpha-\\beta+(\\alpha+\\beta)x_{i}}{2(1-x_{i}^{2})} & i=j=1,\\cdots,N-1\\\\\n\\frac{-2\\Gamma(N+\\alpha+1)}{\\Gamma(N)\\Gamma(\\alpha+2)(1-x_{j})^{2}(1+x_{j})J(x_{j})} & i=N\n\\end{cases}\n\\]\n\n\nJacobi Gauss expansion\n\nJacobi Transformation:\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\alpha,\\beta)}\\Vert^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\alpha,\\beta)}(x_{j})w_{j}\n\\]\n\nInverse Jacobi Transformation:\n\n\\[\nu(x_{j})=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\alpha,\\beta)}(x_{j})\n\\]\nor\n\\[\n{\\bf u}={\\bf P}\\tilde{{\\bf u}}\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix. The quadrature polynomial for Jacobi-Gauss expansion is given by:\n\\[\n\\begin{aligned}Q(x) & =P_{N+1}^{(\\alpha,\\beta)}\\end{aligned}\n\\]\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}P_{N+1}^{(\\alpha,\\beta)}(x_{i})}{\\partial_{x}P_{N+1}^{(\\alpha,\\beta)}(x_{j})}\\frac{1}{x_{i}-x_{j}} & 0\\le i\\ne j\\le N\\\\\n\\frac{\\alpha-\\beta+(\\alpha+\\beta+2)x_{i}}{2(1-x_{i}^{2})} & 0\\le i=j\\le N\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Jacobi Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "ultraspherical-polynomial-expansion.html",
    "href": "ultraspherical-polynomial-expansion.html",
    "title": "Ultraspherical Polynomial Expansion",
    "section": "",
    "text": "Continuous expansion\nLet \\(u(x)\\) be any continuous function defined over \\(\\left[-1,1\\right]\\) and \\(P_{n}^{(\\lambda)}(x)\\) be an ultraspherical polynomial of degree \\(n\\) and \\(\\lambda&gt;-\\frac{1}{2}\\) . Then the continuous polynomial expansion of \\(u\\) in terms of ultraspherical polynomials is given by:\n\\[\nu(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}P_{n}^{(\\lambda)}(x)\n\\]\nwith the following expansion coefficients,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\lambda)}\\Vert^{2}}\\int_{-1}^{+1}u(x)P_{n}^{(\\lambda)}(x)\\left(1-x^{2}\\right)^{\\lambda-\\frac{1}{2}}dx\n\\]\nwhere,\n\\[\n\\Vert P_{n}^{(\\lambda)}\\Vert^{2}=\\left(2^{1-2\\lambda}\\right)\\frac{\\pi}{\\left[\\Gamma(\\lambda)\\right]^{2}}\\frac{\\Gamma\\left(n+2\\lambda\\right)}{\\left(n+\\lambda\\right)\\Gamma\\left(n+1\\right)}\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) has a similar expansion with coefficients \\(\\hat{u}_{n}^{(m)}\\):\n\\[\n\\partial_{x}^{m}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(m)}P_{n}^{(\\lambda)}(x)\n\\]\nNow, we should ask, “what is the relation between \\(\\hat{u}_{n}^{(m)}\\) and \\(\\hat{u}_{n}^{(m-1)}\\)?” To get the answer let us start with the first derivative, that is, \\(m=1\\).\n\\[\n\\partial_{x}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(1)}P_{n}^{(\\lambda)}(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}\\partial_{x}P_{n}^{(\\lambda)}(x)\n\\]\nFrom the previous chapter, we know that,\n\\[\nP_{n}^{(\\lambda)}=\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{d}{dx}\\left(P_{n+1}^{(\\lambda)}-P_{n-1}^{(\\lambda)}\\right)\n\\]\nHence,\n\\[\n\\partial_{x}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(1)}\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{dP_{n+1}^{(\\lambda)}}{dx}-\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(1)}\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{dP_{n-1}^{(\\lambda)}}{dx}\n\\]\nNow note that\n\\[\n\\frac{dP_{-1}^{(\\lambda)}}{dx}=\\frac{dP_{0}^{(\\lambda)}}{dx}=0\n\\]\nhence,\n\\[\n\\partial_{x}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(1)}\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{dP_{n+1}^{(\\lambda)}}{dx}-\\sum_{n=2}^{\\infty}\\hat{u}_{n}^{(1)}\\frac{1}{2\\left(n+\\lambda\\right)}\\frac{dP_{n-1}^{(\\lambda)}}{dx}\n\\]\nor,\n\\[\n\\partial_{x}u(x)=\\sum_{n=0}^{\\infty}\\left(\\frac{\\hat{u}_{n-1}^{(1)}}{2\\left(n+\\lambda-1\\right)}-\\frac{\\hat{u}_{n+1}^{(1)}}{2\\left(n+\\lambda+1\\right)}\\right)\\frac{dP_{n}^{(\\lambda)}}{dx}\n\\]\nTherefore,\n\\[\n\\hat{u}_{n}=\\frac{\\hat{u}_{n-1}^{(1)}}{2\\left(n+\\lambda-1\\right)}-\\frac{\\hat{u}_{n+1}^{(1)}}{2\\left(n+\\lambda+1\\right)}\n\\]\nSimilarly,\n\\[\n\\hat{u}_{n}^{(m-1)}=\\frac{\\hat{u}_{n-1}^{(m)}}{2\\left(n+\\lambda-1\\right)}-\\frac{\\hat{u}_{n+1}^{(m)}}{2\\left(n+\\lambda+1\\right)}\n\\]\nTherefore, one can easily compute the expansion coefficient of the function from the expansion coefficients of its derivative. We can invert this relationship to get the coefficient of derivative from the expansion coefficient of the functions.\n\\[\n\\hat{u}_{n}^{(m)}=\\left(2n+\\lambda\\right)\\sum_{\\begin{aligned}p=n+1\\\\\nn+p\\text{ odd}\n\\end{aligned}\n}^{\\infty}\\hat{u}_{p}^{(m-1)}\n\\]\n\n\nTruncated expansion\nIn practice, we consider expansion of \\(u(x)\\) by using the finite number of polynomials \\(P_{n}^{(\\lambda)}(x)\\) with \\(n\\le N\\),\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}P_{n}^{(\\lambda)}(x)\n\\]\nIn this way, \\(\\mathcal{P}_{N}u(x)\\) denotes the projection of \\(u(x)\\) on \\({\\bf \\mathcal{P}}_{N}\\), therefore, \\(\\hat{u}_{n}=0,\\forall n&gt;N\\).\nLet us now consider the first derivative of \\(u\\).\n\\[\n\\mathcal{P}_{N}\\frac{du(x)}{dx}=\\sum_{n=0}^{N}\\hat{u}_{n}^{(1)}P_{n}^{(\\lambda)}(x),\n\\]\nwith \\(\\hat{u}_{n}^{(1)}=0,\\forall n&gt;N\\). Therefore,\n\\[\n\\hat{u}_{N}^{(1)}:=\\left(2N+\\lambda\\right)\\sum_{\\begin{aligned}p=N+1\\\\\nN+p\\text{ odd}\n\\end{aligned}\n}^{\\infty}\\hat{u}_{p}=0\n\\]\nIt means \\(\\mathcal{P}_{N}\\frac{du(x)}{dx}\\in\\mathcal{P}_{N-1}\\). Then, we can obtain coefficients of derivative from backward subtitution.\n\\[\n\\hat{u}_{n-1}^{(m)}=\\left(\\frac{n+\\lambda-1}{n+\\lambda+1}\\right)\\hat{u}_{n+1}^{(m)}+2\\left(n+\\lambda-1\\right)\\hat{u}_{n}^{(m-1)},\\text{with }\\hat{u}_{N}^{(m)}=0\n\\]\n\nTheorem: For any \\(u(x)\\in H_{w}^{p}\\left[-1,1\\right]\\), \\(p\\ge0\\), there exists a constant \\(C\\), independent of N, such that:\n\n\\[\n\\Vert u-\\mathcal{P}_{N}u\\Vert_{L_{w}^{2}\\left[-1,1\\right]}\\le CN^{-p}\\Vert u\\Vert_{H_{w}^{p}\\left[-1,1\\right]}\n\\]\nAccording to this theorem, the error in \\(u\\) decays spectrally in weighted \\(L^{2}\\) norm.\n\nTheorem: Let \\(u(x)\\in H_{w}^{p}\\left[-1,1\\right]\\); there exists a constant \\(C\\), independent of N, such that:\n\n\\[\n\\Vert\\mathcal{P}_{N}\\frac{du}{dx}-\\frac{d}{dx}\\mathcal{P}_{N}u\\Vert_{H_{w}^{q}\\left[-1,1\\right]}\\le CN^{2q-p+3/2}\\Vert u\\Vert_{H_{w}^{p}\\left[-1,1\\right]},\\quad0\\le q\\le p\n\\]\nAccording to this theorem, the error in \\(u\\) decays spectrally in weighted Sobolev norm.\n\nTheorem: For any \\(u(x)\\in H_{w}^{p}\\left[-1,1\\right]\\); there exists a constant \\(C\\), independent of N, such that:\n\n\\[\n\\Vert u-\\mathcal{P}_{N}u\\Vert_{H_{w}^{q}\\left[-1,1\\right]}\\le CN^{\\sigma(q,p)}\\Vert u\\Vert_{H_{w}^{p}\\left[-1,1\\right]},\\quad0\\le q\\le p\n\\]\nwhere,\n\\[\n\\sigma(q,p)=\\begin{cases}\n\\frac{3}{2}q-p & 0\\le q\\le1\\\\\n2q-p-\\frac{1}{2} & q\\ge1\n\\end{cases}\n\\]\nAccording to this theorem, the error in \\(u\\) decays spectrally in weighted Sobolev norm.\n\n\nDiscrete expansion\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) be a set of Gauss, Gauss-Radau or Gauss-Lobatto quadrature nodes and weights. The discrete Ultraspherical polynomial expansion is given by Inverse Discrete Ultraspherical Transform (or_Inverse Ultraspherical Transform_):\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\lambda)}(x)\n\\]\nwhere \\(\\tilde{u}_{n}\\) are the coefficients of discrete polynomial expansion compute by Forward Discrete Ultraspherical Transform (or_Ultraspherical Transform_):\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\lambda)}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\lambda)}(x_{j})w_{j}\n\\]\n\nIt is noteworthy that \\(\\Vert P_{n}^{(\\lambda)}\\Vert_{N}^{2}\\) would be exact for Gauss and Gauss-Radau quadratures, but it would be approximate for Gauss-Lobatto points.\n\\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) denotes value of \\(u\\) at quadrature points, we will refer it to nodal-values in physical space, or simply nodal values of \\(u\\).\n\\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) denotes the coefficient of polynomial expansion, we will refer it to modal-values in frequency space, or simply modal values \\(u\\).\n\nIf \\(f\\in\\mathcal{P}_{N}\\) then, the \\(f^{2}\\in\\mathcal{P}_{2N}\\), therefore, \\(N+1\\) Gauss-Quadrature points and Gauss-Radau points are enough for computing the norm. However, Gauss-Lobatto points are not enough to compute the norm. In practice, Gauss-Lobatto rules are very useful as they include boundary nodes. Thanks to following lemma we can compute the equivalent norm by using the Gauss-Lobatto points.\n\nLemma: Let \\(\\left\\{ x_{i}\\right\\}_{i=1}^{N-1}\\) be the \\(N-1\\) interior Gauss-Lobatto points, then the ultraspherical polynomials, \\(P_{N}^{(\\lambda)}\\) satisfy\n\n\n\\[\n\\frac{d}{dx}P_{N-1}^{(\\lambda)}(x_{i})=-NP_{N}^{(\\lambda)}(x_{j})\\quad\\forall j\\in\\left[1,\\cdots,N-1\\right],\n\\]\n\nThe proof is direct by noting that\n\n\\[\nnP_{n}^{(\\lambda)}=x\\frac{dP_{n}^{(\\lambda)}}{dx}-\\frac{dP_{n-1}^{(\\lambda)}}{dx}\n\\]\n\nand \\(\\left\\{ x_{i}\\right\\}_{i=1}^{N-1}\\) are zeros of \\(\\frac{dP_{N}^{(\\lambda)}}{dx}\\). Therefore, the discrete norm \\(\\Vert P_{N}^{(\\lambda)}\\Vert_{N}\\) by using Gauss-Lobatto points:\n\\[\n\\Vert P_{N}^{(\\lambda)}\\Vert_{N}^{2}=\\frac{1}{N^{2}}\\sum_{i=0}^{N}\\left(\\frac{d}{dx}P_{N-1}^{(\\lambda)}(x_{i})\\right)^{2}w_{i}\n\\]\nNote that\n\\[\n\\frac{dP_{N-1}^{\\left(\\lambda\\right)}}{dx}=2\\lambda P_{N-2}^{\\left(\\lambda+1\\right)}\n\\]\nHence,\n\\[\n\\Vert P_{N}^{(\\lambda)}\\Vert_{N}^{2}=\\frac{1}{N^{2}}\\left\\Vert \\frac{dP_{N-1}^{(\\lambda)}}{dx}\\right\\Vert_{N}^{2}=\\frac{4\\lambda^{2}}{N^{2}}\\left\\Vert P_{N-2}^{\\left(\\lambda+1\\right)}\\right\\Vert_{N}^{2}=2^{2\\lambda}\\frac{\\Gamma^{2}(\\lambda+\\frac{1}{2})\\Gamma(N+2\\lambda)}{NN!\\Gamma^{2}(2\\lambda)}\n\\]\n\n\nDifferentiation in physical space\nIn the physical space, we can write the discrete Ultraspherical expansion by using the Lagrange polynomials with interpolation points as the Gauss quadrature points \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N}\\).\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})l_{j}(x)\n\\]\n\nAll Lagrange polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), are \\(N\\) order polynomials, and \\(l_{j}(x_{i})=\\delta_{ij}\\).\nLagrange polynomial depend upon the quadrature rules used in the discrete transformation.\n\nThe differentiation in physical space is given by:\n\\[\n\\partial_{x}^{m}\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x)\n\\]\nIf we evaluate the derivatives at quadrature points, then\n\\[\n\\begin{aligned}\\partial_{x}^{m}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\end{aligned}\n\\]\nConsider \\(m=1\\):\n\\[\n\\begin{aligned}\\partial_{x}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\\\\n& =\\sum_{j=0}^{N}u(x_{j})D_{ij}\n\\end{aligned}\n\\]\nwhere, \\(D_{ij}\\) is called the Differentiation matrix, which is a square matrix of size \\(N+1\\). In the matrix-vector form:\n\\[\n\\frac{d{\\bf u}}{dx}={\\bf D}{\\bf u}\n\\]\n\nThe entries of matrix \\({\\bf D}\\) depend upon the orthogonal polynomial family, and quadrature type.\nIf the \\(N+1\\) quadrature points are zeros of polynomial \\(Q\\in\\mathcal{P}_{N+1}\\), (\\(Q\\) is also called the quadrature polynomial) then Lagrange polynomial and \\(D_{ij}\\) are given by:\n\n\\[\nl_{j}(x)=\\frac{Q(x)}{\\partial_{x}Q(x_{j})}\\frac{1}{\\left(x-x_{j}\\right)},j=0,\\cdots,N\n\\]\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}Q(x_{i})}{\\partial_{x}Q(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\\\\\n\\frac{\\partial_{x}^{2}Q(x_{i})}{2\\partial_{x}Q(x_{j})} & i=j\n\\end{cases}\n\\]\nQuadrature polynomial \\(Q\\) for Gauss, Gauss-Radau, and Gauss-Lobatto quadrature are given by\n\\[\nQ=\\begin{cases}\nP_{N+1}^{(\\lambda)}(x) & \\text{Gauss}\\\\\nP_{N+1}^{(\\lambda)}(x)-\\frac{P_{N+1}^{(\\lambda)}(a)}{P_{N}^{(\\lambda)}(a)}P_{N}^{(\\lambda)}(x) & \\text{Gauss-Radau}\\\\\nP_{N+1}^{(\\lambda)}(x)+\\alpha_{N}P_{N}^{(\\lambda)}(x)+\\beta_{N}P_{N-1}^{(\\lambda)}(x) & \\text{Gauss-Lobatto}\n\\end{cases}\n\\]\nIn the case of Gauss-Radau \\(a\\in\\left\\{ -1,1\\right\\} ,\\)and in the case of Gauss-Lobatto, \\(\\alpha_{N}\\) and \\(\\beta_{N}\\) are obtained by solving following 2×2 system of equations:\n\\[\n\\left[\\begin{array}{cc}\nP_{N}^{(\\lambda)}(-1) & P_{N-1}^{(\\lambda)}(-1)\\\\\nP_{N}^{(\\lambda)}(1) & P_{N-1}^{(\\lambda)}(1)\n\\end{array}\\right]\\left\\{ \\begin{array}{c}\n\\alpha_{N}\\\\\n\\beta_{N}\n\\end{array}\\right\\} =-\\left\\{ \\begin{array}{c}\nP_{N+1}^{(\\lambda)}(-1)\\\\\nP_{N+1}^{(\\lambda)}(+1)\n\\end{array}\\right\\}\n\\]\n\nThe \\(m\\)th order derivative of \\(u\\) at quadrature point is given by:\n\n\\[\n\\frac{d^{m}{\\bf u}}{dx^{m}}={\\bf D}^{m}{\\bf u}\n\\]\n\n\nDifferentiation in frequency space\nThe process of Differentiation in the frequency space is relatively simpler than that in the physical space. In the frequency space, \\(\\mathcal{I}_{N}u(x)\\in\\mathcal{P}_{N}\\),\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\lambda)}(x)\n\\]\nand \\(\\mathcal{I}_{N}\\frac{d}{dx}u(x)\\in P_{N-1}\\)\n\\[\n\\mathcal{I}_{N}\\frac{d}{dx}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}\\frac{d}{dx}P_{n}^{(\\lambda)}(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}^{(1)}P_{n}^{(\\lambda)}(x)\n\\]\nwhere, \\(\\tilde{u}_{n}^{(1)}\\) are the modal coefficients for first derivative, and \\(\\tilde{u}_{N}^{(1)}=0\\). We can use following backward subtitution algorithm to get \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\)from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\):\n\nInitialization: \\(\\tilde{u}_{N}^{(1)}=0\\), \\(\\tilde{u}_{N-1}^{(1)}=2\\left(N+\\lambda-1\\right)\\tilde{u}_{N}\\)\nFor \\(n=N-1,\\cdots,1\\): \\(\\tilde{u}_{n-1}^{(1)}=2\\left(n+\\lambda-1\\right)\\tilde{u}_{n}+\\left(\\frac{n+\\lambda-1}{n+\\lambda+1}\\right)\\tilde{u}_{n+1}^{(1)}\\)\n\n\n\nUltraspherical Gauss-Lobatto expansion\n\nUltraspherical Transformation:\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\lambda)}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\lambda)}(x_{j})w_{j}\n\\]\n\\[\n\\Vert P_{n}^{(\\lambda)}\\Vert_{N}^{2}=\\begin{cases}\n\\Vert P_{n}^{(\\lambda)}\\Vert^{2} & n&lt;N\\\\\n2\\left(\\frac{N+\\lambda}{N}\\right)\\Vert P_{N}^{(\\lambda)}\\Vert^{2} & n=N\n\\end{cases}\n\\]\nwhere,\n\\[\n\\Vert P_{n}^{(\\lambda)}\\Vert^{2}=\\left(2^{1-2\\lambda}\\right)\\frac{\\pi}{\\left[\\Gamma(\\lambda)\\right]^{2}}\\frac{\\Gamma\\left(n+2\\lambda\\right)}{\\left(n+\\lambda\\right)\\Gamma\\left(n+1\\right)}\n\\]\n\nInverse Ultraspherical Transformation:\n\n\\[\nu(x_{j})=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\lambda)}(x_{j})\n\\]\nNote that the inverse Jacobi transform is computed by using Clenshaw algorithm. Differentiation in physical space is performed by using \\(D\\) matrix, which is given below.\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\lambda-0.5-N(N+2\\lambda)}{(2\\lambda+3)} & i=j=0\\\\\n\\frac{\\left(\\lambda-0.5\\right)x_{i}}{\\left(1-x_{i}^{2}\\right)} & i=j=1,\\cdots,N-1\\\\\n-D_{00} & i=j=N\\\\\n\\frac{\\lambda+0.5}{x_{i}-x_{j}}\\frac{P_{N}^{(\\lambda)}(x_{i})}{P_{N}^{(\\lambda)}(x_{j})} & i\\ne j,j=0,N\\\\\n\\frac{1}{x_{i}-x_{j}}\\frac{P_{N}^{(\\lambda)}(x_{i})}{P_{N}^{(\\lambda)}(x_{j})} & i\\ne j=1,\\cdots,N-1\n\\end{cases}\n\\]\nUltraspherical-Gauss-Lobatto differentiation matrix is centro-symmetric:\n\\[\nD_{ij}=-D_{N-i,N-j}\n\\]\nThis centro-symmetric corresponds to the property that if the vector containing function value is reversed, that is, \\((u_{0},u_{1}\\cdots,u_{N})\\) is replaced by \\((u_{N},u_{N-1}\\cdots,u_{0})\\), then the derivative is reversed and also multiply by \\(-1\\). This property can be used to develop fast differentiation algorithms. Let \\({\\bf u}\\) be the vector (in \\(R^{N+1}\\)) of nodal values (Lobatto points) of function \\(u(x)\\). Let us consider that \\(N\\) is odd. So\n\\[\n{\\bf u}={\\bf e}+{\\bf o}\n\\]\nwhere,\n\\[\ne_{i}=\\frac{1}{2}\\left(u_{i}+u_{N-i}\\right),i=0,1,\\cdots,N\n\\]\n\\[\ne_{i}=\\frac{1}{2}\\left(u_{i}-u_{N-i}\\right),i=0,1,\\cdots,N\n\\]\nNote that\n\\[\ne_{i}=e_{N-i}\n\\]\n\\[\no_{i}=-o_{N-i}\n\\]\nNow we can write differentiation in physical space as:\n\\[\n{\\bf u}^{(1)}={\\bf D}{\\bf u}={\\bf D}{\\bf e}+{\\bf D}{\\bf o}={\\bf e}'+{\\bf o}'\n\\]\nwhere, \\(\\forall i=0,1,\\cdots,N/2\\)\n\\[\ne'_{i}=\\sum_{j=0}^{N/2}\\left(D_{ij}+D_{i,N-j}\\right)e_{j}\n\\]\n\\[\ne'_{N-i}=-e_{i}'\n\\]\n\\[\no'_{i}=\\sum_{j=0}^{N/2}\\left(D_{ij}-D_{i,N-j}\\right)o_{j}\n\\]\n\\[\no'_{N-i}=o_{i}'\n\\]\nTherefore,\\(\\forall i=0,1,\\cdots,N/2\\)\n\\[\nu_{i}'=e'_{i}+o'_{i}\n\\]\n\\[\nu'_{N-i}=-e'_{i}+o'_{i}\n\\]\n\n\nUltraspherical Gauss expansion\n\nUltraspherical transformation:\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\lambda)}\\Vert^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\lambda)}(x_{j})w_{j}\n\\]\n\nInverse Ultraspherical transformation:\n\n\\[\nu(x_{j})=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\lambda)}(x_{j})\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix.\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}P_{N+1}^{(\\lambda)}(x_{i})}{\\partial_{x}P_{N+1}^{(\\lambda)}(x_{j})}\\frac{1}{x_{i}-x_{j}} & 0\\le i\\ne j\\le N\\\\\n\\frac{\\left(\\lambda+0.5\\right)x_{i}}{\\left(1-x_{i}^{2}\\right)} & 0\\le i=j\\le N\n\\end{cases}\n\\]\n\n\nUltraspherical Gauss-Radau expansion\n\nUltraspherical transformation:\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}^{(\\lambda)}\\Vert^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}^{(\\lambda)}(x_{j})w_{j}\n\\]\n\nInverse Ultraspherical transformation:\n\n\\[\nu(x_{j})=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}^{(\\lambda)}(x_{j})\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Ultraspherical Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html",
    "href": "legendre-polynomial-expansion.html",
    "title": "Legendre Polynomial Expansion",
    "section": "",
    "text": "Continuous expansion\nLegendre polynomial can be obtained from Ultraspherical polynomial, by using \\(\\lambda=0.5\\). The continuous Legendre expansion is given by\n\\[\nu(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}P_{n}(x)\n\\]\nwith the following expansion coefficients,\n\\[\n\\hat{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert^{2}}\\int_{-1}^{+1}u(x)P_{n}(x)dx\n\\]\nwhere,\n\\[\n\\Vert P_{n}\\Vert^{2}=\\frac{2}{2n+1}\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) has a similar expansion with coefficients \\(\\hat{u}_{n}^{(m)}\\):\n\\[\n\\partial_{x}^{m}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(m)}P_{n}^{(\\lambda)}(x)\n\\]\nThe relation between \\(\\hat{u}_{n}\\) and \\(\\hat{u}_{n}^{(1)}\\) is given below:\n\\[\n\\hat{u}_{n}=\\frac{\\hat{u}_{n-1}^{(1)}}{\\left(2n-1\\right)}-\\frac{\\hat{u}_{n+1}^{(1)}}{\\left(2n+3\\right)}\n\\]\nSimilarly,\n\\[\n\\hat{u}_{n}^{(m-1)}=\\frac{\\hat{u}_{n-1}^{(m)}}{\\left(2n-1\\right)}-\\frac{\\hat{u}_{n+1}^{(m)}}{\\left(2n+3\\right)}\n\\]\nTherefore, one can easily compute the expansion coefficient of the function from the expansion coefficients of its derivative.",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#truncated-expansion",
    "href": "legendre-polynomial-expansion.html#truncated-expansion",
    "title": "Legendre Polynomial Expansion",
    "section": "Truncated expansion",
    "text": "Truncated expansion\nIn practice, we consider expansion of \\(u(x)\\) by using the finite number of polynomials \\(P_{n}(x)\\) with \\(n\\le N\\),\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}P_{n}(x)\n\\]\nIn this way, \\(\\mathcal{P}_{N}u(x)\\) denotes the projection of \\(u(x)\\) on \\(\\mathcal{P}_{N}\\), therefore, \\(\\hat{u}_{n}=0,\\forall n&gt;N\\).\nLet us now consider the first derivative of \\(u\\).\n\\[\n\\mathcal{P}_{N}\\frac{du(x)}{dx}=\\sum_{n=0}^{N}\\hat{u}_{n}^{(1)}P_{n}(x),\n\\]\nwith \\(\\hat{u}_{n}^{(1)}=0,\\forall n&gt;N\\) and \\(\\mathcal{P}_{N}\\frac{du(x)}{dx}\\in\\mathcal{P}_{N-1}\\). We can obtain coefficients of derivative from backward subtitution.\n\\[\n\\hat{u}_{n-1}^{(m)}=\\left(\\frac{2n-1}{2n+3}\\right)\\hat{u}_{n+1}^{(m)}+\\left(2n-1\\right)\\hat{u}_{n}^{(m-1)},\\text{with }\\hat{u}_{N}^{(m)}=0\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#discrete-expansion",
    "href": "legendre-polynomial-expansion.html#discrete-expansion",
    "title": "Legendre Polynomial Expansion",
    "section": "Discrete expansion",
    "text": "Discrete expansion\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) be a set of Gauss, Gauss-Radau or Gauss-Lobatto quadrature nodes and weights. The discrete Legendre polynomial expansion is given by (Inverse Legendre Transform):\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}(x)\n\\]\nwhere \\(\\tilde{u}_{n}\\) are the coefficients of discrete polynomial expansion compute by Forward Discrete Legendre Transform (or_Legendre Transform_ation):\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})P_{n}(x_{j})w_{j}\n\\]\n\nIt is noteworthy that \\(\\Vert P_{n}\\Vert_{N}^{2}\\) would be exact for Gauss and Gauss-Radau quadratures, but it would be approximate for Gauss-Lobatto points.\n\\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) denotes value of \\(u\\) at quadrature points, we will refer it to nodal-values in physical space, or simply nodal values of \\(u\\).\n\\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) denotes the coefficient of polynomial expansion, we will refer it to modal-values in frequency space, or simply modal values \\(u\\).\n\nIf \\(f\\in\\mathcal{P}_{N}\\) then, the \\(f^{2}\\in\\mathcal{P}_{2N}\\), therefore, \\(N+1\\) Gauss-Quadrature points and Gauss-Radau points are enough for computing the norm. However, Gauss-Lobatto points are not enough to compute the norm. In practice, Gauss-Lobatto rules are very useful as they include boundary nodes. Thanks to following lemma we can compute the equivalent norm by using the Gauss-Lobatto points.",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#differentiation-in-physical-space",
    "href": "legendre-polynomial-expansion.html#differentiation-in-physical-space",
    "title": "Legendre Polynomial Expansion",
    "section": "Differentiation in physical space",
    "text": "Differentiation in physical space\nIn the physical space, we can write the discrete Legendre expansion by using the Lagrange polynomials with interpolation points as the Gauss quadrature points \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N}\\).\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})l_{j}(x)\n\\]\n\nAll Lagrange polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), are \\(N\\) order polynomials, and \\(l_{j}(x_{i})=\\delta_{ij}\\).\nLagrange polynomial depend upon the quadrature rules used in the discrete transformation.\n\nThe differentiation in physical space is given by:\n\\[\n\\partial_{x}^{m}\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x)\n\\]\nIf we evaluate the derivatives at quadrature points, then\n\\[\n\\begin{aligned}\\partial_{x}^{m}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\end{aligned}\n\\]\nConsider \\(m=1\\):\n\\[\n\\begin{aligned}\\partial_{x}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\\\\n& =\\sum_{j=0}^{N}u(x_{j})D_{ij}\n\\end{aligned}\n\\]\nwhere, \\(D_{ij}\\) is called the Differentiation matrix, which is a square matrix of size \\(N+1\\). In the matrix-vector form:\n\\[\n\\frac{d{\\bf u}}{dx}={\\bf D}{\\bf u}\n\\]\n\nThe entries of matrix \\({\\bf D}\\) depend upon the orthogonal polynomial family, and quadrature type.\nIf the \\(N+1\\) quadrature points are zeros of polynomial \\(Q\\in\\mathcal{P}_{N+1}\\), (\\(Q\\) is also called the quadrature polynomial) then Lagrange polynomial and \\(D_{ij}\\) are given by:\n\n\\[\nl_{j}(x)=\\frac{Q(x)}{\\partial_{x}Q(x_{j})}\\frac{1}{\\left(x-x_{j}\\right)},j=0,\\cdots,N\n\\]\n\\[\nD_{ij}=\\begin{cases}\n\\frac{\\partial_{x}Q(x_{i})}{\\partial_{x}Q(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\\\\\n\\frac{\\partial_{x}^{2}Q(x_{i})}{2\\partial_{x}Q(x_{j})} & i=j\n\\end{cases}\n\\]\nQuadrature polynomial \\(Q\\) for Gauss, Gauss-Radau, and Gauss-Lobatto quadrature are given by\n\\[\nQ=\\begin{cases}\nP_{N+1}(x) & \\text{Gauss}\\\\\nP_{N+1}(x)-\\frac{P_{N+1}(a)}{P_{N}(a)}P_{N}(x) & \\text{Gauss-Radau}\\\\\nP_{N+1}(x)+\\alpha_{N}P_{N}(x)+\\beta_{N}P_{N-1}(x) & \\text{Gauss-Lobatto}\n\\end{cases}\n\\]\nIn the case of Gauss-Radau \\(a\\in\\left\\{ -1,1\\right\\} ,\\)and in the case of Gauss-Lobatto, \\(\\alpha_{N}\\) and \\(\\beta_{N}\\) are obtained by solving following 2×2 system of equations:\n\\[\n\\left[\\begin{array}{cc}\nP_{N}(-1) & P_{N-1}(-1)\\\\\nP_{N}(1) & P_{N-1}(1)\n\\end{array}\\right]\\left\\{ \\begin{array}{c}\n\\alpha_{N}\\\\\n\\beta_{N}\n\\end{array}\\right\\} =-\\left\\{ \\begin{array}{c}\nP_{N+1}(-1)\\\\\nP_{N+1}(+1)\n\\end{array}\\right\\}\n\\]\n\nThe \\(m\\)th order derivative of \\(u\\) at quadrature point is given by:\n\n\\[\n\\frac{d^{m}{\\bf u}}{dx^{m}}={\\bf D}^{m}{\\bf u}\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#derivative-in-frequency-space",
    "href": "legendre-polynomial-expansion.html#derivative-in-frequency-space",
    "title": "Legendre Polynomial Expansion",
    "section": "Derivative in frequency space",
    "text": "Derivative in frequency space\nThe process of Differentiation in the frequency space is relatively simpler than that in the physical space. In the frequency space, \\(\\mathcal{I}_{N}u(x)\\in\\mathcal{P}_{N}\\),\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}P_{n}(x)\n\\]\nand \\(\\mathcal{I}_{N}\\frac{d}{dx}u(x)\\in P_{N-1}\\)\n\\[\n\\mathcal{I}_{N}\\frac{d}{dx}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}\\frac{d}{dx}P_{n}(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}^{(1)}P_{n}(x)\n\\]\nwhere, \\(\\tilde{u}_{n}^{(1)}\\) are the modal coefficients for first derivative, and \\(\\tilde{u}_{N}^{(1)}=0\\). We can use following backward subtitution algorithm to get \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\)from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\):\n\nInitialization: \\(\\tilde{u}_{N}^{(1)}=0\\), \\(\\tilde{u}_{N-1}^{(1)}=\\left(2N-1\\right)\\tilde{u}_{N}\\)\nFor \\(n=N-1,\\cdots,1\\): \\(\\tilde{u}_{n-1}^{(1)}=\\left(2n-1\\right)\\tilde{u}_{n}+\\left(\\frac{2n-1}{2n+3}\\right)\\tilde{u}_{n+1}^{(1)}\\)",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#legendre-gauss-lobatto-expansion",
    "href": "legendre-polynomial-expansion.html#legendre-gauss-lobatto-expansion",
    "title": "Legendre Polynomial Expansion",
    "section": "Legendre Gauss-Lobatto expansion",
    "text": "Legendre Gauss-Lobatto expansion\n\nLegendre transformation\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert_{N}^{2}}\\sum_{i=0}^{N}u(x_{i})P_{n}(x_{i})w_{i}\n\\]\n\\[\n\\Vert P_{n}\\Vert_{N}^{2}=\\begin{cases}\n\\frac{2}{2n+1} & n&lt;N\\\\\n\\frac{2}{N} & n=N\n\\end{cases}\n\\]\n\nInverse Legendre Transformation:\n\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{i=0}^{N}\\tilde{u}_{i}P_{i}(x)\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix, which is given below.\n\\[\nD_{ij}=\\begin{cases}\n-\\frac{N(N+1)}{4} & i=j=0\\\\\n0 & i=j\\in[1,\\cdots,N-1]\\\\\n\\frac{P_{N}(x_{i})}{P_{N}(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\\\\\n\\frac{N(N+1)}{4} & i=j=N\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#legendre-gauss-expansion",
    "href": "legendre-polynomial-expansion.html#legendre-gauss-expansion",
    "title": "Legendre Polynomial Expansion",
    "section": "Legendre Gauss Expansion",
    "text": "Legendre Gauss Expansion\n\nLegendre transformation\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert_{N}^{2}}\\sum_{i=0}^{N}u(x_{i})P_{n}(x_{i})w_{i}\n\\]\n\\[\n\\Vert P_{n}\\Vert_{N}^{2}=\\Vert P_{n}\\Vert^{2}=\\frac{2}{2n+1}\n\\]\n\nInverse Legendre Transformation:\n\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{i=0}^{N}\\tilde{u}_{i}P_{i}(x)\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix.\n\\[\nD_{ij}=\\begin{cases}\n\\frac{x_{i}}{1-x_{i}^{2}} & i=j\\\\\n\\frac{1}{x_{i}-x_{j}}\\frac{\\partial_{x}P_{N+1}(x_{i})}{\\partial_{x}P_{N+1}(x_{j})} & i\\ne j\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "legendre-polynomial-expansion.html#legendre-gauss-radau-expansion",
    "href": "legendre-polynomial-expansion.html#legendre-gauss-radau-expansion",
    "title": "Legendre Polynomial Expansion",
    "section": "Legendre Gauss-Radau Expansion",
    "text": "Legendre Gauss-Radau Expansion\n\nLegendre transformation\n\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert_{N}^{2}}\\sum_{i=0}^{N}u(x_{i})P_{n}(x_{i})w_{i}\n\\]\n\\[\n\\Vert P_{n}\\Vert_{N}^{2}=\\Vert P_{n}\\Vert^{2}=\\frac{2}{2n+1}\n\\]\n\nInverse Legendre Transformation:\n\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{i=0}^{N}\\tilde{u}_{i}P_{i}(x)\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legendre Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "chebyshev-polynomial-expansion.html",
    "href": "chebyshev-polynomial-expansion.html",
    "title": "Chebyshev Polynomial Expansion",
    "section": "",
    "text": "Continuous expansion\nThe continuous Chebyshev expansion of a function \\(u(x)\\) is given by\n\\[\nu(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}T_{n}(x)\n\\]\nwhere, the expansion coefficients are defined by:\n\\[\n\\hat{u}_{n}=\\frac{2}{c_{n}\\pi}\\int_{-1}^{+1}u(x)T_{n}(x)\\frac{1}{\\sqrt{1-x^{2}}}dx\n\\]\nwhere,\n\\[\nc_{n}=\\begin{cases}\n2 & n=0\\\\\n1 & n&gt;0\n\\end{cases}\n\\]\nThe norm of Chebyshev polynomial is given by\n\\[\n\\Vert T_{n}\\Vert^{2}=\\frac{c_{n}\\pi}{2}\n\\]\nThe \\(m\\)th derivative of \\(u(x)\\) has a similar expansion with coefficients \\(\\hat{u}_{n}^{(m)}\\):\n\\[\n\\partial_{x}^{m}u(x)=\\sum_{n=0}^{\\infty}\\hat{u}_{n}^{(m)}T_{n}(x)\n\\]\nThe relationship between \\(\\hat{u}_{n}^{(m-1)}\\) and \\(\\hat{u}_{n}^{(m)}\\) is given by:\n\\[\n\\hat{u}_{n}^{(m-1)}=\\frac{c_{n-1}}{2n}\\hat{u}_{n-1}^{(m)}-\\frac{1}{2n}\\hat{u}_{n+1}^{(m)}\n\\]\nThe relationship between \\(\\hat{u}_{n}^{(m)}\\)and \\(\\hat{u}_{n}^{(m-1)}\\) is given by:\n\\[\n\\hat{u}_{n}^{(m)}=\\frac{2}{c_{n}}\\sum_{\\begin{aligned}p=n+1\\\\\nn+p\\text{ odd}\n\\end{aligned}\n}^{\\infty}p\\hat{u}_{p}^{(m-1)}\\quad\\forall n\n\\]\n\n\nTruncated expansion\nIn practice, we consider expansion of \\(u(x)\\) by using the finite number of polynomials \\(T_{n}(x)\\) with \\(n\\le N\\),\n\\[\n\\mathcal{P}_{N}u(x)=\\sum_{n=0}^{N}\\hat{u}_{n}T_{n}(x)\n\\]\nIn this way, \\(\\mathcal{P}_{N}u(x)\\) denotes the projection of \\(u(x)\\) on \\(\\mathcal{P}_{N}\\), therefore, \\(\\hat{u}_{n}=0,\\forall n&gt;N\\).\nLet us now consider the first derivative of \\(u\\).\n\\[\n\\mathcal{P}_{N}\\frac{du(x)}{dx}=\\sum_{n=0}^{N}\\hat{u}_{n}^{(1)}T_{n}(x),\n\\]\nwith \\(\\hat{u}_{n}^{(1)}=0,\\forall n&gt;N\\) and \\(\\mathcal{P}_{N}\\frac{du(x)}{dx}\\in\\mathcal{P}_{N-1}\\). We can obtain coefficients of derivative from backward subtitution.\n\\[\nc_{n-1}\\hat{u}_{n-1}^{(m)}=\\hat{u}_{n+1}^{(m)}+2n\\hat{u}_{n}^{(m-1)},\\text{with }\\hat{u}_{N}^{(m)}=0\n\\]\n\n\nDiscrete expansion\nLet \\(\\left\\{ x_{j},w_{j}\\right\\} _{j=0}^{N}\\) be a set of Gauss, Gauss-Radau or Gauss-Lobatto quadrature nodes and weights. The discrete Chebyshev polynomial expansion is given by (Inverse Chebyshev Transform):\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}T_{n}(x)\n\\]\nwhere \\(\\tilde{u}_{n}\\) are the coefficients of discrete polynomial expansion compute by Forward Discrete Chebyshev Transform (or_Chebyshev Transform_ation):\n\\[\n\\tilde{u}_{n}=\\frac{1}{\\Vert P_{n}\\Vert_{N}^{2}}\\sum_{j=0}^{N}u(x_{j})T_{n}(x_{j})w_{j}\n\\]\n\nIt is noteworthy that \\(\\Vert P_{n}\\Vert_{N}^{2}\\) would be exact for Gauss and Gauss-Radau quadratures, but it would be approximate for Gauss-Lobatto points.\n\\(\\left\\{ u(x_{j})\\right\\}_{j=0}^{N}\\) denotes value of \\(u\\) at quadrature points, we will refer it to nodal-values in physical space, or simply nodal values of \\(u\\).\n\\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\) denotes the coefficient of polynomial expansion, we will refer it to modal-values in frequency space, or simply modal values \\(u\\).\n\nIf \\(f\\in\\mathcal{P}_{N}\\) then, the \\(f^{2}\\in\\mathcal{P}_{2N}\\), therefore, \\(N+1\\) Gauss-Quadrature points and Gauss-Radau points are enough for computing the norm. However, Gauss-Lobatto points are not enough to compute the norm. In practice, Gauss-Lobatto rules are very useful as they include boundary nodes. Thanks to following lemma we can compute the equivalent norm by using the Gauss-Lobatto points.\n\nTheorem: For \\(u\\in\\) \\(H_{w}^{p}[-1,1]\\) where \\(p&gt;\\frac{1}{2}\\) and \\(0\\le q\\le p\\), there exists a constant, \\(C\\), which is independent of \\(N\\), such that: \\(\\Vert u-\\mathcal{I}_{N}u\\Vert_{H_{w}^{q}\\left[-1,1\\right]}\\le CN^{2q-p}\\Vert u\\Vert_{H_{w}^{p}\\left[-1,1\\right]}\\).\nTheorem: For \\(u\\in\\) \\(H_{w}^{p}[-1,1]\\) where \\(p&gt;\\frac{1}{2}\\) , there exists a constant, \\(C\\), which is independent of \\(N\\), such that: \\(\\Vert u-\\mathcal{I}_{N}u\\Vert_{L^{\\infty}\\left[-1,1\\right]}\\le CN^{1/2-p}\\Vert u\\Vert_{H_{w}^{p}\\left[-1,1\\right]}\\).\n\n\n\nDifferentiation in physical space\nIn the physical space, we can write the discrete Legendre expansion by using the Lagrange polynomials with interpolation points as the Gauss quadrature points \\(\\left\\{ x_{j}\\right\\}_{j=0}^{N}\\).\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})l_{j}(x)\n\\]\n\nAll Lagrange polynomials, \\(\\left\\{ l_{j}(x)\\right\\}_{j=0}^{N}\\), are \\(N\\) order polynomials, and \\(l_{j}(x_{i})=\\delta_{ij}\\).\nLagrange polynomial depend upon the quadrature rules used in the discrete transformation.\n\nThe differentiation in physical space is given by:\n\\[\n\\partial_{x}^{m}\\mathcal{I}_{N}u(x)=\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x)\n\\]\nIf we evaluate the derivatives at quadrature points, then\n\\[\n\\begin{aligned}\\partial_{x}^{m}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}^{m}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\end{aligned}\n\\]\nConsider \\(m=1\\):\n\\[\n\\begin{aligned}\\partial_{x}\\mathcal{I}_{N}u(x_{i}) & =\\sum_{j=0}^{N}u(x_{j})\\partial_{x}l_{j}(x_{i}),\\quad i=0,\\cdots,N\\\\\n& =\\sum_{j=0}^{N}u(x_{j})D_{ij}\n\\end{aligned}\n\\]\nwhere, \\(D_{ij}\\) is called the Differentiation matrix, which is a square matrix of size \\(N+1\\). In the matrix-vector form:\n\\[\n\\frac{d{\\bf u}}{dx}={\\bf D}{\\bf u}\n\\]\n\nThe entries of matrix \\({\\bf D}\\) depend upon the orthogonal polynomial family, and quadrature type.\nThe \\(m\\)th order derivative of \\(u\\) at quadrature point is given by:\n\n\\[\n\\frac{d^{m}{\\bf u}}{dx^{m}}={\\bf D}^{m}{\\bf u}\n\\]\n\n\nDerivative in frequency space\nThe process of Differentiation in the frequency space is relatively simpler than that in the physical space. In the frequency space, \\(\\mathcal{I}_{N}u(x)\\in\\mathcal{P}_{N}\\),\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}T_{n}(x)\n\\]\nand \\(\\mathcal{I}_{N}\\frac{d}{dx}u(x)\\in P_{N-1}\\)\n\\[\n\\mathcal{I}_{N}\\frac{d}{dx}u(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}\\frac{d}{dx}T_{n}(x)=\\sum_{n=0}^{N}\\tilde{u}_{n}^{(1)}T_{n}(x)\n\\]\nwhere, \\(\\tilde{u}_{n}^{(1)}\\) are the modal coefficients for first derivative, and \\(\\tilde{u}_{N}^{(1)}=0\\). We can use following backward subtitution algorithm to get \\(\\left\\{ \\tilde{u}_{n}^{(1)}\\right\\}_{n=0}^{N}\\)from \\(\\left\\{ \\tilde{u}_{n}\\right\\}_{n=0}^{N}\\):\n\nInitialization: \\(\\tilde{u}_{N}^{(1)}=0\\), \\(\\tilde{u}_{N-1}^{(1)}=\\left(\\frac{2N}{c_{N-1}}\\right)\\tilde{u}_{N}\\)\nFor \\(n=N-1,\\cdots,1\\): \\(c_{n-1}\\tilde{u}_{n-1}^{(1)}=\\tilde{u}_{n+1}^{(1)}+2n\\tilde{u}_{n}\\)\n\n\n\nChebyshev Gauss-Lobatto expansion\nChebyshev Gauss-Lobatto rule is given by:\n\\[\nx_{j}=-\\cos\\left(\\frac{\\pi j}{N}\\right)\n\\]\n\\[\nw_{j}=\\frac{\\pi}{c_{j}N}\n\\]\n\\[\n\\theta_{j}=\\pi+\\frac{\\pi j}{N}\n\\]\n\\[\nT_{n}(x_{j})=cos\\left(n\\pi+\\frac{n\\pi j}{N}\\right)=\\left(-1\\right)^{n}cos\\left(\\frac{n\\pi j}{N}\\right)\n\\]\n\\[\nT_{n}(x_{j})=\\cos\\left(\\frac{n\\pi j}{N}\\right)\n\\]\n\nChebyshev transformation\n\n\\[\n\\begin{aligned}\\tilde{u}_{n} & =\\frac{1}{\\Vert T_{n}\\Vert_{N}^{2}}\\sum_{i=0}^{N}u(x_{i})\\cos\\left(\\frac{n\\pi i}{N}\\right)w_{i}\\end{aligned}\n\\]\nwhere,\n\\[\n\\Vert T_{n}\\Vert_{N}^{2}=\\frac{\\pi}{2}\\tilde{c}_{n}\n\\]\nand,\n\\[\n\\tilde{c}_{n}=\\begin{cases}\n2 & n=0,N\\\\\n1 & \\text{otherwise}\n\\end{cases}\n\\]\nFinally, the Chebyshev Gauss-Lobatto expansion of a function \\(u(x)\\) on \\([-1,1]\\) is given by:\n\\[\n\\begin{aligned}\\tilde{u}_{n} & =\\frac{2}{N\\tilde{c}_{n}}\\sum_{i=0}^{N}\\frac{u(x_{i})}{\\tilde{c}_{i}}\\cos\\left(\\frac{n\\pi i}{N}\\right)\\end{aligned}\n\\]\n\nInverse Chebyshev Transformation:\n\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{i=0}^{N}\\tilde{u}_{i}T_{i}(x)\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix, which is given below.\n\\[\nD_{ij}=\\begin{cases}\n-\\frac{2N^{2}+1}{6} & i=j=0\\\\\n-\\frac{x_{i}}{2(1-x_{i}^{2})} & i=j\\in[1,\\cdots,N-1]\\\\\n\\frac{\\tilde{c}_{i}}{\\tilde{c}_{j}}\\frac{\\left(-1\\right)^{i+j}}{x_{i}-x_{j}} & i\\ne j\\\\\n-D_{00} & i=j=N\n\\end{cases}\n\\]\nTo achieve higher order accuracy in spectral differentiations, we use:\n\\[\nD_{ij}=\\begin{cases}\n-\\frac{2N^{2}+1}{6} & i=j=0\\\\\n-\\frac{x_{i}}{2\\sin^{2}\\left(\\frac{\\pi i}{N}\\right)} & i=j\\in[1,\\cdots,N-1]\\\\\n\\frac{\\tilde{c}_{i}}{2\\tilde{c}_{j}}\\frac{\\left(-1\\right)^{i+j}}{\\sin\\left(\\frac{i+j}{2N}\\pi\\right)\\sin\\left(\\frac{i-j}{2N}\\pi\\right)} & i\\ne j\\\\\n-D_{00} & i=j=N\n\\end{cases}\n\\]\n\n\nChebyshev Gauss expansion\nChebyshev Gauss points are:\n\\[\nx_{j}=-\\cos\\left(\\frac{(2j+1)\\pi}{2N+2}\\right)\n\\]\n\\[\nw_{j}=\\frac{\\pi}{N+1}\n\\]\n\\[\n\\theta_{j}=\\pi+\\frac{\\left(2j+1\\right)\\pi}{2N+2}\n\\]\n\\[\nT_{n}(x_{j})=cos\\left(n\\pi+\\frac{n\\left(2j+1\\right)\\pi}{2N+2}\\right)=\\left(-1\\right)^{n}\\cos n\\left(\\frac{2j+1}{2N+2}\\right)\\pi\n\\]\nTherefore,\n\\[\nT_{n}(x_{j})=\\cos n\\left(\\frac{2j+1}{2N+2}\\right)\\pi\n\\]\n\nChebyshev transformation:\n\n\\[\n\\begin{aligned}\\tilde{u}_{n} & =\\frac{2}{c_{n}(N+1)}\\sum_{i=0}^{N}u(x_{i})\\cos\\frac{n(2i+1)}{N+1}\\frac{\\pi}{2}\\end{aligned}\n\\]\n\nInverse Chebyshev Transformation:\n\n\\[\n\\mathcal{I}_{N}u(x)=\\sum_{i=0}^{N}\\tilde{u}_{i}T_{i}(x)\n\\]\nDifferentiation in physical space is performed by using \\(D\\) matrix, which is given below.\n\\[\nD_{ij}=\\begin{cases}\n\\frac{z_{i}}{2(1-z_{i}^{2})} & i=j\\\\\n\\frac{\\partial_{x}T_{N+1}(x_{i})}{\\partial_{x}T_{N+1}(x_{j})}\\frac{1}{x_{i}-x_{j}} & i\\ne j\n\\end{cases}\n\\]",
    "crumbs": [
      "Orthogonal polynomial expansion",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chebyshev Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "16  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]